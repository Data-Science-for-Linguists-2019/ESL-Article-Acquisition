{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis\n",
    "2019.04.06 - ?\n",
    "\n",
    "I get to data analysis in this notebook. This is _part 1_, as I am planning on attacking analysis from another aspect in the future. This notebook looks at the usage of articles in front of specific count and mass nouns, obtained from the prepatory analysis and exploration. However, due to limitations on finding nouns used in each level of interest for four language groups in two different corpora (Arabic L1 from BALC, Arabic L1 from PELIC, Spanish L1 from PELIC, Korean L1 from PELIC), only 1 sample from each level in each language was able to be obtained. Due to this, and due to the fact that I may not have very many interesting or informative findings, I am planning on expanding my analysis in a second part.\n",
    "\n",
    "## Summary of code\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%pprint            # to turn off pretty printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# I tried to use .read_csv, but it didn't work, so I'll continue to use .from_csv\n",
    "balc = pd.DataFrame.from_csv('../data/balc_targets.csv', index_col=[0])\n",
    "pelic = pd.DataFrame.from_csv('../private/pelic_targets.csv', index_col=[0])\n",
    "targets = pd.DataFrame.from_csv('../exploratory-analysis/chosen_targets_new.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Level</th>\n",
       "      <th>Original_Text</th>\n",
       "      <th>Normalized_Essay</th>\n",
       "      <th>Revised_Essay</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_count</th>\n",
       "      <th>TTR</th>\n",
       "      <th>Guiraud</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>targ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1347</td>\n",
       "      <td>200611403</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200611403\\n\\n\\n\\nLast summer ho...</td>\n",
       "      <td>Last summer holiday iam going with my family t...</td>\n",
       "      <td>Last summer holiday iam going with my family t...</td>\n",
       "      <td>['Last', 'summer', 'holiday', 'iam', 'going', ...</td>\n",
       "      <td>82</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>4.858987</td>\n",
       "      <td>[(Last, 'JJ'), (summer, 'NN'), (holiday, 'NN')...</td>\n",
       "      <td>['last', 'summer', 'holiday', 'iam', 'go', 'wi...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1171</td>\n",
       "      <td>200608092</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200608092\\n\\n\\n\\nI have just ha...</td>\n",
       "      <td>I have just had the perfect holidy. In my holi...</td>\n",
       "      <td>I have just had the perfect holidy. In my holi...</td>\n",
       "      <td>['I', 'have', 'just', 'had', 'the', 'perfect',...</td>\n",
       "      <td>188</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>6.126330</td>\n",
       "      <td>[(I, 'PRP'), (have, 'VBP'), (just, 'RB'), (had...</td>\n",
       "      <td>['-PRON-', 'have', 'just', 'have', 'the', 'per...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1441</td>\n",
       "      <td>200603618</td>\n",
       "      <td>5</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 5 200603618\\n\\n\\n\\nIn the summer ...</td>\n",
       "      <td>In the summer holiday my family dicides to spe...</td>\n",
       "      <td>In the summer holiday my family dicides to spe...</td>\n",
       "      <td>['In', 'the', 'summer', 'holiday', 'my', 'fami...</td>\n",
       "      <td>215</td>\n",
       "      <td>0.460465</td>\n",
       "      <td>6.751744</td>\n",
       "      <td>[(In, 'IN'), (the, 'DT'), (summer, 'NN'), (hol...</td>\n",
       "      <td>['in', 'the', 'summer', 'holiday', '-PRON-', '...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1530</td>\n",
       "      <td>200607320</td>\n",
       "      <td>6</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 6 200607320\\n\\n\\n\\nThere have bee...</td>\n",
       "      <td>There have been many films reteased lately, So...</td>\n",
       "      <td>There have been many films reteased lately, So...</td>\n",
       "      <td>['There', 'have', 'been', 'many', 'films', 're...</td>\n",
       "      <td>234</td>\n",
       "      <td>0.598291</td>\n",
       "      <td>9.152086</td>\n",
       "      <td>[(There, 'EX'), (have, 'VBP'), (been, 'VBN'), ...</td>\n",
       "      <td>['there', 'have', 'be', 'many', 'film', 'retea...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>881</td>\n",
       "      <td>200607798</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200607798\\n\\nWhere I going to t...</td>\n",
       "      <td>Where I going to the India with my family , my...</td>\n",
       "      <td>Where I going to the India with my family , my...</td>\n",
       "      <td>['Where', 'I', 'going', 'to', 'the', 'India', ...</td>\n",
       "      <td>151</td>\n",
       "      <td>0.602649</td>\n",
       "      <td>7.405475</td>\n",
       "      <td>[(Where, 'WRB'), (I, 'PRP'), (going, 'VBG'), (...</td>\n",
       "      <td>['where', '-PRON-', 'go', 'to', 'the', 'india'...</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index   Filename  Level  \\\n",
       "0        0   1347  200611403      3   \n",
       "1        1   1171  200608092      4   \n",
       "2        2   1441  200603618      5   \n",
       "3        3   1530  200607320      6   \n",
       "4        4    881  200607798      3   \n",
       "\n",
       "                                       Original_Text  \\\n",
       "0  \\t\\t\\t\\tCEPA 3 200611403\\n\\n\\n\\nLast summer ho...   \n",
       "1  \\t\\t\\t\\tCEPA 4 200608092\\n\\n\\n\\nI have just ha...   \n",
       "2  \\t\\t\\t\\tCEPA 5 200603618\\n\\n\\n\\nIn the summer ...   \n",
       "3  \\t\\t\\t\\tCEPA 6 200607320\\n\\n\\n\\nThere have bee...   \n",
       "4  \\t\\t\\t\\tCEPA 3 200607798\\n\\nWhere I going to t...   \n",
       "\n",
       "                                    Normalized_Essay  \\\n",
       "0  Last summer holiday iam going with my family t...   \n",
       "1  I have just had the perfect holidy. In my holi...   \n",
       "2  In the summer holiday my family dicides to spe...   \n",
       "3  There have been many films reteased lately, So...   \n",
       "4  Where I going to the India with my family , my...   \n",
       "\n",
       "                                       Revised_Essay  \\\n",
       "0  Last summer holiday iam going with my family t...   \n",
       "1  I have just had the perfect holidy. In my holi...   \n",
       "2  In the summer holiday my family dicides to spe...   \n",
       "3  There have been many films reteased lately, So...   \n",
       "4  Where I going to the India with my family , my...   \n",
       "\n",
       "                                              tokens  token_count       TTR  \\\n",
       "0  ['Last', 'summer', 'holiday', 'iam', 'going', ...           82  0.536585   \n",
       "1  ['I', 'have', 'just', 'had', 'the', 'perfect',...          188  0.446809   \n",
       "2  ['In', 'the', 'summer', 'holiday', 'my', 'fami...          215  0.460465   \n",
       "3  ['There', 'have', 'been', 'many', 'films', 're...          234  0.598291   \n",
       "4  ['Where', 'I', 'going', 'to', 'the', 'India', ...          151  0.602649   \n",
       "\n",
       "    Guiraud                                                pos  \\\n",
       "0  4.858987  [(Last, 'JJ'), (summer, 'NN'), (holiday, 'NN')...   \n",
       "1  6.126330  [(I, 'PRP'), (have, 'VBP'), (just, 'RB'), (had...   \n",
       "2  6.751744  [(In, 'IN'), (the, 'DT'), (summer, 'NN'), (hol...   \n",
       "3  9.152086  [(There, 'EX'), (have, 'VBP'), (been, 'VBN'), ...   \n",
       "4  7.405475  [(Where, 'WRB'), (I, 'PRP'), (going, 'VBG'), (...   \n",
       "\n",
       "                                              lemmas   targ  \n",
       "0  ['last', 'summer', 'holiday', 'iam', 'go', 'wi...   book  \n",
       "1  ['-PRON-', 'have', 'just', 'have', 'the', 'per...   book  \n",
       "2  ['in', 'the', 'summer', 'holiday', '-PRON-', '...   book  \n",
       "3  ['there', 'have', 'be', 'many', 'film', 'retea...   book  \n",
       "4  ['where', '-PRON-', 'go', 'to', 'the', 'india'...  money  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Level</th>\n",
       "      <th>Original_Text</th>\n",
       "      <th>Normalized_Essay</th>\n",
       "      <th>Revised_Essay</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_count</th>\n",
       "      <th>TTR</th>\n",
       "      <th>Guiraud</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>targ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>200611403</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200611403\\n\\n\\n\\nLast summer ho...</td>\n",
       "      <td>Last summer holiday iam going with my family t...</td>\n",
       "      <td>Last summer holiday iam going with my family t...</td>\n",
       "      <td>['Last', 'summer', 'holiday', 'iam', 'going', ...</td>\n",
       "      <td>82</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>4.858987</td>\n",
       "      <td>[(Last, 'JJ'), (summer, 'NN'), (holiday, 'NN')...</td>\n",
       "      <td>['last', 'summer', 'holiday', 'iam', 'go', 'wi...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>200608092</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200608092\\n\\n\\n\\nI have just ha...</td>\n",
       "      <td>I have just had the perfect holidy. In my holi...</td>\n",
       "      <td>I have just had the perfect holidy. In my holi...</td>\n",
       "      <td>['I', 'have', 'just', 'had', 'the', 'perfect',...</td>\n",
       "      <td>188</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>6.126330</td>\n",
       "      <td>[(I, 'PRP'), (have, 'VBP'), (just, 'RB'), (had...</td>\n",
       "      <td>['-PRON-', 'have', 'just', 'have', 'the', 'per...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>200603618</td>\n",
       "      <td>5</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 5 200603618\\n\\n\\n\\nIn the summer ...</td>\n",
       "      <td>In the summer holiday my family dicides to spe...</td>\n",
       "      <td>In the summer holiday my family dicides to spe...</td>\n",
       "      <td>['In', 'the', 'summer', 'holiday', 'my', 'fami...</td>\n",
       "      <td>215</td>\n",
       "      <td>0.460465</td>\n",
       "      <td>6.751744</td>\n",
       "      <td>[(In, 'IN'), (the, 'DT'), (summer, 'NN'), (hol...</td>\n",
       "      <td>['in', 'the', 'summer', 'holiday', '-PRON-', '...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>200607320</td>\n",
       "      <td>6</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 6 200607320\\n\\n\\n\\nThere have bee...</td>\n",
       "      <td>There have been many films reteased lately, So...</td>\n",
       "      <td>There have been many films reteased lately, So...</td>\n",
       "      <td>['There', 'have', 'been', 'many', 'films', 're...</td>\n",
       "      <td>234</td>\n",
       "      <td>0.598291</td>\n",
       "      <td>9.152086</td>\n",
       "      <td>[(There, 'EX'), (have, 'VBP'), (been, 'VBN'), ...</td>\n",
       "      <td>['there', 'have', 'be', 'many', 'film', 'retea...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>200607798</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200607798\\n\\nWhere I going to t...</td>\n",
       "      <td>Where I going to the India with my family , my...</td>\n",
       "      <td>Where I going to the India with my family , my...</td>\n",
       "      <td>['Where', 'I', 'going', 'to', 'the', 'India', ...</td>\n",
       "      <td>151</td>\n",
       "      <td>0.602649</td>\n",
       "      <td>7.405475</td>\n",
       "      <td>[(Where, 'WRB'), (I, 'PRP'), (going, 'VBG'), (...</td>\n",
       "      <td>['where', '-PRON-', 'go', 'to', 'the', 'india'...</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0   Filename  Level  \\\n",
       "0        0  200611403      3   \n",
       "1        1  200608092      4   \n",
       "2        2  200603618      5   \n",
       "3        3  200607320      6   \n",
       "4        4  200607798      3   \n",
       "\n",
       "                                       Original_Text  \\\n",
       "0  \\t\\t\\t\\tCEPA 3 200611403\\n\\n\\n\\nLast summer ho...   \n",
       "1  \\t\\t\\t\\tCEPA 4 200608092\\n\\n\\n\\nI have just ha...   \n",
       "2  \\t\\t\\t\\tCEPA 5 200603618\\n\\n\\n\\nIn the summer ...   \n",
       "3  \\t\\t\\t\\tCEPA 6 200607320\\n\\n\\n\\nThere have bee...   \n",
       "4  \\t\\t\\t\\tCEPA 3 200607798\\n\\nWhere I going to t...   \n",
       "\n",
       "                                    Normalized_Essay  \\\n",
       "0  Last summer holiday iam going with my family t...   \n",
       "1  I have just had the perfect holidy. In my holi...   \n",
       "2  In the summer holiday my family dicides to spe...   \n",
       "3  There have been many films reteased lately, So...   \n",
       "4  Where I going to the India with my family , my...   \n",
       "\n",
       "                                       Revised_Essay  \\\n",
       "0  Last summer holiday iam going with my family t...   \n",
       "1  I have just had the perfect holidy. In my holi...   \n",
       "2  In the summer holiday my family dicides to spe...   \n",
       "3  There have been many films reteased lately, So...   \n",
       "4  Where I going to the India with my family , my...   \n",
       "\n",
       "                                              tokens  token_count       TTR  \\\n",
       "0  ['Last', 'summer', 'holiday', 'iam', 'going', ...           82  0.536585   \n",
       "1  ['I', 'have', 'just', 'had', 'the', 'perfect',...          188  0.446809   \n",
       "2  ['In', 'the', 'summer', 'holiday', 'my', 'fami...          215  0.460465   \n",
       "3  ['There', 'have', 'been', 'many', 'films', 're...          234  0.598291   \n",
       "4  ['Where', 'I', 'going', 'to', 'the', 'India', ...          151  0.602649   \n",
       "\n",
       "    Guiraud                                                pos  \\\n",
       "0  4.858987  [(Last, 'JJ'), (summer, 'NN'), (holiday, 'NN')...   \n",
       "1  6.126330  [(I, 'PRP'), (have, 'VBP'), (just, 'RB'), (had...   \n",
       "2  6.751744  [(In, 'IN'), (the, 'DT'), (summer, 'NN'), (hol...   \n",
       "3  9.152086  [(There, 'EX'), (have, 'VBP'), (been, 'VBN'), ...   \n",
       "4  7.405475  [(Where, 'WRB'), (I, 'PRP'), (going, 'VBG'), (...   \n",
       "\n",
       "                                              lemmas   targ  \n",
       "0  ['last', 'summer', 'holiday', 'iam', 'go', 'wi...   book  \n",
       "1  ['-PRON-', 'have', 'just', 'have', 'the', 'per...   book  \n",
       "2  ['in', 'the', 'summer', 'holiday', '-PRON-', '...   book  \n",
       "3  ['there', 'have', 'be', 'many', 'film', 'retea...   book  \n",
       "4  ['where', '-PRON-', 'go', 'to', 'the', 'india'...  money  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the index column, we don't need it\n",
    "balc = balc.drop('index', axis=1)\n",
    "balc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>class_code</th>\n",
       "      <th>level_id</th>\n",
       "      <th>native_language</th>\n",
       "      <th>version</th>\n",
       "      <th>toks_re</th>\n",
       "      <th>toks_re_len</th>\n",
       "      <th>toks_nltk</th>\n",
       "      <th>Guiraud</th>\n",
       "      <th>targ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35211</td>\n",
       "      <td>4599</td>\n",
       "      <td>cy3</td>\n",
       "      <td>75298</td>\n",
       "      <td>I am living in pittsburgh to studying English ...</td>\n",
       "      <td>w</td>\n",
       "      <td>3</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>1</td>\n",
       "      <td>['i', 'am', 'living', 'in', 'pittsburgh', 'to'...</td>\n",
       "      <td>237</td>\n",
       "      <td>['I', 'am', 'living', 'in', 'pittsburgh', 'to'...</td>\n",
       "      <td>6.365784</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26264</td>\n",
       "      <td>3441</td>\n",
       "      <td>aa2</td>\n",
       "      <td>61136</td>\n",
       "      <td>The reasons I decided to learn English\\nNowada...</td>\n",
       "      <td>w</td>\n",
       "      <td>4</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'reasons', 'i', 'decided', 'to', 'lear...</td>\n",
       "      <td>392</td>\n",
       "      <td>['The', 'reasons', 'I', 'decided', 'to', 'lear...</td>\n",
       "      <td>8.131728</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26812</td>\n",
       "      <td>3503</td>\n",
       "      <td>di8</td>\n",
       "      <td>62302</td>\n",
       "      <td>Effects of Beauty\\n        A lot of people rea...</td>\n",
       "      <td>w</td>\n",
       "      <td>5</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>1</td>\n",
       "      <td>['effects', 'of', 'beauty', 'a', 'lot', 'of', ...</td>\n",
       "      <td>366</td>\n",
       "      <td>['Effects', 'of', 'Beauty', 'A', 'lot', 'of', ...</td>\n",
       "      <td>8.415605</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18572</td>\n",
       "      <td>2544</td>\n",
       "      <td>dg7</td>\n",
       "      <td>41011</td>\n",
       "      <td>?        LIST\\n\\nThe entrance is in front of t...</td>\n",
       "      <td>w</td>\n",
       "      <td>3</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1</td>\n",
       "      <td>['list', 'the', 'entrance', 'is', 'in', 'front...</td>\n",
       "      <td>124</td>\n",
       "      <td>['?', 'LIST', 'The', 'entrance', 'is', 'in', '...</td>\n",
       "      <td>3.502303</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11290</td>\n",
       "      <td>1641</td>\n",
       "      <td>fv7</td>\n",
       "      <td>28619</td>\n",
       "      <td>-        Job.\\n-        Personality.\\n-       ...</td>\n",
       "      <td>w</td>\n",
       "      <td>4</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1</td>\n",
       "      <td>['job', 'personality', 'interested', 'i', 'hav...</td>\n",
       "      <td>315</td>\n",
       "      <td>['-', 'Job', '.', '-', 'Personality', '.', '-'...</td>\n",
       "      <td>9.353040</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   answer_id  question_id anon_id  user_file_id  \\\n",
       "0      35211         4599     cy3         75298   \n",
       "1      26264         3441     aa2         61136   \n",
       "2      26812         3503     di8         62302   \n",
       "3      18572         2544     dg7         41011   \n",
       "4      11290         1641     fv7         28619   \n",
       "\n",
       "                                                text class_code  level_id  \\\n",
       "0  I am living in pittsburgh to studying English ...          w         3   \n",
       "1  The reasons I decided to learn English\\nNowada...          w         4   \n",
       "2  Effects of Beauty\\n        A lot of people rea...          w         5   \n",
       "3  ?        LIST\\n\\nThe entrance is in front of t...          w         3   \n",
       "4  -        Job.\\n-        Personality.\\n-       ...          w         4   \n",
       "\n",
       "  native_language  version                                            toks_re  \\\n",
       "0          Arabic        1  ['i', 'am', 'living', 'in', 'pittsburgh', 'to'...   \n",
       "1          Arabic        1  ['the', 'reasons', 'i', 'decided', 'to', 'lear...   \n",
       "2          Arabic        1  ['effects', 'of', 'beauty', 'a', 'lot', 'of', ...   \n",
       "3          Korean        1  ['list', 'the', 'entrance', 'is', 'in', 'front...   \n",
       "4          Korean        1  ['job', 'personality', 'interested', 'i', 'hav...   \n",
       "\n",
       "   toks_re_len                                          toks_nltk   Guiraud  \\\n",
       "0          237  ['I', 'am', 'living', 'in', 'pittsburgh', 'to'...  6.365784   \n",
       "1          392  ['The', 'reasons', 'I', 'decided', 'to', 'lear...  8.131728   \n",
       "2          366  ['Effects', 'of', 'Beauty', 'A', 'lot', 'of', ...  8.415605   \n",
       "3          124  ['?', 'LIST', 'The', 'entrance', 'is', 'in', '...  3.502303   \n",
       "4          315  ['-', 'Job', '.', '-', 'Personality', '.', '-'...  9.353040   \n",
       "\n",
       "   targ  \n",
       "0  book  \n",
       "1  book  \n",
       "2  book  \n",
       "3  book  \n",
       "4  book  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pelic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">token_count</th>\n",
       "      <th colspan=\"8\" halign=\"left\">Guiraud</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Level</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>151.7</td>\n",
       "      <td>64.187313</td>\n",
       "      <td>78.0</td>\n",
       "      <td>102.25</td>\n",
       "      <td>144.0</td>\n",
       "      <td>167.00</td>\n",
       "      <td>264.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.163016</td>\n",
       "      <td>1.109401</td>\n",
       "      <td>4.858987</td>\n",
       "      <td>5.306816</td>\n",
       "      <td>5.996125</td>\n",
       "      <td>7.194436</td>\n",
       "      <td>7.877855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>211.3</td>\n",
       "      <td>41.411351</td>\n",
       "      <td>138.0</td>\n",
       "      <td>185.75</td>\n",
       "      <td>209.0</td>\n",
       "      <td>238.00</td>\n",
       "      <td>286.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.811704</td>\n",
       "      <td>1.021188</td>\n",
       "      <td>5.344792</td>\n",
       "      <td>6.127009</td>\n",
       "      <td>6.680361</td>\n",
       "      <td>7.663461</td>\n",
       "      <td>8.455767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0</td>\n",
       "      <td>251.6</td>\n",
       "      <td>70.062195</td>\n",
       "      <td>172.0</td>\n",
       "      <td>188.75</td>\n",
       "      <td>255.0</td>\n",
       "      <td>282.25</td>\n",
       "      <td>397.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.484633</td>\n",
       "      <td>0.928882</td>\n",
       "      <td>6.186455</td>\n",
       "      <td>6.807033</td>\n",
       "      <td>7.507225</td>\n",
       "      <td>7.826307</td>\n",
       "      <td>8.944468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>229.4</td>\n",
       "      <td>40.467271</td>\n",
       "      <td>183.0</td>\n",
       "      <td>200.75</td>\n",
       "      <td>220.5</td>\n",
       "      <td>243.00</td>\n",
       "      <td>303.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.029801</td>\n",
       "      <td>0.465230</td>\n",
       "      <td>7.529412</td>\n",
       "      <td>7.798222</td>\n",
       "      <td>7.981108</td>\n",
       "      <td>8.169718</td>\n",
       "      <td>9.152086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      token_count                                                         \\\n",
       "            count   mean        std    min     25%    50%     75%    max   \n",
       "Level                                                                      \n",
       "3            10.0  151.7  64.187313   78.0  102.25  144.0  167.00  264.0   \n",
       "4            10.0  211.3  41.411351  138.0  185.75  209.0  238.00  286.0   \n",
       "5            10.0  251.6  70.062195  172.0  188.75  255.0  282.25  397.0   \n",
       "6            10.0  229.4  40.467271  183.0  200.75  220.5  243.00  303.0   \n",
       "\n",
       "      Guiraud                                                              \\\n",
       "        count      mean       std       min       25%       50%       75%   \n",
       "Level                                                                       \n",
       "3        10.0  6.163016  1.109401  4.858987  5.306816  5.996125  7.194436   \n",
       "4        10.0  6.811704  1.021188  5.344792  6.127009  6.680361  7.663461   \n",
       "5        10.0  7.484633  0.928882  6.186455  6.807033  7.507225  7.826307   \n",
       "6        10.0  8.029801  0.465230  7.529412  7.798222  7.981108  8.169718   \n",
       "\n",
       "                 \n",
       "            max  \n",
       "Level            \n",
       "3      7.877855  \n",
       "4      8.455767  \n",
       "5      8.944468  \n",
       "6      9.152086  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balc.groupby('Level')['token_count', 'Guiraud'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">toks_re_len</th>\n",
       "      <th colspan=\"8\" halign=\"left\">Guiraud</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level_id</th>\n",
       "      <th>native_language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
       "      <th>Arabic</th>\n",
       "      <td>10.0</td>\n",
       "      <td>191.4</td>\n",
       "      <td>105.506398</td>\n",
       "      <td>75.0</td>\n",
       "      <td>113.50</td>\n",
       "      <td>174.0</td>\n",
       "      <td>234.00</td>\n",
       "      <td>400.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.504896</td>\n",
       "      <td>1.098519</td>\n",
       "      <td>4.638007</td>\n",
       "      <td>6.181381</td>\n",
       "      <td>6.649604</td>\n",
       "      <td>7.135215</td>\n",
       "      <td>7.848084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Korean</th>\n",
       "      <td>10.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>79.033045</td>\n",
       "      <td>100.0</td>\n",
       "      <td>123.25</td>\n",
       "      <td>171.0</td>\n",
       "      <td>239.50</td>\n",
       "      <td>330.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.221210</td>\n",
       "      <td>1.824843</td>\n",
       "      <td>3.502303</td>\n",
       "      <td>6.070947</td>\n",
       "      <td>7.876158</td>\n",
       "      <td>8.275595</td>\n",
       "      <td>9.358192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spanish</th>\n",
       "      <td>10.0</td>\n",
       "      <td>152.3</td>\n",
       "      <td>80.963709</td>\n",
       "      <td>69.0</td>\n",
       "      <td>102.00</td>\n",
       "      <td>139.5</td>\n",
       "      <td>169.75</td>\n",
       "      <td>355.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.011871</td>\n",
       "      <td>0.666962</td>\n",
       "      <td>5.151778</td>\n",
       "      <td>5.589022</td>\n",
       "      <td>5.930714</td>\n",
       "      <td>6.427172</td>\n",
       "      <td>7.295815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">4</th>\n",
       "      <th>Arabic</th>\n",
       "      <td>10.0</td>\n",
       "      <td>258.9</td>\n",
       "      <td>121.135782</td>\n",
       "      <td>57.0</td>\n",
       "      <td>165.50</td>\n",
       "      <td>303.0</td>\n",
       "      <td>359.50</td>\n",
       "      <td>392.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.592946</td>\n",
       "      <td>1.402359</td>\n",
       "      <td>4.900770</td>\n",
       "      <td>6.665213</td>\n",
       "      <td>8.151374</td>\n",
       "      <td>8.391443</td>\n",
       "      <td>9.564674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Korean</th>\n",
       "      <td>10.0</td>\n",
       "      <td>218.1</td>\n",
       "      <td>107.858395</td>\n",
       "      <td>46.0</td>\n",
       "      <td>170.25</td>\n",
       "      <td>219.5</td>\n",
       "      <td>309.25</td>\n",
       "      <td>361.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.587213</td>\n",
       "      <td>1.240380</td>\n",
       "      <td>5.602794</td>\n",
       "      <td>6.758256</td>\n",
       "      <td>7.602113</td>\n",
       "      <td>8.331711</td>\n",
       "      <td>9.353040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spanish</th>\n",
       "      <td>10.0</td>\n",
       "      <td>187.1</td>\n",
       "      <td>137.795702</td>\n",
       "      <td>59.0</td>\n",
       "      <td>86.25</td>\n",
       "      <td>106.0</td>\n",
       "      <td>312.25</td>\n",
       "      <td>398.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.127076</td>\n",
       "      <td>1.926144</td>\n",
       "      <td>5.077368</td>\n",
       "      <td>5.648795</td>\n",
       "      <td>6.457281</td>\n",
       "      <td>8.270508</td>\n",
       "      <td>10.536023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
       "      <th>Arabic</th>\n",
       "      <td>10.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>103.297843</td>\n",
       "      <td>79.0</td>\n",
       "      <td>131.00</td>\n",
       "      <td>246.0</td>\n",
       "      <td>297.50</td>\n",
       "      <td>366.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.722298</td>\n",
       "      <td>1.377498</td>\n",
       "      <td>5.659800</td>\n",
       "      <td>6.553237</td>\n",
       "      <td>7.899653</td>\n",
       "      <td>8.740135</td>\n",
       "      <td>9.616783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Korean</th>\n",
       "      <td>10.0</td>\n",
       "      <td>180.6</td>\n",
       "      <td>107.968308</td>\n",
       "      <td>60.0</td>\n",
       "      <td>96.50</td>\n",
       "      <td>159.0</td>\n",
       "      <td>215.50</td>\n",
       "      <td>374.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.333414</td>\n",
       "      <td>1.370396</td>\n",
       "      <td>4.776679</td>\n",
       "      <td>6.857697</td>\n",
       "      <td>7.363757</td>\n",
       "      <td>8.053800</td>\n",
       "      <td>9.499716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spanish</th>\n",
       "      <td>10.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>68.821831</td>\n",
       "      <td>159.0</td>\n",
       "      <td>303.00</td>\n",
       "      <td>330.0</td>\n",
       "      <td>361.50</td>\n",
       "      <td>397.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.254176</td>\n",
       "      <td>0.832434</td>\n",
       "      <td>6.661633</td>\n",
       "      <td>7.744835</td>\n",
       "      <td>8.385115</td>\n",
       "      <td>8.674723</td>\n",
       "      <td>9.712147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         toks_re_len                                           \\\n",
       "                               count   mean         std    min     25%    50%   \n",
       "level_id native_language                                                        \n",
       "3        Arabic                 10.0  191.4  105.506398   75.0  113.50  174.0   \n",
       "         Korean                 10.0  187.0   79.033045  100.0  123.25  171.0   \n",
       "         Spanish                10.0  152.3   80.963709   69.0  102.00  139.5   \n",
       "4        Arabic                 10.0  258.9  121.135782   57.0  165.50  303.0   \n",
       "         Korean                 10.0  218.1  107.858395   46.0  170.25  219.5   \n",
       "         Spanish                10.0  187.1  137.795702   59.0   86.25  106.0   \n",
       "5        Arabic                 10.0  226.0  103.297843   79.0  131.00  246.0   \n",
       "         Korean                 10.0  180.6  107.968308   60.0   96.50  159.0   \n",
       "         Spanish                10.0  317.0   68.821831  159.0  303.00  330.0   \n",
       "\n",
       "                                        Guiraud                                \\\n",
       "                             75%    max   count      mean       std       min   \n",
       "level_id native_language                                                        \n",
       "3        Arabic           234.00  400.0    10.0  6.504896  1.098519  4.638007   \n",
       "         Korean           239.50  330.0    10.0  7.221210  1.824843  3.502303   \n",
       "         Spanish          169.75  355.0    10.0  6.011871  0.666962  5.151778   \n",
       "4        Arabic           359.50  392.0    10.0  7.592946  1.402359  4.900770   \n",
       "         Korean           309.25  361.0    10.0  7.587213  1.240380  5.602794   \n",
       "         Spanish          312.25  398.0    10.0  7.127076  1.926144  5.077368   \n",
       "5        Arabic           297.50  366.0    10.0  7.722298  1.377498  5.659800   \n",
       "         Korean           215.50  374.0    10.0  7.333414  1.370396  4.776679   \n",
       "         Spanish          361.50  397.0    10.0  8.254176  0.832434  6.661633   \n",
       "\n",
       "                                                                   \n",
       "                               25%       50%       75%        max  \n",
       "level_id native_language                                           \n",
       "3        Arabic           6.181381  6.649604  7.135215   7.848084  \n",
       "         Korean           6.070947  7.876158  8.275595   9.358192  \n",
       "         Spanish          5.589022  5.930714  6.427172   7.295815  \n",
       "4        Arabic           6.665213  8.151374  8.391443   9.564674  \n",
       "         Korean           6.758256  7.602113  8.331711   9.353040  \n",
       "         Spanish          5.648795  6.457281  8.270508  10.536023  \n",
       "5        Arabic           6.553237  7.899653  8.740135   9.616783  \n",
       "         Korean           6.857697  7.363757  8.053800   9.499716  \n",
       "         Spanish          7.744835  8.385115  8.674723   9.712147  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pelic.groupby(['level_id', 'native_language'])['toks_re_len', 'Guiraud'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing regex\n",
    "I'll be using regular expressions to look for the targets, so below is some testing I did on a UDF and some test phrases to see what I can do with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "myre = re.compile(r'((\\w+ ){,2}\\w+ book.*?\\b)', re.I)\n",
    "test = [\"I put the book on the counter.\", \"I put a book on the counter.\", \"I put the books on the counter\",\n",
    "       \"I put some books on the counter.\", \"I put my books on the counter.\", \"I put book on the counter.\",\n",
    "       \"I put books on the counter.\", \"I put book and books and the other books on the counter.\"]\n",
    "\n",
    "def getArticles(regex, text):\n",
    "    myre = re.compile(regex)\n",
    "    search = myre.findall(text)\n",
    "    articles = []\n",
    "    for item in search:\n",
    "        if 'the' in item:\n",
    "            articles.append((item, 'the'))\n",
    "        elif 'a' in item or 'an' in item:\n",
    "            articles.append((item, 'a/an'))\n",
    "        else:\n",
    "            articles.append((item, '0'))\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('I put the book', 'put '), '0')]\n",
      "[(('I put a book', 'put '), '0')]\n",
      "[(('I put the books', 'put '), '0')]\n",
      "[(('I put some books', 'put '), '0')]\n",
      "[(('I put my books', 'put '), '0')]\n",
      "[(('I put book', 'I '), '0')]\n",
      "[(('I put books', 'I '), '0')]\n",
      "[(('I put book', 'I '), '0'), (('and books', ''), '0'), (('and the other books', 'the '), '0')]\n"
     ]
    }
   ],
   "source": [
    "for s in test:\n",
    "    print(getArticles(myre, s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, this is an obvious issue. All of the returns are zero articles, which is simply not true! Let's investigate a little further..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I put the book', 'put ')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = test[0]\n",
    "a = myre.findall(s1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I put the book', 'put ')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'I put the book'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]\n",
    "'the' in a[0]\n",
    "\n",
    "a[0][0]\n",
    "'the' in a[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the issue was that I was initially targeting the entire tuple, not the string object of interest, and it was returning 'false' for everything I searched for, thus kicking everything down to the 'else' condition. Let's rewrite getArticles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArticles(regex, text):\n",
    "    \"\"\"Uses a regex targeting a noun. Finds all instances of the noun and returns whether the return contains a definite article, an indefinite article, a zero article, or other types of determiners.\n",
    "    Input: regex (a regex compile), text (can be a single string object or a list of string objects).\n",
    "    Returns item and type of article in a list format.\"\"\"\n",
    "    myre = re.compile(regex)\n",
    "    look = myre.findall(text)\n",
    "    other = ['my', 'his', 'her', 'their', 'their', 'our', 'ours', 'its', \n",
    "            'this', 'that', 'these', 'those', 'some', 'much', 'many', 'most', 'some', 'any', 'enough',\n",
    "            'all', \"both\", 'half', 'either', 'neither', 'each', 'every']\n",
    "    articles = []\n",
    "    indef = re.compile(r'\\ban?\\b')\n",
    "    for item in look:\n",
    "        if any(search in item[0] for search in other):\n",
    "            if 'the' in item[0]:\n",
    "                articles.append((item, 'the'))\n",
    "            elif indef.search(item[0]):\n",
    "                matchobj = indef.search(item[0])\n",
    "                if matchobj:\n",
    "                    articles.append((item, 'a/an'))\n",
    "                else:\n",
    "                    articles.append((item, 'other'))\n",
    "            else:\n",
    "                articles.append((item, 'other'))\n",
    "        elif 'the' in item[0]:\n",
    "            articles.append((item, 'the'))\n",
    "        elif indef.search(item[0]):\n",
    "            matchobj = indef.search(item[0])\n",
    "            if matchobj:\n",
    "                articles.append((item, 'a/an'))\n",
    "        else:\n",
    "            articles.append((item, '0'))\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('I put the book', 'put '), 'the')]\n",
      "[(('I put a book', 'put '), 'a/an')]\n",
      "[(('I put the books', 'put '), 'the')]\n",
      "[(('I put some books', 'put '), 'other')]\n",
      "[(('I put my books', 'put '), 'other')]\n",
      "[(('I put book', 'I '), '0')]\n",
      "[(('I put books', 'I '), '0')]\n",
      "[(('I put book', 'I '), '0'), (('and books', ''), '0'), (('and the other books', 'the '), 'the')]\n"
     ]
    }
   ],
   "source": [
    "for s in test:\n",
    "    print(getArticles(myre, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('I put the book', 'put '), 'the')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getArticles(myre, s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I read any book', 'read '), ('and read any book', 'read ')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = myre.findall(pelic.text[0])\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('I read any book', 'read '), 'other'), (('and read any book', 'read '), 'other')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getArticles(myre, pelic.text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may not be perfect, so we'll need to double-check along the way, but this should be a good start. Let's start looking at some nouns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count nouns\n",
    "In this section, I'll take a look at the targets that are count nouns:\n",
    "- book \n",
    "- place\n",
    "- park\n",
    "- week\n",
    "- story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>counts_cepa</th>\n",
       "      <th>counts_pelic</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>place</td>\n",
       "      <td>770</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>park</td>\n",
       "      <td>431</td>\n",
       "      <td>247.0</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>week</td>\n",
       "      <td>308</td>\n",
       "      <td>469.0</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>story</td>\n",
       "      <td>182</td>\n",
       "      <td>254.0</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>book</td>\n",
       "      <td>121</td>\n",
       "      <td>685.0</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lemma  counts_cepa  counts_pelic   type\n",
       "37   place          770        1883.0  count\n",
       "73    park          431         247.0  count\n",
       "101   week          308         469.0  count\n",
       "154  story          182         254.0  count\n",
       "194   book          121         685.0  count"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[targets.type == 'count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'Book'\n",
    "myre is already set to look for 'book', so let's just jump into it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_pelic = pelic[pelic.targ == 'book']\n",
    "book_balc = balc[balc.targ == 'book']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>class_code</th>\n",
       "      <th>level_id</th>\n",
       "      <th>native_language</th>\n",
       "      <th>version</th>\n",
       "      <th>toks_re</th>\n",
       "      <th>toks_re_len</th>\n",
       "      <th>toks_nltk</th>\n",
       "      <th>Guiraud</th>\n",
       "      <th>targ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35211</td>\n",
       "      <td>4599</td>\n",
       "      <td>cy3</td>\n",
       "      <td>75298</td>\n",
       "      <td>I am living in pittsburgh to studying English ...</td>\n",
       "      <td>w</td>\n",
       "      <td>3</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>1</td>\n",
       "      <td>['i', 'am', 'living', 'in', 'pittsburgh', 'to'...</td>\n",
       "      <td>237</td>\n",
       "      <td>['I', 'am', 'living', 'in', 'pittsburgh', 'to'...</td>\n",
       "      <td>6.365784</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26264</td>\n",
       "      <td>3441</td>\n",
       "      <td>aa2</td>\n",
       "      <td>61136</td>\n",
       "      <td>The reasons I decided to learn English\\nNowada...</td>\n",
       "      <td>w</td>\n",
       "      <td>4</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'reasons', 'i', 'decided', 'to', 'lear...</td>\n",
       "      <td>392</td>\n",
       "      <td>['The', 'reasons', 'I', 'decided', 'to', 'lear...</td>\n",
       "      <td>8.131728</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26812</td>\n",
       "      <td>3503</td>\n",
       "      <td>di8</td>\n",
       "      <td>62302</td>\n",
       "      <td>Effects of Beauty\\n        A lot of people rea...</td>\n",
       "      <td>w</td>\n",
       "      <td>5</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>1</td>\n",
       "      <td>['effects', 'of', 'beauty', 'a', 'lot', 'of', ...</td>\n",
       "      <td>366</td>\n",
       "      <td>['Effects', 'of', 'Beauty', 'A', 'lot', 'of', ...</td>\n",
       "      <td>8.415605</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18572</td>\n",
       "      <td>2544</td>\n",
       "      <td>dg7</td>\n",
       "      <td>41011</td>\n",
       "      <td>?        LIST\\n\\nThe entrance is in front of t...</td>\n",
       "      <td>w</td>\n",
       "      <td>3</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1</td>\n",
       "      <td>['list', 'the', 'entrance', 'is', 'in', 'front...</td>\n",
       "      <td>124</td>\n",
       "      <td>['?', 'LIST', 'The', 'entrance', 'is', 'in', '...</td>\n",
       "      <td>3.502303</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11290</td>\n",
       "      <td>1641</td>\n",
       "      <td>fv7</td>\n",
       "      <td>28619</td>\n",
       "      <td>-        Job.\\n-        Personality.\\n-       ...</td>\n",
       "      <td>w</td>\n",
       "      <td>4</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1</td>\n",
       "      <td>['job', 'personality', 'interested', 'i', 'hav...</td>\n",
       "      <td>315</td>\n",
       "      <td>['-', 'Job', '.', '-', 'Personality', '.', '-'...</td>\n",
       "      <td>9.353040</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2738</td>\n",
       "      <td>300</td>\n",
       "      <td>ad1</td>\n",
       "      <td>16211</td>\n",
       "      <td>The statue is situated in the middle of a sea ...</td>\n",
       "      <td>w</td>\n",
       "      <td>5</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'statue', 'is', 'situated', 'in', 'the...</td>\n",
       "      <td>60</td>\n",
       "      <td>['The', 'statue', 'is', 'situated', 'in', 'the...</td>\n",
       "      <td>4.776679</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29216</td>\n",
       "      <td>3881</td>\n",
       "      <td>bt8</td>\n",
       "      <td>66247</td>\n",
       "      <td>...</td>\n",
       "      <td>w</td>\n",
       "      <td>3</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>1</td>\n",
       "      <td>['types', 'of', 'magazines', 'there', 'are', '...</td>\n",
       "      <td>166</td>\n",
       "      <td>['Types', 'of', 'magazines', 'There', 'are', '...</td>\n",
       "      <td>7.295815</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18537</td>\n",
       "      <td>2541</td>\n",
       "      <td>en1</td>\n",
       "      <td>40609</td>\n",
       "      <td>You can get other personal reasons in order to...</td>\n",
       "      <td>w</td>\n",
       "      <td>4</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>1</td>\n",
       "      <td>['you', 'can', 'get', 'other', 'personal', 're...</td>\n",
       "      <td>90</td>\n",
       "      <td>['You', 'can', 'get', 'other', 'personal', 're...</td>\n",
       "      <td>6.429965</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33911</td>\n",
       "      <td>4461</td>\n",
       "      <td>bi4</td>\n",
       "      <td>73652</td>\n",
       "      <td>Learning English has been very hard to underst...</td>\n",
       "      <td>w</td>\n",
       "      <td>5</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>1</td>\n",
       "      <td>['learning', 'english', 'has', 'been', 'very',...</td>\n",
       "      <td>365</td>\n",
       "      <td>['Learning', 'English', 'has', 'been', 'very',...</td>\n",
       "      <td>8.270098</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   answer_id  question_id anon_id  user_file_id  \\\n",
       "0      35211         4599     cy3         75298   \n",
       "1      26264         3441     aa2         61136   \n",
       "2      26812         3503     di8         62302   \n",
       "3      18572         2544     dg7         41011   \n",
       "4      11290         1641     fv7         28619   \n",
       "5       2738          300     ad1         16211   \n",
       "6      29216         3881     bt8         66247   \n",
       "7      18537         2541     en1         40609   \n",
       "8      33911         4461     bi4         73652   \n",
       "\n",
       "                                                text class_code  level_id  \\\n",
       "0  I am living in pittsburgh to studying English ...          w         3   \n",
       "1  The reasons I decided to learn English\\nNowada...          w         4   \n",
       "2  Effects of Beauty\\n        A lot of people rea...          w         5   \n",
       "3  ?        LIST\\n\\nThe entrance is in front of t...          w         3   \n",
       "4  -        Job.\\n-        Personality.\\n-       ...          w         4   \n",
       "5  The statue is situated in the middle of a sea ...          w         5   \n",
       "6                                                ...          w         3   \n",
       "7  You can get other personal reasons in order to...          w         4   \n",
       "8  Learning English has been very hard to underst...          w         5   \n",
       "\n",
       "  native_language  version                                            toks_re  \\\n",
       "0          Arabic        1  ['i', 'am', 'living', 'in', 'pittsburgh', 'to'...   \n",
       "1          Arabic        1  ['the', 'reasons', 'i', 'decided', 'to', 'lear...   \n",
       "2          Arabic        1  ['effects', 'of', 'beauty', 'a', 'lot', 'of', ...   \n",
       "3          Korean        1  ['list', 'the', 'entrance', 'is', 'in', 'front...   \n",
       "4          Korean        1  ['job', 'personality', 'interested', 'i', 'hav...   \n",
       "5          Korean        1  ['the', 'statue', 'is', 'situated', 'in', 'the...   \n",
       "6         Spanish        1  ['types', 'of', 'magazines', 'there', 'are', '...   \n",
       "7         Spanish        1  ['you', 'can', 'get', 'other', 'personal', 're...   \n",
       "8         Spanish        1  ['learning', 'english', 'has', 'been', 'very',...   \n",
       "\n",
       "   toks_re_len                                          toks_nltk   Guiraud  \\\n",
       "0          237  ['I', 'am', 'living', 'in', 'pittsburgh', 'to'...  6.365784   \n",
       "1          392  ['The', 'reasons', 'I', 'decided', 'to', 'lear...  8.131728   \n",
       "2          366  ['Effects', 'of', 'Beauty', 'A', 'lot', 'of', ...  8.415605   \n",
       "3          124  ['?', 'LIST', 'The', 'entrance', 'is', 'in', '...  3.502303   \n",
       "4          315  ['-', 'Job', '.', '-', 'Personality', '.', '-'...  9.353040   \n",
       "5           60  ['The', 'statue', 'is', 'situated', 'in', 'the...  4.776679   \n",
       "6          166  ['Types', 'of', 'magazines', 'There', 'are', '...  7.295815   \n",
       "7           90  ['You', 'can', 'get', 'other', 'personal', 're...  6.429965   \n",
       "8          365  ['Learning', 'English', 'has', 'been', 'very',...  8.270098   \n",
       "\n",
       "   targ  \n",
       "0  book  \n",
       "1  book  \n",
       "2  book  \n",
       "3  book  \n",
       "4  book  \n",
       "5  book  \n",
       "6  book  \n",
       "7  book  \n",
       "8  book  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_pelic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('I read any book', 'read '), 'other'), (('and read any book', 'read '), 'other')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'I am living in pittsburgh to studying English and I do not have more free time in weekdays because I have a lot of homework . Also on friday is special day to do any thing I like . Usually when I have free time I like spend my time with my friend or I read any book I like . \\n   I have many friends in pittsburgh  and I like hang out with them . Usually I meet my friends in the coffee and we keep talk about any interesting subject . Usually I like go to any where with my friend from anther country because I like to learn about the culture . Last week I went with my friend to Amoush country , she is from the Us and she taught me many information about the people who life in the Us .\\n  When I was child I like to read any thing around me and my father taught  me the reading is important part in the live . In the weekend I have special time to reading . Usually I like read about the history or any novel for example I bought novel last month and I have been reading it .\\n\\nI have more free time in my country than Pittsburgh and I do many activity  like sport and watching Tv . Also the best activities for me when I life anywhere  are spend my time with my friends and read any book I like .'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getArticles(myre, book_pelic.text[0])\n",
    "book_pelic.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_pelic: 0\n",
      "[(('I read any book', 'read '), 'other'), (('and read any book', 'read '), 'other')]\n",
      "I am living in pittsburgh to studying English and I do not have more free time in weekdays because I have a lot of homework . Also on friday is special day to do any thing I like . Usually when I have free time I like spend my time with my friend or I read any book I like . \n",
      "   I have many friends in pittsburgh  and I like hang out with them . Usually I meet my friends in the coffee and we keep talk about any interesting subject . Usually I like go to any where with my friend from anther country because I like to learn about the culture . Last week I went with my friend to Amoush country , she is from the Us and she taught me many information about the people who life in the Us .\n",
      "  When I was child I like to read any thing around me and my father taught  me the reading is important part in the live . In the weekend I have special time to reading . Usually I like read about the history or any novel for example I bought novel last month and I have been reading it .\n",
      "\n",
      "I have more free time in my country than Pittsburgh and I do many activity  like sport and watching Tv . Also the best activities for me when I life anywhere  are spend my time with my friends and read any book I like .\n",
      "\n",
      "book_pelic: 1\n",
      "[(('are so many books', 'so '), 'other'), (('For example books', 'For '), '0')]\n",
      "The reasons I decided to learn English\n",
      "Nowadays many people learn and study English in many countries. English is the most expanse language in the world. More than half the populations around the world speak English. I have chosen English as the second language after my mother tongue. Learning another language gives me the ability to understand other culture.  Also there are three main reasons why I decided to learn English as a second language, study, communication, and business.\n",
      "The most important reason is study. Learning English is usually a part of getting a high score on a test such as TOEFL for university. I have to study English hard to enter a good university in the U.S. Also, there are so many books written in English that I must learn English. The English is the language of sciences now. There are many researches and conferences had used English language. The English is the key to many things. For example books, music, computers, health, and internet.\n",
      "The next reason is communication. English has become the international language over the world. I learn English because I want to travel to another country and I need to know speak English to get many things as stay in a hotel or buy gifts or communicate with other people. Also English is the main language of organizations like the Unite Nation. There are lots of letters and postcards are written in English. Almost all international competitions are administrated in English. For example, the Olympics worlds contest. In addition I talk about my ideas and opinions on internet discussion groups or send e-mail to interesting people and learn about their life and culture.\n",
      "The last reason is business. Learning English give me the ability do business oversees in other countries. Learning English helps me to open the door of business and markets over the world. All business today is international. I have to know English to contact other businesspeople. There are many international business newspapers and magazines written in English. \n",
      "  In conclusion, learning English is probably one of the best skills to study by the beat language and communication with people from different country and make business over the world. Learning other countries language is very hard, but there are lots of people learning English. And each of them has a variety of important reasons.\n",
      "\n",
      "\n",
      "book_pelic: 2\n",
      "[(('they judged the book', 'judged '), 'the'), (('judge a book', 'judge '), 'a/an')]\n",
      "Effects of Beauty\n",
      "        A lot of people really get wonderful opportunities in their life only because they are beautiful or handsome. On the other hand there are some people who didn't get such chances because they don't look good although they are qualified. There are some positives effects of being beautiful or handsome such as getting a better job or having a great social life. However; there are some negatives like facing sexual harassment. \n",
      "        Everybody feels comfortable or happy when seeing a good looking person especially from the opposite sex. There are some positives of being a good-looking person. First of all, handsome or beautiful people get good chances in their life. For example, if two women applied for a job and they were both qualified for it, the company would most likely hire the prettier one because people judge from the appearance.  Secondly, the social life of a good looking person is usually better because people want to know this person to date him/her for example.  According to Jane Brody (1981) attractiveness was an important factor in choosing a partner to date.\n",
      "        \n",
      "\n",
      "However, there are some negatives of being beautiful or handsome. One of the negatives for example is a company could hire unqualified people for important position because they are attractive. The company may not know that this specific person is not qualified but they judged the book by its cover. In the same article, Jane wrote \"M INNEAPOLIS STUDIES of physical attractiveness show that people do, in fact, judge a book by its cover, often with dramatic effects on those being judged\". Another negative of being a good looking person is that beautiful people could face sexual harassment in their life especially at an early age and this could destroy the person's life. A big number of people who have Psychological Issues, have suffered from sexual harassment when they were young.\n",
      "        In conclusion, being a good-looking person has some positives like better chances in life and a good social life. However it has also some negatives such as facing sexual harassment.\n",
      "References:\n",
      "BRODY, J (1981, September 1). Effects of beauty found to run surprisingly deep. Retrieved July 2, 2009, from ANON_URLPAGE \n",
      "\n",
      "\n",
      "\n",
      "book_pelic: 3\n",
      "[(('between book', ''), '0'), (('beside book', ''), '0'), (('between book', ''), '0'), (('I have two book', 'have '), '0'), (('One book', ''), '0'), (('beside book', ''), '0')]\n",
      "?        LIST\n",
      "\n",
      "The entrance is in front of the desk.\n",
      "The desk is on the front, between book chests.\n",
      "Bed is on the left corner, beside book chest.\n",
      "Clothes chest is on the left, in front of bed.\n",
      "My room center has the heart shape rug.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I have little furniture in my room.\n",
      "As you enter the door through the entrance, desk is in front of you. The desk is on the front, between book chests. I have two book chests. One book chest is on the right wall. The other one is on the front wall. My bed is on the left corner, beside book chest. Clothes chest is on the left, in front of bed. My room center has the heart shape rug.\n",
      "\n",
      "\n",
      "book_pelic: 4\n",
      "[(('reading books', ''), '0')]\n",
      "-        Job.\n",
      "-        Personality.\n",
      "-        Interested.\n",
      "\n",
      "\n",
      "I have a sister whose name is Jin-Young, is different from me. And she is 2 years older then me. My people said that we look similar, so they sometimes can't distinguish both on the pictures. But we are different from job, personalities and interested.\n",
      "\n",
      "The first thing is that we were different job, before when I came to Pittsburgh. My sister has been working dental Hygienist. She likes her job because she likes to meet people and she take care people's teeth, whereas I have been working at trading company. I've liked my job because I prepared to actively work such as stewardess or designer. But I've working at office.\n",
      "\n",
      "Second of all, we are totally different. She is a sincere lady. Her sincerity shows off her character. She tends to was withdrawn. I think she is now much outgoing than she used to be. Also she's not that strong. On the other hand, I was a kind of introvert person. But I changed my personality when I entered my company. Because I had to presentation in front people and we had dine with coworkers. More I speak too much. Also I'm very impatient so, I'm rather short tempered, and sometimes get easily excited about unimportant things. \n",
      "\n",
      "Finally, we are interested which are very different. My sister usually spends time to staying at home, reading books or watching movies in her free time. But I usually spend time to exercise or going to outside such as running, playing tennis or swimming.\n",
      "We are different interested but sometimes we had have same time such as shopping.\n",
      "\n",
      "In conclusion, there is different in personalities, jobs and interested between us. But we have the qualities of the parents. So we love and we respect each other. And we are good matches like we hit it off well. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "book_pelic: 5\n",
      "[(('She has a book', 'has '), 'a/an')]\n",
      "The statue is situated in the middle of a sea or river, and it is pretty high. It is blush green and it looks like a beautiful woman. She has a book in her left hand, and she holds a torch in the right hand. On the top of her head, there is a crown, which looks good on her. \n",
      "\n",
      "book_pelic: 6\n",
      "[(('from all good bookshops', 'all '), 'other')]\n",
      "                                                                                  Types of magazines\n",
      "\n",
      "\n",
      "\n",
      "                   There are three types of magazines, they are available from all good bookshops or online.  I can to get the best preference or the information about if it is interesting for me.\n",
      "\n",
      "The first type of magazine is a sport magazine.  For example, I can find magazine providing the latest information on building and operating an athletic facility, athletic programs, action photos, athlete interviews, scores and statistic on an  professional and college sports.  The second type of magazine is an automobile whether if I have a passion for cars, I can find a long list of magazines especially tailored for the information needs of car such as car design, car market, or car lifestyle.  The last type is a health magazine these cover a variety of topics including physical fitness, nutrition, beauty, weight training and body building.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In conclusion, I can find many types of magazines the most important,  I can choose or find my preference and what information is interesting for me.\n",
      "\n",
      "book_pelic: 7\n",
      "[(('and thousands of books', 'thousands '), '0')]\n",
      "You can get other personal reasons in order to acquire the proficiency in English and to continue including more benefits in this list. But, no body can deny that learning English has many benefits today. Because this language permits us communicate our ideas and feelings to the people that in some cases they are living in other side of the world. By the English we can accede to the advances of science, read thousands and thousands of books that are published every day, and finally, of course earn some money.\n",
      "\n",
      "book_pelic: 8\n",
      "[(('lessons in the book', 'in '), 'the')]\n",
      "Learning English has been very hard to understand for me, but I have had many teachers that have encouraged me to practice English all the time to improve my skills. Every teacher has its own style of teaching class, but it is crucial that at the end all teachers have the same goal, try to give to students the best information possible. Each style of teaching has positive and negative aspects; in this essay I will focus in two of my teachers, and specifically in how they were alike, and how they were different each other. \n",
      "\n",
      "\n",
      "First of all, I had a teacher she was very kind, good, orderly, and I could improve my English skill very well. But sometimes, in my class we missed a lot of time in a specific point or chapter, so we could not keep working as fast as possible in a semester. I enjoyed her style of teaching because was very useful, in areas such as listening activities in class, or learning new vocabulary words. On the other hand, I am having a teacher this semester who is always fighting with us in a good way, with the goal of encourage us to study hard every day. We have been practicing different kind of essay using god topics to keep our attention in class. We have tried to work very fast in the semester to cover as much as possible with respect of the lessons in the book. We have studied new vocabulary words, different form of words, and different kind of essay.\n",
      "\n",
      "Second, both teachers have different personalities in their styles of teaching. My teacher of last semester had a style of class very serious, where she explained all her class and students keep sitting, and listen to her carefully. With this teacher we had a system of work very strict, which consisted in listen to the theory, and then we did the practice. On the other hand, my current teacher has a style of teaching very interesting, which consist in different activities during the class. We have played games to figure out vocabulary words, also we have played games in team to practice different strategies of English.  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for x in book_pelic.text:\n",
    "    print(\"book_pelic:\", index)\n",
    "    print(getArticles(myre, x))\n",
    "    print(x)\n",
    "    print()\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A quick look: 'book' in the PELIC sources\n",
    "\n",
    "##### Indexes 0 - 2: Arabic L1 \n",
    "###### 0: Arabic L1, Level 3\n",
    "In regards to using 'book', this writer tends to use the plural 'books' (three times) and (correctly) uses the zero () article in front of these forms. If only accounting for the plural form of 'books', it would appear this writer has perfect acquisition of article usage with plural count nouns. However, taking a glance at some of the other nouns of this type in the passage, we can see that's simply not true (e.g., 'I learned __the__ crepes, many kinds of __the__ nut cakes'). This could, possibly, be due to an effect from the L1 -- Arabic does use the definite article 'al' in front of plural nominal forms.\n",
    "\n",
    "As I mentioned at the beginning of this notebook, I think it will be more informative to look at nouns and article usage in passages overall instead of just at target nouns. But I will continue this small look into the usage of articles for this target.\n",
    "\n",
    "Forms: (expected, produced) \n",
    "- plural form 'books': (, )\n",
    "- plural form 'books': (, )\n",
    "- plural form 'books': (, )\n",
    "\n",
    "###### 1: Arabic L1, Level 4\n",
    "This writer uses the  article for a first-mention post-modified noun ('I like  book called The Last Lecture'). Normally, post-modified singular count nouns would take 'the', but because it is a first-mention, I would argue that this is an error with the indefinite article 'a/an'. \n",
    "\n",
    "Forms: (expected, produced)\n",
    "- first-mention singular 'book': (a, )\n",
    "\n",
    "###### 2: Arabic L1, Level 5\n",
    "Like the first writer, this writer used the plural form of 'book' ('Studying English in my country has materials and books'). We are not concerned with the lexical error in verb choice -- the plural form 'books' (and 'materials') is used, which warrants the use of the zero article, so the writer is correct in their usage. Overall, this writer seems to use the zero article correctly with the plural form of nouns.\n",
    "\n",
    "Forms: (expected, produced)\n",
    "- plural form 'books': (, )\n",
    "\n",
    "##### Indexes 3 - 5: Korean L1 \n",
    "###### 3: Korean L1, Level 3\n",
    "Many of the uses of 'book' here are actually a splitting of a nominal form ('book chest' instead of 'bookcase'). The use of articles in front of plural forms is generally as expected (zero article), but at times inconsistent in front of singular forms of count nouns (e.g., 'As you enter the door through the entrance, desk is in front of you.') \n",
    "\n",
    "I definitely think it will be more interesting to compare articles at large rather than looking at specific target nouns.\n",
    "\n",
    "Forms: (expected, produced)\n",
    "- Irrelevant for target\n",
    "\n",
    "###### 4: Korean L1, Level 4\n",
    "The tagging is obviously not perfect in my `getArticles` function -- it incorrectly tagged 'The book' as zero instead of definite, I'm assuming since 'the' is capitalized. It didn't catch the first mention of 'book' in the previous sentence, due to misspelling ('But he used bool source.')\n",
    "\n",
    "Second-mention book correctly uses 'the', but the writer misses the first-mention indefinite in the previous sentence.\n",
    "\n",
    "Forms: (expected, produced)\n",
    "- First mention singular count: (a, )\n",
    "- Subsequent mention singular count: (the, the)\n",
    "\n",
    "###### 5: Korean L1, Level 5\n",
    "Overall, this writer seems to have a good grasp on first-mention article usage, which expects the usage of 'a' or 'an'. \n",
    "\n",
    "Forms: (expected, produced)\n",
    "- First mention singular count: (a, a)\n",
    "\n",
    "##### Indexes 6 - 8: Spanish L1 \n",
    "###### 6: Spanish L1, Level 3\n",
    "Like the first Korean writer, this 'book' is actually not a lone, nominal form ('bookshops'). Overall, this speaker seems to have a handle on the zero article in front of plural nominal forms, but article usage in front of singular nouns seems it may be inconsitent.\n",
    "\n",
    "Forms: (expected, produced)\n",
    "- Irrelevant for target\n",
    "\n",
    "###### 7: Spanish L1, Level 4\n",
    "In this essay, the writer correctly uses the plural form of 'books' with the zero article. In some cases, it seems there may be some issues with the over-usage of the definite article in front of singular nouns where it is not warranted (e.g., 'the proficiency in English', 'the English').\n",
    "\n",
    "Forms: (expected, produced)\n",
    "- plural form 'books': (, )\n",
    "\n",
    "###### 8: Spanish L1, Level 5\n",
    "In the phrase 'lessons in the book', 'the' is used before the target. I would argue this seems to be used in a sense where the book being talked about is _shared knowledge_, since this seems to be discussing whatever book is used in this class.\n",
    "\n",
    "The writer seems to have a grasp of zero article in front of plural nouns. That being said, there are a few times throughout the essay where a zero article is used in front of a singular count noun that should actually be pluralized (e.g., 'we have played  games in  team', 'different  form of  words'). \n",
    "\n",
    "Forms: (expected, produced)\n",
    "- Shared knowledge: (the, the)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Level</th>\n",
       "      <th>Original_Text</th>\n",
       "      <th>Normalized_Essay</th>\n",
       "      <th>Revised_Essay</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_count</th>\n",
       "      <th>TTR</th>\n",
       "      <th>Guiraud</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>targ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>200611403</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200611403\\n\\n\\n\\nLast summer ho...</td>\n",
       "      <td>Last summer holiday iam going with my family t...</td>\n",
       "      <td>Last summer holiday iam going with my family t...</td>\n",
       "      <td>['Last', 'summer', 'holiday', 'iam', 'going', ...</td>\n",
       "      <td>82</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>4.858987</td>\n",
       "      <td>[(Last, 'JJ'), (summer, 'NN'), (holiday, 'NN')...</td>\n",
       "      <td>['last', 'summer', 'holiday', 'iam', 'go', 'wi...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>200608092</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200608092\\n\\n\\n\\nI have just ha...</td>\n",
       "      <td>I have just had the perfect holidy. In my holi...</td>\n",
       "      <td>I have just had the perfect holidy. In my holi...</td>\n",
       "      <td>['I', 'have', 'just', 'had', 'the', 'perfect',...</td>\n",
       "      <td>188</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>6.126330</td>\n",
       "      <td>[(I, 'PRP'), (have, 'VBP'), (just, 'RB'), (had...</td>\n",
       "      <td>['-PRON-', 'have', 'just', 'have', 'the', 'per...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>200603618</td>\n",
       "      <td>5</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 5 200603618\\n\\n\\n\\nIn the summer ...</td>\n",
       "      <td>In the summer holiday my family dicides to spe...</td>\n",
       "      <td>In the summer holiday my family dicides to spe...</td>\n",
       "      <td>['In', 'the', 'summer', 'holiday', 'my', 'fami...</td>\n",
       "      <td>215</td>\n",
       "      <td>0.460465</td>\n",
       "      <td>6.751744</td>\n",
       "      <td>[(In, 'IN'), (the, 'DT'), (summer, 'NN'), (hol...</td>\n",
       "      <td>['in', 'the', 'summer', 'holiday', '-PRON-', '...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>200607320</td>\n",
       "      <td>6</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 6 200607320\\n\\n\\n\\nThere have bee...</td>\n",
       "      <td>There have been many films reteased lately, So...</td>\n",
       "      <td>There have been many films reteased lately, So...</td>\n",
       "      <td>['There', 'have', 'been', 'many', 'films', 're...</td>\n",
       "      <td>234</td>\n",
       "      <td>0.598291</td>\n",
       "      <td>9.152086</td>\n",
       "      <td>[(There, 'EX'), (have, 'VBP'), (been, 'VBN'), ...</td>\n",
       "      <td>['there', 'have', 'be', 'many', 'film', 'retea...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0   Filename  Level  \\\n",
       "0        0  200611403      3   \n",
       "1        1  200608092      4   \n",
       "2        2  200603618      5   \n",
       "3        3  200607320      6   \n",
       "\n",
       "                                       Original_Text  \\\n",
       "0  \\t\\t\\t\\tCEPA 3 200611403\\n\\n\\n\\nLast summer ho...   \n",
       "1  \\t\\t\\t\\tCEPA 4 200608092\\n\\n\\n\\nI have just ha...   \n",
       "2  \\t\\t\\t\\tCEPA 5 200603618\\n\\n\\n\\nIn the summer ...   \n",
       "3  \\t\\t\\t\\tCEPA 6 200607320\\n\\n\\n\\nThere have bee...   \n",
       "\n",
       "                                    Normalized_Essay  \\\n",
       "0  Last summer holiday iam going with my family t...   \n",
       "1  I have just had the perfect holidy. In my holi...   \n",
       "2  In the summer holiday my family dicides to spe...   \n",
       "3  There have been many films reteased lately, So...   \n",
       "\n",
       "                                       Revised_Essay  \\\n",
       "0  Last summer holiday iam going with my family t...   \n",
       "1  I have just had the perfect holidy. In my holi...   \n",
       "2  In the summer holiday my family dicides to spe...   \n",
       "3  There have been many films reteased lately, So...   \n",
       "\n",
       "                                              tokens  token_count       TTR  \\\n",
       "0  ['Last', 'summer', 'holiday', 'iam', 'going', ...           82  0.536585   \n",
       "1  ['I', 'have', 'just', 'had', 'the', 'perfect',...          188  0.446809   \n",
       "2  ['In', 'the', 'summer', 'holiday', 'my', 'fami...          215  0.460465   \n",
       "3  ['There', 'have', 'been', 'many', 'films', 're...          234  0.598291   \n",
       "\n",
       "    Guiraud                                                pos  \\\n",
       "0  4.858987  [(Last, 'JJ'), (summer, 'NN'), (holiday, 'NN')...   \n",
       "1  6.126330  [(I, 'PRP'), (have, 'VBP'), (just, 'RB'), (had...   \n",
       "2  6.751744  [(In, 'IN'), (the, 'DT'), (summer, 'NN'), (hol...   \n",
       "3  9.152086  [(There, 'EX'), (have, 'VBP'), (been, 'VBN'), ...   \n",
       "\n",
       "                                              lemmas  targ  \n",
       "0  ['last', 'summer', 'holiday', 'iam', 'go', 'wi...  book  \n",
       "1  ['-PRON-', 'have', 'just', 'have', 'the', 'per...  book  \n",
       "2  ['in', 'the', 'summer', 'holiday', '-PRON-', '...  book  \n",
       "3  ['there', 'have', 'be', 'many', 'film', 'retea...  book  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_balc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_balc: 0\n",
      "[(('wooke in the booke', 'in '), 'the')]\n",
      "Last summer holiday iam going with my family to perfect weekend. we going to the India. We going to wooke in the booke and go to shopping. And we will go to see Tag Mhale. It was so wonderful. cause it have a nice people and a nice shope. After I finsed in India iam going to Hangare with my family. we spend in Loxx. And iam plaing football and going to swam.\n",
      "\n",
      "book_balc: 1\n",
      "[(('friend reading some Bookes', 'reading '), 'other')]\n",
      "I have just had the perfect holidy. In my holiday I went to dubai, Abu dabi, Sharjah Al-Ain and Fujirah I went there places with my family and my friends. I went the cinama and watched nice movies with my friends, I went malls I buys clothes and play some time with sisters and brothers for example went the sea with my family I just had a wonderfor time I swam in the sea and play with my father and sisters football. I'm very happy becouse I have nice holiday. In a some time I went net coffe set in a nel and drank some coffe or juce. On day in aholiday I went the my friends house she wented your friend reading some Bookes, magazims, and stores the mother my friend set and to took for a what's to do in holiday she gived nice idea. open the eyes and close the eyes and the butiful holidy finishd The holiday is wonderful becouse I went many places with my family and my friends.\n",
      "\n",
      "book_balc: 2\n",
      "[(('newspaper or story book', 'or '), '0')]\n",
      "In the summer holiday my family dicides to spend our holiday in Japan , so I prepared my self to spend 2 week there. When I reached Japan ,I feel so intresting when I saw Japanese child wearing traditional dress(keymono) and playing with water. The weather there was so nice . We stay in small house made of wood and there was a cute family from Japan living with us. They was so kind with us. They took us to have a nice Jeirney in the city. When I reached the city I been shocked when I saw people every where. there holding magazine or newspaper or story book, every where on the bus, in the street on the park every where, every where they Just read and work all the time. They really had diffrent life. When our Jeirney finished in the city .they took us to Japanese hotel where I eat a deliscious food. Really I spend intresting time in Japan I learned some Japanese word and I learned about there culture and tradition, and I learned how to manage my time. Really it was a nice and perfect holiday I have ever spend.\n",
      "\n",
      "book_balc: 3\n",
      "[(('t judde a book', 'judde '), 'a/an')]\n",
      "There have been many films reteased lately, Some were good and others were awful.. but there's always that little group of films that shine through the rest, films that are so good that you don't mind watching them a second time. The film that I enjoyed the most was based on and named after the classic novel \"Pride and Prejudice\" It stars Keira Knightley who's one of my favourite actresses. The story is about how important first impressions are and how they effect the way aperson is seen. This happened when Elizabeth bennet overhears Mr.Darsey , Arich gentleman complaing to his friend about the party they were attending and how he thought that Elizabeth was not pretty and called her plain. After that Elizabeth thinks of Mr. Darsey as an arrogant man and doesn't want anything to do with him, She also refuses his marrige proposal because of her pride, And it takes many incedents and some time before she realises that she had fallen in love with him and the film ends with her accepting his proposal.. I enjoyed this film because of the great story, the wonderful scenery and because it can be seen in the real world , last but not least I learnt that we shouldn't judde a book by it's cover .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for x in book_balc.Revised_Essay:\n",
    "    print(\"book_balc:\", index)\n",
    "    print(getArticles(myre, x))\n",
    "    print(x)\n",
    "    print()\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A quick look: 'book' in the BALC sources\n",
    "\n",
    "###### 0: Arabic L1, Level 3\n",
    "There are, unsurprisingly, a lot of orthographic mistakes in this essay. Arabic speakers are well-known to make orthographic mistakes in writing, and all of the CEPA essays are hand-written.\n",
    "\n",
    "The phrase tagged was 'wooke in the booke' and is tagged as definite. If this phrase is supposed to be 'walk in the park', this would be a correct usage of the definite. However, this seems like a bit of a stretch. If it is something like 'looke in (at?) the booke and go to shopping' (there is some contextual sense here), than this would be an error in production.\n",
    "\n",
    "There are some interesting article usages in this essay, such as inconsistent usae of 'the India' and ' India' (compare with the Arabic term for India, 'al-Hind', which uses the definite article 'al').\n",
    "\n",
    "Forms: (expected, produced)\n",
    "- wooke in the booke (I'm not entirely sure what this is supposed to actually be): (?, the)\n",
    "\n",
    "###### 1: Arabic L1, Level 4\n",
    "This instance of 'book' is plural and uses a quantifier 'some', which is correct usage. I am more interested in article usage rather than quantifiers, but it may be useful to examine them (at least if they are correctly in place of the zero article in front of plural forms). For example, the writer previously used both the indefinite article and some in front of 'time' ('In a some time').\n",
    "\n",
    "Forms: (expected, produced)\n",
    "- plural count 'book(e)s': ( or quantifier, quantifier 'some')\n",
    "\n",
    "###### 2: Arabic L1, Level 5\n",
    "So this phrase ('holding magazine or newspaper or story book') has the production of the zero article in front of the singular count noun form ('book') but has the sense of plurality ('books'). However, I have a decision here to make: if I take the error to be an error in article production based on the nominal form, the error is that the zero article is used instead of the indefinite article 'a'; if I take the error here to be in the absence of plural '-s' on books, than the correct article was used (). \n",
    "\n",
    "There are some other interesting article usages in this essay as well, such as 'took us to  Japanese hotel' (use of  where 'a' is expected) and 'a deliscious food' (misuse of a instead of ).\n",
    "\n",
    "Forms: (expected, produced)\n",
    "- TBD: \n",
    "    - If the error is considered to be the absence of plural '-s' on 'book', then: (, )\n",
    "    - If the error is considered to be the absence of indefinite in front of singular 'book', then: (a, )\n",
    "\n",
    "###### 3: Arabic L1, Level 6\n",
    "This actually has a common idiom in English, 'don't judge a book by its cover'. They used it correctly, both in form (ignoring orthography) and in meaning. \n",
    "\n",
    "There are many instances of articles in this essay, and for the most part, they seem to be used correctly. There's a variety of different uses (first mention, post-modification, etc.), so I think it would be interesting to examine these uses at a larger range than I am currently doing.\n",
    "\n",
    "Forms: (expected, produced)\n",
    "- 'don't judge a book by its cover': (a, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass nouns\n",
    "In this section, I'll take a look at the targets that are mass (non-count) nouns:\n",
    "- time\n",
    "- sea\n",
    "- food\n",
    "- water\n",
    "- money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>counts_cepa</th>\n",
       "      <th>counts_pelic</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>time</td>\n",
       "      <td>984</td>\n",
       "      <td>3595.0</td>\n",
       "      <td>mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>sea</td>\n",
       "      <td>301</td>\n",
       "      <td>285.0</td>\n",
       "      <td>mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>food</td>\n",
       "      <td>267</td>\n",
       "      <td>3829.0</td>\n",
       "      <td>mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>water</td>\n",
       "      <td>125</td>\n",
       "      <td>583.0</td>\n",
       "      <td>mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>money</td>\n",
       "      <td>58</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>mass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lemma  counts_cepa  counts_pelic  type\n",
       "27    time          984        3595.0  mass\n",
       "103    sea          301         285.0  mass\n",
       "117   food          267        3829.0  mass\n",
       "189  water          125         583.0  mass\n",
       "321  money           58        1585.0  mass"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[targets.type == 'mass']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'Food'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "myre = re.compile(r'((\\w+ ){,2}\\w+ food.*?\\b)', re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_pelic = pelic[pelic.targ == 'food']\n",
    "food_balc = balc[balc.targ == 'food']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>class_code</th>\n",
       "      <th>level_id</th>\n",
       "      <th>native_language</th>\n",
       "      <th>version</th>\n",
       "      <th>toks_re</th>\n",
       "      <th>toks_re_len</th>\n",
       "      <th>toks_nltk</th>\n",
       "      <th>Guiraud</th>\n",
       "      <th>targ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27578</td>\n",
       "      <td>3671</td>\n",
       "      <td>bn7</td>\n",
       "      <td>63276</td>\n",
       "      <td>Saudi Arabia and the United states have ma...</td>\n",
       "      <td>w</td>\n",
       "      <td>3</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>1</td>\n",
       "      <td>['saudi', 'arabia', 'and', 'the', 'united', 's...</td>\n",
       "      <td>225</td>\n",
       "      <td>['Saudi', 'Arabia', 'and', 'the', 'United', 's...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18412</td>\n",
       "      <td>2527</td>\n",
       "      <td>du8</td>\n",
       "      <td>40115</td>\n",
       "      <td>My favorite place to eat lunch in Okland is my...</td>\n",
       "      <td>w</td>\n",
       "      <td>4</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>1</td>\n",
       "      <td>['my', 'favorite', 'place', 'to', 'eat', 'lunc...</td>\n",
       "      <td>150</td>\n",
       "      <td>['My', 'favorite', 'place', 'to', 'eat', 'lunc...</td>\n",
       "      <td>6.368673</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>43068</td>\n",
       "      <td>5492</td>\n",
       "      <td>cu1</td>\n",
       "      <td>89640</td>\n",
       "      <td>1. Writing some of the Western world's greates...</td>\n",
       "      <td>w</td>\n",
       "      <td>5</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>1</td>\n",
       "      <td>['writing', 'some', 'of', 'the', 'western', 'w...</td>\n",
       "      <td>143</td>\n",
       "      <td>['1', '.', 'Writing', 'some', 'of', 'the', 'We...</td>\n",
       "      <td>9.616783</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14646</td>\n",
       "      <td>2106</td>\n",
       "      <td>ea4</td>\n",
       "      <td>34099</td>\n",
       "      <td>\\nI have a lovely sister who works at ...</td>\n",
       "      <td>w</td>\n",
       "      <td>3</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1</td>\n",
       "      <td>['i', 'have', 'a', 'lovely', 'sister', 'who', ...</td>\n",
       "      <td>330</td>\n",
       "      <td>['I', 'have', 'a', 'lovely', 'sister', 'who', ...</td>\n",
       "      <td>9.358192</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19387</td>\n",
       "      <td>2634</td>\n",
       "      <td>gz2</td>\n",
       "      <td>43185</td>\n",
       "      <td>The best way to solve Higgins' problem is to c...</td>\n",
       "      <td>w</td>\n",
       "      <td>4</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'best', 'way', 'to', 'solve', 'higgins...</td>\n",
       "      <td>183</td>\n",
       "      <td>['The', 'best', 'way', 'to', 'solve', 'Higgins...</td>\n",
       "      <td>6.579069</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2514</td>\n",
       "      <td>276</td>\n",
       "      <td>hb4</td>\n",
       "      <td>15360</td>\n",
       "      <td>When I visited my relative's house in N.J, I m...</td>\n",
       "      <td>w</td>\n",
       "      <td>5</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1</td>\n",
       "      <td>['when', 'i', 'visited', 'my', 'relative', 's'...</td>\n",
       "      <td>187</td>\n",
       "      <td>['When', 'I', 'visited', 'my', 'relative', \"'s...</td>\n",
       "      <td>7.385851</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>19745</td>\n",
       "      <td>2666</td>\n",
       "      <td>fe7</td>\n",
       "      <td>44199</td>\n",
       "      <td>Both \"Mc Donald's\" and \"Wendy's\" are restauran...</td>\n",
       "      <td>w</td>\n",
       "      <td>3</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>1</td>\n",
       "      <td>['both', 'mc', 'donald', 's', 'and', 'wendy', ...</td>\n",
       "      <td>98</td>\n",
       "      <td>['Both', '``', 'Mc', 'Donald', \"'s\", \"''\", 'an...</td>\n",
       "      <td>5.151778</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1856</td>\n",
       "      <td>186</td>\n",
       "      <td>gq4</td>\n",
       "      <td>13092</td>\n",
       "      <td>It's an excellent movie, I think it was a good...</td>\n",
       "      <td>w</td>\n",
       "      <td>4</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>1</td>\n",
       "      <td>['it', 's', 'an', 'excellent', 'movie', 'i', '...</td>\n",
       "      <td>80</td>\n",
       "      <td>['It', \"'s\", 'an', 'excellent', 'movie', ',', ...</td>\n",
       "      <td>6.484597</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26033</td>\n",
       "      <td>3426</td>\n",
       "      <td>df4</td>\n",
       "      <td>60529</td>\n",
       "      <td>Adavantages and Disavantages of Both Single an...</td>\n",
       "      <td>w</td>\n",
       "      <td>5</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>1</td>\n",
       "      <td>['adavantages', 'and', 'disavantages', 'of', '...</td>\n",
       "      <td>372</td>\n",
       "      <td>['Adavantages', 'and', 'Disavantages', 'of', '...</td>\n",
       "      <td>7.569747</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    answer_id  question_id anon_id  user_file_id  \\\n",
       "9       27578         3671     bn7         63276   \n",
       "10      18412         2527     du8         40115   \n",
       "11      43068         5492     cu1         89640   \n",
       "12      14646         2106     ea4         34099   \n",
       "13      19387         2634     gz2         43185   \n",
       "14       2514          276     hb4         15360   \n",
       "15      19745         2666     fe7         44199   \n",
       "16       1856          186     gq4         13092   \n",
       "17      26033         3426     df4         60529   \n",
       "\n",
       "                                                 text class_code  level_id  \\\n",
       "9       Saudi Arabia and the United states have ma...          w         3   \n",
       "10  My favorite place to eat lunch in Okland is my...          w         4   \n",
       "11  1. Writing some of the Western world's greates...          w         5   \n",
       "12          \\nI have a lovely sister who works at ...          w         3   \n",
       "13  The best way to solve Higgins' problem is to c...          w         4   \n",
       "14  When I visited my relative's house in N.J, I m...          w         5   \n",
       "15  Both \"Mc Donald's\" and \"Wendy's\" are restauran...          w         3   \n",
       "16  It's an excellent movie, I think it was a good...          w         4   \n",
       "17  Adavantages and Disavantages of Both Single an...          w         5   \n",
       "\n",
       "   native_language  version  \\\n",
       "9           Arabic        1   \n",
       "10          Arabic        1   \n",
       "11          Arabic        1   \n",
       "12          Korean        1   \n",
       "13          Korean        1   \n",
       "14          Korean        1   \n",
       "15         Spanish        1   \n",
       "16         Spanish        1   \n",
       "17         Spanish        1   \n",
       "\n",
       "                                              toks_re  toks_re_len  \\\n",
       "9   ['saudi', 'arabia', 'and', 'the', 'united', 's...          225   \n",
       "10  ['my', 'favorite', 'place', 'to', 'eat', 'lunc...          150   \n",
       "11  ['writing', 'some', 'of', 'the', 'western', 'w...          143   \n",
       "12  ['i', 'have', 'a', 'lovely', 'sister', 'who', ...          330   \n",
       "13  ['the', 'best', 'way', 'to', 'solve', 'higgins...          183   \n",
       "14  ['when', 'i', 'visited', 'my', 'relative', 's'...          187   \n",
       "15  ['both', 'mc', 'donald', 's', 'and', 'wendy', ...           98   \n",
       "16  ['it', 's', 'an', 'excellent', 'movie', 'i', '...           80   \n",
       "17  ['adavantages', 'and', 'disavantages', 'of', '...          372   \n",
       "\n",
       "                                            toks_nltk   Guiraud  targ  \n",
       "9   ['Saudi', 'Arabia', 'and', 'the', 'United', 's...  7.000000  food  \n",
       "10  ['My', 'favorite', 'place', 'to', 'eat', 'lunc...  6.368673  food  \n",
       "11  ['1', '.', 'Writing', 'some', 'of', 'the', 'We...  9.616783  food  \n",
       "12  ['I', 'have', 'a', 'lovely', 'sister', 'who', ...  9.358192  food  \n",
       "13  ['The', 'best', 'way', 'to', 'solve', 'Higgins...  6.579069  food  \n",
       "14  ['When', 'I', 'visited', 'my', 'relative', \"'s...  7.385851  food  \n",
       "15  ['Both', '``', 'Mc', 'Donald', \"'s\", \"''\", 'an...  5.151778  food  \n",
       "16  ['It', \"'s\", 'an', 'excellent', 'movie', ',', ...  6.484597  food  \n",
       "17  ['Adavantages', 'and', 'Disavantages', 'of', '...  7.569747  food  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_pelic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food_pelic: 0\n",
      "[(('many dishes of foods', 'dishes '), 'other'), (('Arabia has traditional food', 'has '), '0'), (('the traditional food', 'the '), 'the'), (('use the convenient foods', 'the '), 'the'), (('convenient food is food', 'food '), '0'), (('of the convenient foods', 'the '), 'the'), (('in Preparation of food', 'Preparation '), '0'), (('uses less convenient foods', 'less '), '0'), (('to eat convenient foods', 'eat '), '0'), (('and prepared the foodm', 'prepared '), 'the'), (('between preparation of food', 'preparation '), '0'), (('is put into food', 'put '), '0'), (('American food', ''), '0'), (('Saudi food', ''), '0'), (('has form of food', 'form '), '0'), (('for his traditional food', 'his '), 'other')]\n",
      "    Saudi Arabia and the United states have many dishes of foods to eat it. First of all,Saudi\n",
      "Arabia has traditional food so is America.For example,the traditional food in Saudi Arabia is\n",
      "Kapssh. Kapssh is consist of meat and rice.It is popular dish in Saudi Arabia. American traditional\n",
      "food is Hamburger. It is contain beef , chicken, salad and bagel.Both Saudi Arabia and the United\n",
      "States use the convenient foods.convenient food is food that is partly or completely prepared already.It is bought in supermarket. There are many kind of the convenient foods.For example, fish and chicken.\n",
      "\n",
      "\n",
      "      Saudi Arabia is different than the United States in Preparation of food. First of all,Saudi Arabia uses less convenient foods than the United States because the Saudi citizens used to cook.On the other hand,American people used to eat convenient foods.In fact, American sometimes cooks and prepared the foodm,but there are differents between preparation of food in these countries. The most important thing is spice. The spice is a powder or seed taken from plants that is put into food to give it special taste.Although, American food is unpleasant,Saudi food is delisious.\n",
      "\n",
      "\n",
      "     Eventually, any man has form of food like it.Therefore, You cannot change the way of the person or the way for his traditional food.\n",
      "\n",
      "\n",
      "food_pelic: 1\n",
      "[(('eat our traditional food', 'our '), 'other'), (('types of Libyan food', 'of '), '0'), (('of Libyan traditional foods', 'Libyan '), '0')]\n",
      "My favorite place to eat lunch in Okland is my house, where I don't like eating in the restaurant.\n",
      "I enjoy eating in my house, because it is the place where I can eat our traditional food. In my house I live with my friends and we prepare all types of Libyan food such as , bazine, cuscus, rushda and asida which is not available in Okland restaurants. In my house with my friends we feel free to eat by any way we want, because some of Libyan traditional foods need special way to eat (eg: bazin need to be eaten in group and by hands which I cant do it at resrurance).  When I have arrived to Okland I ate lunch in three different restaurants, but I did not enjoy eating at any of them.\n",
      "So, for me my house is the best place to eat lunch in Okland.\n",
      "\n",
      "\n",
      "food_pelic: 2\n",
      "[(('used in many food', 'in '), 'other')]\n",
      "1. Writing some of the Western world's greatest music, Beethoven became totally deaf in mid-life.\n",
      "2. Chemicals are used in many food products that will stay fresher longer.\n",
      "3. The Ancient Peru exhibit, which was held over for two weeks, was popular.\n",
      "4. The West Coast suffered a severe drought, in contrast, The East Coast had heavy rainfall.\n",
      "5. While John Fish lectured, he showed us a slide which diagrammed the double helix structure of DNA.\n",
      "6. First National Bank, whose president is a woman, tries to attract female customers. \n",
      "7. Being the oldest son, I am responsible for taking care of my parents.\n",
      "8. Having finished, the performers left the stage.\n",
      "9. He enrolled in an advanced calculus class, founding it too difficult, he dropped it.\n",
      "10. The analysts worked many hours on the computer program, not finding the cause of the problem, they gave up, and they went home.\n",
      "\n",
      "food_pelic: 3\n",
      "[(('inch on that food', 'on '), 'other')]\n",
      "        \n",
      "I have a lovely sister who works at a bank in Korea. She is two years younger than me, but she is as tall as me. Of course, she is lighter than I am in weight. Then, she looks younger than her real age; I think it is because of the history of our family. Actually, all of my family members, including me, have young faces. Next, she has splendid, long black hair. Also, she often likes to change her hair style. So, she sometimes has big wavy long hair, or sometimes she has straight long hair. In addition, she has big eyes and double-edged eyelids, unlike me. Moreover, she has bright skin color and a good smile. Therefore, people who have ever seen her think that she is feminine and benevolent.\n",
      "However, I know that she is not as affectionate as her appearance. First of all, she is selfish and doesn't take a conciliatory attitude to me. Especially, she yields an inch on that food, so we sometimes squabble. Once, someone came to my home with Haagen Dazs Vanila ice cream, and we put it in our refrigerator. At that time, I had no time to eat it because I had to go out to finish something. I was only thinking of the ice cream while I went out. However, I didn't eat it because my sister ate it all. I was really angry and asked for her about it. Then, she said, \"Why didn't you eat it before I eat it?\". On the contrary, she sometimes makes me laugh because she mishears what I say. Once, I asked her, \"Do you try the cheese snack?\", but she misheard me. She heard \"employment\" instead of \"cheese snack\", \"employment\" is pronounced as 'chui jik' in Korean. Also, Such things are a daily event. Finally, I wish she would conduct in her appearance. Then, I think that she can be more lovely woman than what she is. \n",
      "\n",
      "\n",
      "\n",
      "food_pelic: 4\n",
      "[(('offered bad quality foods', 'bad '), '0'), (('the foods', ''), 'the'), (('should drop the foods', 'drop '), 'the'), (('and good quality foods', 'good '), '0')]\n",
      "The best way to solve Higgins' problem is to cooperate with business partners.  He has some problems that are associated with money.  These are his problems he didn't do much advertising and offered bad quality foods to customer due to not enough money.  Also, the foods' price is expensive to students.  He should be guaranteed finance to solve the problems.  If he cooperates with others, Higgins and his business partners have to distribute a profit. However, the business partners can solve his financial problem.  If he has enough finance, he should hire a professional chief because the most important thing is tastes in a restaurant.   Also, he should drop the foods' price.  This is because his restaurant is located at Benson University so his main customers are students in the university.  The lower prices and good tastes are very important to students in their lunch time. Then, many students will prefer to go Higgins' restaurant in their lunch time due to the lower price and good quality foods.  Therefore, he will be great success in his business with his partners without advertising. \n",
      "\n",
      "food_pelic: 5\n",
      "[(('presents and chose food', 'and '), '0'), (('pasta and other foods', 'and '), 'the')]\n",
      "When I visited my relative's house in N.J, I made a great dinner for them with my other cousins. I visited their house on my vacation because of N.Y trip. I visited there for free so that I could save my money. After New year's day, I felt very thankful for them. The day before yesterday that we took the day for party, I and other cousins planed on making great dinner for them. First, we made a plan for the dinner. We bought presents and chose food. We decided to make pasta and other simple things. Second, we search recipe of pasta and bought ingredients and cake for party. Then, we cooked our pasta and other foods for two hours. It was our first time to cook pasta, so we had many troubles about it. However, it was good memory for us. Finally, aunt and uncle came home and we had very great time. Although we made many mistakes and disarranged kitchen, the atmosphere was full of happiness. And of course, we cleaned all the dirty things that we made in process.\n",
      "\n",
      "food_pelic: 6\n",
      "[(('that sell fast food', 'sell '), 'other'), (('restaurants have similar food', 'have '), '0'), (('a great fast food', 'great '), 'a/an')]\n",
      "Both \"Mc Donald's\" and \"Wendy's\" are restaurants that sell fast food. First of all, Mc Donald's is as delicious as Wendy's. Next, Wendy's is famous around the U.S. and so is Mc Donald's. Both restaurants have similar food and both restaurants are very common. Then both \"Mc Donald's\" and \"Wendy's\" prepare very special hamburgers. Finally both restaurants are very nice. Come and try their hamburgers, then you can choose which one is special for you and know why I said that. The two restaurants serve a great fast food.  \n",
      "\n",
      "food_pelic: 7\n",
      "[(('s food', ''), '0')]\n",
      "It's an excellent movie, I think it was a good job to make aware people in all the world who consume Mc Donald's food regularly. It' s a bad diet of sugar, high fat, calories and carbs.\n",
      "\n",
      " I think that the best message that the film had for us was that Mc Donald's Company doesn't care about our health, the only think that they want is to sell their products and win more and more money.\n",
      "\n",
      "food_pelic: 8\n",
      "[(('for buying food', 'for '), '0')]\n",
      "Adavantages and Disavantages of Both Single and Maried People\n",
      "\n",
      "\n",
      "Many young people desire to get marry  quickly and other married people want to return to their past life. There are many features between single people and married people. These features are related to the different types of responsabilities, friends, education, children, properties, stability, travel, time, space, clothes, freedom, etc. There are many comparasion and contrasts between single people and married people.\n",
      "\n",
      "First, the responsabilities of the married people are very different from single people. Maried people must work to support their children, for paying all the checks, for buying food, for paying all the needs of their children such as education, healthy insuarance, recreation, clothes, vaccins, etc. Generally, the single people don't have children and it makes easier the life of the single people. Basically, they have to dedicate to study in the majority of the cases.\n",
      "\n",
      "Second, the friends of the married people are more affected than the single people due to all couples should share their life, they should share the majority of the activities since they are an unit. Commonly, married people are busier than single people. Then, the married people spend less time with their friends than the single people. Nevetherless, both married people and single people can have the same amount of friends.\n",
      "\n",
      "Third, traveling is not easy for the married people because of their duties. The overheads of the matrimony are higher than the expenses of the single people. Nonetheless, there are many families that plan to travel at least once per year. On the other hand, there are many single people that cannot travel frequently or scarcely they travel close to the cities or town. In addition, married people have more properties than single people due to .they find the stability of the their families.\n",
      "\n",
      "In conclusion, there are many differences in the life of both single people and maried people. Perhaps, the married people have more limitations than the single people because of enourmous responsabilities, However, the married people have more stability than the single people. According to this analysis, both married and single people have cons and pros. Simply, the married's life is a stage very different from single's life.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for x in food_pelic.text:\n",
    "    print(\"food_pelic:\", index)\n",
    "    print(getArticles(myre, x))\n",
    "    print(x)\n",
    "    print()\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A quick look: 'food' in the PELIC sources\n",
    "\n",
    "##### Indexes 0 - 2: Arabic L1 \n",
    "###### 0: Arabic L1, Level 3\n",
    "This contains the phrase 'I smelled the food who (that) my mother cooked'. Although normally food would not take the definite article in this case, because it is post-modified with the phrase 'who (that) my mother cooked', it is required. Therefore, this is an accurate production of the definite article.\n",
    "\n",
    "We see correct usage of zero articles in front of plural nouns, but there is a first-mention error ('it was the stove' instead of 'it was (there was) a stove').\n",
    "\n",
    "Forms: (expected, produced) \n",
    "- post-modified mass noun: (the, the)\n",
    "\n",
    "###### 1: Arabic L1, Level 4\n",
    "The target ('preparing food') is correctly assigned the zero article. \n",
    "\n",
    "Of interesting note is the definite article being used with plurals ('the enegery resources'). Later in the essay, 'how can we live if the oil is gone' is produced, in which 'oil' is used as a mass noun and 'the' is incorrectly used instead of the zero article.\n",
    "\n",
    "Forms: (expected, produced)\n",
    "- mass noun: (, )\n",
    "\n",
    "###### 2: Arabic L1, Level 5\n",
    "One of the uses of 'fast food' is adjectival (modifying 'restaurants'). Otherwise, ' fast food' is correctly produced. The last two uses are post-modified, and thus take 'the'. \n",
    "\n",
    "Of interesting note: the writer consistently uses 'a good health' instead of ' good health', where 'health' is also a mass noun. \n",
    "\n",
    "Forms: (expected, produced)\n",
    "- mass noun: (, )\n",
    "- mass noun: (, )\n",
    "- post-modified: (the, the)\n",
    "- post-modified: (the, the)\n",
    "\n",
    "##### Indexes 3 - 5: Korean L1 \n",
    "###### 3: Korean L1, Level 3\n",
    "This essay has a lot of first-mention and some second-mention, so there are a lot of cases of the indefinite article in this sample. Most of these uses are correct, although there are some errors in which second-mention nouns are still taking the indefinite 'a'. \n",
    "\n",
    "The targeted phrase 'I put all food in a refrigerator', makes me feel weird. This is a case of second-mention taking 'a', which is one issue, but I'm not sure if this should be 'all the food' or not.\n",
    "\n",
    "Forms: (expected, produced)\n",
    "- 'all food': (?, ))\n",
    "\n",
    "###### 4: Korean L1, Level 4\n",
    "Forms: (expected, produced)\n",
    "- 'good quality food': (, )\n",
    "- 'if the food is so terrible': (the, the)\n",
    "- 'provide the good food': (, the)\n",
    "\n",
    "###### 5: Korean L1, Level 5\n",
    "Forms: (expected, produced)\n",
    "- 'and chose food': (, )\n",
    "- 'pasta and other foods': (, )\n",
    "\n",
    "##### Indexes 6 - 8: Spanish L1 \n",
    "###### 6: Spanish L1, Level 3\n",
    "Forms: (expected, produced)\n",
    "- 'eat my favorite food' -- possessive\n",
    "\n",
    "###### 7: Spanish L1, Level 4\n",
    "Forms: (expected, produced)\n",
    "- regex failed because of whitespace, 'ambulances, food or everything that': (, )\n",
    "\n",
    "###### 8: Spanish L1, Level 5\n",
    "Forms: (expected, produced)\n",
    "- 'for buying food': (, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food_balc: 0\n",
      "[(('hotel gived us food', 'gived '), '0'), (('but this food', 'but '), 'other')]\n",
      "Holiday is very important for anyone because the people can rest and have happy time. Also, people travel and do hobbies in holiday time, so this time for anyone important and useful. I traveled with my family last holiday to the India. This was first time for us to travel india. Befor we always traveled to Europe countries where we enjoy very much and had nice time. The wrost holiday for us. It was last because a lot of reasons. Firstly, we stated at normal hotel. The hotel gived us food, but this food was very bad and made us sicks. Also, some times in the hotel. The electirc closed and no water in ther bath. After that we went to the mountains th India. The mountains were very nice and My family became happy to see this natural place but when we went back to the hotel. Thives stold us and took every thing we have it. Then we went back to the home in the UAE and my family was very sad and we wished if we didn't travel to the India. In my ipinion for nay traveler to be carful and choose country which have safe. Also, Isuggest no traveling to the broad because UAE now have a lot of nice places and festivals Specially in Dubai you can find anything you want.\n",
      "\n",
      "food_balc: 1\n",
      "[(('eating a good food', 'a '), 'a/an')]\n",
      "I like to the gardan in the winter becaue the weather is very nice . The trees is green and the flower is very beatiful . I love this places. I go to the gardan when I have a holiday in Friday . I go to the gardan with father , mothe , sister and brother. I went to the gardan by car . The father is driving . When I go to the gardan I playing and raning and I eating a good food, fruit and vegetables because it is a healthy . The area is very big . My brother playing with bicycle and the sister sit up in the mother and father . I alway come in the gardan in the morning not on the night because go in the house early. I'm very happy when you go to the gardan. I like the flower very much . My father and my playing football I like to playing football . And I take the picture with family in the gardan. In the gardan I look the birds the birds is flying and sing. And I took the some animal I look a rabbil and cat . When he was a night I go to the house . I'm very funny and happy the gardan is very beautiful and the weather is very nice . I can to come in the gardan in the holiday.\n",
      "\n",
      "food_balc: 2\n",
      "[(('many things like foods', 'things '), 'other'), (('we enjoy eating Foods', 'enjoy '), '0')]\n",
      "In the last summer holiday, my father decided to take me and my family to beach. My mother got up early and prepared many things like foods, drinks and umberella. My sisters and my brothers feels so happy. In the beach we enjoy eating Foods, ice, meats, sandwich, and drinking cool water. My brothers enjoy swimming and diving in the sea. My sisters interesting in playing football, handball, singing and dancing. My mother help my father to catch fishes. Suddinly my sister Fatima was crying because her hand broke. My father took my small sister to hospitall. My mother was worring and crying After 3 months my sister fatima had been ok and felt happy. Also I can't forget what happing to my sister fatima So I advise all parentes to take care and encourage their children. Finally As Isee we should be more sumpathic, understand an helpful with the children..\n",
      "\n",
      "food_balc: 3\n",
      "[(('liked the eygptian food', 'the '), 'the'), (('famous kinds of food', 'kinds '), '0')]\n",
      "Last summer's vication I went to Eygpt. Eygpt is one of the greatest countries I visited in my whole life. I went with my whole family members. We had a great time due to the fantastic warm weather and off course the great place. People there are so freindly and cheerful although some of them are poor and simple but they always welcome us. In the first day I visited the great Pyramids, they are so huge. And I saw the \"ABU ALHOUL\", and I enjoyed taking pictures there with my family. The resturants there are great too, I liked the eygptian food much. One of their famous kinds of food called \"Kushari\" it consists of rice, tomato souce and some green vegetables. It is dilecous. Going to Eygpt is great idea for having a great summer holidy. I advice every family that havnt visited Eygpt yet to visit it. Am pretty sure that they will have a lot of fun in that amazing place.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for x in food_balc.Revised_Essay:\n",
    "    print(\"food_balc:\", index)\n",
    "    print(getArticles(myre, x))\n",
    "    print(x)\n",
    "    print()\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A quick look: 'food' in the BALC sources\n",
    "\n",
    "###### 0: Arabic L1, Level 3\n",
    "Forms: (expected, produced)\n",
    "- (('hotel gived us food', 'gived '), '0'):  (, )\n",
    "- ('but this food', 'but '), 'other') -- possessive, okay\n",
    "\n",
    "###### 1: Arabic L1, Level 4\n",
    "Forms: (expected, produced)\n",
    "- 'I eating a good food': (, a)\n",
    "\n",
    "###### 2: Arabic L1, Level 5\n",
    "Forms: (expected, produced)\n",
    "- 'many things like foods': (, )\n",
    "- 'enjoy eating Foods': (, )\n",
    "\n",
    "###### 3: Arabic L1, Level 6\n",
    "Forms: (expected, produced)\n",
    "- 'I liked the eygptian food much': (, the)\n",
    "- 'famous kinds of food': (, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I have just had the perfect holidy. In my holiday I went to dubai, Abu dabi, Sharjah Al-Ain and Fujirah I went there places with my family and my friends. I went the cinama and watched nice movies with my friends, I went malls I buys clothes and play some time with sisters and brothers for example went the sea with my family I just had a wonderfor time I swam in the sea and play with my father and sisters football. I'm very happy becouse I have nice holiday. In a some time I went net coffe set in a nel and drank some coffe or juce. On day in aholiday I went the my friends house she wented your friend reading some Bookes, magazims, and stores the mother my friend set and to took for a what's to do in holiday she gived nice idea. open the eyes and close the eyes and the butiful holidy finishd The holiday is wonderful becouse I went many places with my family and my friends.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = balc.Revised_Essay[1]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have just had the perfect holidy. In my holiday I went to dubai, Abu dabi, Sharjah Al-Ain and Fujirah I went there places with my family and my friends. I went the cinama and watched nice movies with my friends, I went malls I buys clothes and play some time with sisters and brothers for example went the sea with my family I just had a wonderfor time I swam in the sea and play with my father and sisters football. I'm very happy becouse I have nice holiday. In a some time I went net coffe set in a nel and drank some coffe or juce. On day in aholiday I went the my friends house she wented your friend reading some Bookes, magazims, and stores the mother my friend set and to took for a what's to do in holiday she gived nice idea. open the eyes and close the eyes and the butiful holidy finishd The holiday is wonderful becouse I went many places with my family and my friends.\n",
      "I PRP\n",
      "have VBP\n",
      "just RB\n",
      "had VBN\n",
      "the DT\n",
      "perfect JJ\n",
      "holidy NN\n",
      ". .\n",
      "In IN\n",
      "my PRP$\n",
      "holiday NN\n",
      "I PRP\n",
      "went VBD\n",
      "to IN\n",
      "dubai NNS\n",
      ", ,\n",
      "Abu NNP\n",
      "dabi NNP\n",
      ", ,\n",
      "Sharjah NNP\n",
      "Al NNP\n",
      "- HYPH\n",
      "Ain NNP\n",
      "and CC\n",
      "Fujirah NNP\n",
      "I PRP\n",
      "went VBD\n",
      "there RB\n",
      "places NNS\n",
      "with IN\n",
      "my PRP$\n",
      "family NN\n",
      "and CC\n",
      "my PRP$\n",
      "friends NNS\n",
      ". .\n",
      "I PRP\n",
      "went VBD\n",
      "the DT\n",
      "cinama NN\n",
      "and CC\n",
      "watched VBD\n",
      "nice JJ\n",
      "movies NNS\n",
      "with IN\n",
      "my PRP$\n",
      "friends NNS\n",
      ", ,\n",
      "I PRP\n",
      "went VBD\n",
      "malls NNS\n",
      "I PRP\n",
      "buys VBZ\n",
      "clothes NNS\n",
      "and CC\n",
      "play VB\n",
      "some DT\n",
      "time NN\n",
      "with IN\n",
      "sisters NNS\n",
      "and CC\n",
      "brothers NNS\n",
      "for IN\n",
      "example NN\n",
      "went VBD\n",
      "the DT\n",
      "sea NN\n",
      "with IN\n",
      "my PRP$\n",
      "family NN\n",
      "I PRP\n",
      "just RB\n",
      "had VBD\n",
      "a DT\n",
      "wonderfor JJ\n",
      "time NN\n",
      "I PRP\n",
      "swam VBP\n",
      "in IN\n",
      "the DT\n",
      "sea NN\n",
      "and CC\n",
      "play VB\n",
      "with IN\n",
      "my PRP$\n",
      "father NN\n",
      "and CC\n",
      "sisters NNS\n",
      "football NN\n",
      ". .\n",
      "I PRP\n",
      "'m VBP\n",
      "very RB\n",
      "happy JJ\n",
      "becouse NN\n",
      "I PRP\n",
      "have VBP\n",
      "nice JJ\n",
      "holiday NN\n",
      ". .\n",
      "In IN\n",
      "a DT\n",
      "some DT\n",
      "time NN\n",
      "I PRP\n",
      "went VBD\n",
      "net JJ\n",
      "coffe NN\n",
      "set VBN\n",
      "in IN\n",
      "a DT\n",
      "nel NN\n",
      "and CC\n",
      "drank VB\n",
      "some DT\n",
      "coffe NN\n",
      "or CC\n",
      "juce NN\n",
      ". .\n",
      "On IN\n",
      "day NN\n",
      "in IN\n",
      "aholiday NN\n",
      "I PRP\n",
      "went VBD\n",
      "the DT\n",
      "my PRP$\n",
      "friends NNS\n",
      "house NN\n",
      "she PRP\n",
      "wented VBD\n",
      "your PRP$\n",
      "friend NN\n",
      "reading VBG\n",
      "some DT\n",
      "Bookes NNPS\n",
      ", ,\n",
      "magazims NNS\n",
      ", ,\n",
      "and CC\n",
      "stores NNS\n",
      "the DT\n",
      "mother NN\n",
      "my PRP$\n",
      "friend NN\n",
      "set VBD\n",
      "and CC\n",
      "to TO\n",
      "took VBD\n",
      "for IN\n",
      "a DT\n",
      "what WP\n",
      "'s VBZ\n",
      "to TO\n",
      "do VB\n",
      "in IN\n",
      "holiday NN\n",
      "she PRP\n",
      "gived VBD\n",
      "nice JJ\n",
      "idea NN\n",
      ". .\n",
      "open VB\n",
      "the DT\n",
      "eyes NNS\n",
      "and CC\n",
      "close VB\n",
      "the DT\n",
      "eyes NNS\n",
      "and CC\n",
      "the DT\n",
      "butiful JJ\n",
      "holidy NN\n",
      "finishd VBZ\n",
      "The DT\n",
      "holiday NN\n",
      "is VBZ\n",
      "wonderful JJ\n",
      "becouse NN\n",
      "I PRP\n",
      "went VBD\n",
      "many JJ\n",
      "places NNS\n",
      "with IN\n",
      "my PRP$\n",
      "family NN\n",
      "and CC\n",
      "my PRP$\n",
      "friends NNS\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "# i want to test something\n",
    "doc = nlp(test)\n",
    "print(doc)\n",
    "for tok in doc:\n",
    "    print(tok.text, tok.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have just had the perfect holidy. In my holiday I went to dubai, Abu dabi, Sharjah Al-Ain and Fujirah I went there places with my family and my friends. I went the cinama and watched nice movies with my friends, I went malls I buys clothes and play some time with sisters and brothers for example went the sea with my family I just had a wonderfor time I swam in the sea and play with my father and sisters football. I'm very happy becouse I have nice holiday. In a some time I went net coffe set in a nel and drank some coffe or juce. On day in aholiday I went the my friends house she wented your friend reading some Bookes, magazims, and stores the mother my friend set and to took for a what's to do in holiday she gived nice idea. open the eyes and close the eyes and the butiful holidy finishd The holiday is wonderful becouse I went many places with my family and my friends.\n",
      "The word is:  holidy\n",
      "What article was used in front of it? the\n",
      "What article should have been used in front of it? the\n",
      "What article rule is the correct usage? superlative\n",
      "The word is:  holiday\n",
      "What article was used in front of it? my\n",
      "What article should have been used in front of it? my\n",
      "What article rule is the correct usage? BrE holiday\n",
      "The word is:  dubai\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? city name\n",
      "The word is:  Abu\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? city name\n",
      "The word is:  dabi\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? city name\n",
      "The word is:  Sharjah\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? city name\n",
      "The word is:  Al\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? city name\n",
      "The word is:  Ain\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? city name\n",
      "The word is:  Fujirah\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? city name\n",
      "The word is:  places\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? plural count\n",
      "The word is:  family\n",
      "What article was used in front of it? my\n",
      "What article should have been used in front of it? my\n",
      "What article rule is the correct usage? possessive\n",
      "The word is:  friends\n",
      "What article was used in front of it? my\n",
      "What article should have been used in front of it? my\n",
      "What article rule is the correct usage? posessive\n",
      "The word is:  cinama\n",
      "What article was used in front of it? the\n",
      "What article should have been used in front of it? construction name\n",
      "What article rule is the correct usage? the\n",
      "The word is:  movies\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? plural count\n",
      "The word is:  friends\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? my\n",
      "What article rule is the correct usage? possessive\n",
      "The word is:  malls\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? the\n",
      "What article rule is the correct usage? plural count\n",
      "The word is:  clothes\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? noncount\n",
      "The word is:  time\n",
      "What article was used in front of it? some\n",
      "What article should have been used in front of it? some\n",
      "What article rule is the correct usage? pre-nominal modifier\n",
      "The word is:  sisters\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? my\n",
      "What article rule is the correct usage? possessive\n",
      "The word is:  brothers\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? coordinating nominals\n",
      "The word is:  example\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? collocation\n",
      "The word is:  sea\n",
      "What article was used in front of it? the\n",
      "What article should have been used in front of it? the\n",
      "What article rule is the correct usage? geographical feature names\n",
      "The word is:  family\n",
      "What article was used in front of it? my\n",
      "What article should have been used in front of it? my\n",
      "What article rule is the correct usage? possessive\n",
      "The word is:  time\n",
      "What article was used in front of it? a\n",
      "What article should have been used in front of it? a\n",
      "What article rule is the correct usage? singular countable\n",
      "The word is:  sea\n",
      "What article was used in front of it? the\n",
      "What article should have been used in front of it? the\n",
      "What article rule is the correct usage? geographical features name\n",
      "The word is:  father\n",
      "What article was used in front of it? my\n",
      "What article should have been used in front of it? my\n",
      "What article rule is the correct usage? possessive\n",
      "The word is:  sisters\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? coordinating nominals\n",
      "The word is:  football\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? noncountable\n",
      "The word is:  becouse\n",
      "What article was used in front of it? because\n",
      "What article should have been used in front of it? because\n",
      "What article rule is the correct usage? incorrect tagging\n",
      "The word is:  holiday\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? a\n",
      "What article rule is the correct usage? singular countable\n",
      "The word is:  time\n",
      "What article was used in front of it? a+some\n",
      "What article should have been used in front of it? some\n",
      "What article rule is the correct usage? noncountable\n",
      "The word is:  coffe\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? noncount\n",
      "The word is:  nel\n",
      "What article was used in front of it? nel\n",
      "What article should have been used in front of it? nel\n",
      "What article rule is the correct usage? not a word\n",
      "The word is:  coffe\n",
      "What article was used in front of it? some\n",
      "What article should have been used in front of it? some\n",
      "What article rule is the correct usage? noncount \n",
      "The word is:  juce\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? coordinating related nominals\n",
      "The word is:  day\n",
      "What article was used in front of it? on(e)\n",
      "What article should have been used in front of it? one\n",
      "What article rule is the correct usage? countable, ordinal\n",
      "The word is:  aholiday\n",
      "What article was used in front of it? a\n",
      "What article should have been used in front of it? the\n",
      "What article rule is the correct usage? second mention\n",
      "The word is:  friends\n",
      "What article was used in front of it? the+my\n",
      "What article should have been used in front of it? my\n",
      "What article rule is the correct usage? possessive\n",
      "The word is:  house\n",
      "What article was used in front of it? 's\n",
      "What article should have been used in front of it? 's\n",
      "What article rule is the correct usage? posessive\n",
      "The word is:  friend\n",
      "What article was used in front of it? your\n",
      "What article should have been used in front of it? your\n",
      "What article rule is the correct usage? posessive\n",
      "The word is:  Bookes\n",
      "What article was used in front of it? some\n",
      "What article should have been used in front of it? some\n",
      "What article rule is the correct usage? indefinite plural quantity\n",
      "The word is:  magazims\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? \n",
      "The word is:  stores\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? \n",
      "The word is:  mother\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? \n",
      "The word is:  friend\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? \n",
      "The word is:  holiday\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? \n",
      "The word is:  idea\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? \n",
      "The word is:  eyes\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? \n",
      "The word is:  eyes\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? \n",
      "The word is:  holidy\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? \n",
      "The word is:  holiday\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? \n",
      "The word is:  becouse\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? \n",
      "The word is:  places\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? \n",
      "What article rule is the correct usage? \n",
      "The word is:  family\n",
      "What article was used in front of it? \n",
      "What article should have been used in front of it? d\n",
      "What article rule is the correct usage? d\n",
      "The word is:  friends\n",
      "What article was used in front of it? d\n",
      "What article should have been used in front of it? d\n",
      "What article rule is the correct usage? d\n"
     ]
    }
   ],
   "source": [
    "print(doc)\n",
    "articles = []\n",
    "\n",
    "for tok in doc:\n",
    "    if tok.tag_ == 'NN' or tok.tag_ == 'NNS' or tok.tag_ == 'NNP' or tok.tag_ == 'NNPS':\n",
    "        print('The word is: ', tok)\n",
    "        produced = input('What article was used in front of it? ')\n",
    "        actual = input('What article should have been used in front of it? ')\n",
    "        rule = input('What article rule is the correct usage? ')\n",
    "        articles.append((tok, tok.tag_, 'produced:', produced, 'actual:', actual, rule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(holidy, 'NN', 'produced:', 'the', 'actual:', 'the', 'superlative'), (holiday, 'NN', 'produced:', 'my', 'actual:', 'my', 'BrE holiday'), (dubai, 'NNS', 'produced:', '', 'actual:', '', 'city name'), (Abu, 'NNP', 'produced:', '', 'actual:', '', 'city name'), (dabi, 'NNP', 'produced:', '', 'actual:', '', 'city name'), (Sharjah, 'NNP', 'produced:', '', 'actual:', '', 'city name'), (Al, 'NNP', 'produced:', '', 'actual:', '', 'city name'), (Ain, 'NNP', 'produced:', '', 'actual:', '', 'city name'), (Fujirah, 'NNP', 'produced:', '', 'actual:', '', 'city name'), (places, 'NNS', 'produced:', '', 'actual:', '', 'plural count'), (family, 'NN', 'produced:', 'my', 'actual:', 'my', 'possessive'), (friends, 'NNS', 'produced:', 'my', 'actual:', 'my', 'posessive'), (cinama, 'NN', 'produced:', 'the', 'actual:', 'construction name', 'the'), (movies, 'NNS', 'produced:', '', 'actual:', '', 'plural count'), (friends, 'NNS', 'produced:', '', 'actual:', 'my', 'possessive'), (malls, 'NNS', 'produced:', '', 'actual:', 'the', 'plural count'), (clothes, 'NNS', 'produced:', '', 'actual:', '', 'noncount'), (time, 'NN', 'produced:', 'some', 'actual:', 'some', 'pre-nominal modifier'), (sisters, 'NNS', 'produced:', '', 'actual:', 'my', 'possessive'), (brothers, 'NNS', 'produced:', '', 'actual:', '', 'coordinating nominals'), (example, 'NN', 'produced:', '', 'actual:', '', 'collocation'), (sea, 'NN', 'produced:', 'the', 'actual:', 'the', 'geographical feature names'), (family, 'NN', 'produced:', 'my', 'actual:', 'my', 'possessive'), (time, 'NN', 'produced:', 'a', 'actual:', 'a', 'singular countable'), (sea, 'NN', 'produced:', 'the', 'actual:', 'the', 'geographical features name'), (father, 'NN', 'produced:', 'my', 'actual:', 'my', 'possessive'), (sisters, 'NNS', 'produced:', '', 'actual:', '', 'coordinating nominals'), (football, 'NN', 'produced:', '', 'actual:', '', 'noncountable'), (becouse, 'NN', 'produced:', 'because', 'actual:', 'because', 'incorrect tagging'), (holiday, 'NN', 'produced:', '', 'actual:', 'a', 'singular countable'), (time, 'NN', 'produced:', 'a+some', 'actual:', 'some', 'noncountable'), (coffe, 'NN', 'produced:', '', 'actual:', '', 'noncount'), (nel, 'NN', 'produced:', 'nel', 'actual:', 'nel', 'not a word'), (coffe, 'NN', 'produced:', 'some', 'actual:', 'some', 'noncount '), (juce, 'NN', 'produced:', '', 'actual:', '', 'coordinating related nominals'), (day, 'NN', 'produced:', 'on(e)', 'actual:', 'one', 'countable, ordinal'), (aholiday, 'NN', 'produced:', 'a', 'actual:', 'the', 'second mention'), (friends, 'NNS', 'produced:', 'the+my', 'actual:', 'my', 'possessive'), (house, 'NN', 'produced:', \"'s\", 'actual:', \"'s\", 'posessive'), (friend, 'NN', 'produced:', 'your', 'actual:', 'your', 'posessive'), (Bookes, 'NNPS', 'produced:', 'some', 'actual:', 'some', 'indefinite plural quantity'), (magazims, 'NNS', 'produced:', '', 'actual:', '', ''), (stores, 'NNS', 'produced:', '', 'actual:', '', ''), (mother, 'NN', 'produced:', '', 'actual:', '', ''), (friend, 'NN', 'produced:', '', 'actual:', '', ''), (holiday, 'NN', 'produced:', '', 'actual:', '', ''), (idea, 'NN', 'produced:', '', 'actual:', '', ''), (eyes, 'NNS', 'produced:', '', 'actual:', '', ''), (eyes, 'NNS', 'produced:', '', 'actual:', '', ''), (holidy, 'NN', 'produced:', '', 'actual:', '', ''), (holiday, 'NN', 'produced:', '', 'actual:', '', ''), (becouse, 'NN', 'produced:', '', 'actual:', '', ''), (places, 'NNS', 'produced:', '', 'actual:', '', ''), (family, 'NN', 'produced:', '', 'actual:', 'd', 'd'), (friends, 'NNS', 'produced:', 'd', 'actual:', 'd', 'd')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

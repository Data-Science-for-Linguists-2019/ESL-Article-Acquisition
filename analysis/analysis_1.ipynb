{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis\n",
    "2019.04.06 - ?\n",
    "\n",
    "I get to data analysis in this notebook. This is _part 1_, as I am planning on attacking analysis from another aspect in the future. This notebook looks at the usage of articles in front of specific count and mass nouns, obtained from the prepatory analysis and exploration. However, due to limitations on finding nouns used in each level of interest for four language groups in two different corpora (Arabic L1 from BALC, Arabic L1 from PELIC, Spanish L1 from PELIC, Korean L1 from PELIC), only 1 sample from each level in each language was able to be obtained. Due to this, and due to the fact that I may not have very many interesting or informative findings, I am planning on expanding my analysis in a second part.\n",
    "\n",
    "## Summary of code\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%pprint            # to turn off pretty printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# I tried to use .read_csv, but it didn't work, so I'll continue to use .from_csv\n",
    "balc = pd.DataFrame.from_csv('../data/balc_targets.csv', index_col=[0])\n",
    "pelic = pd.DataFrame.from_csv('../private/pelic_targets.csv', index_col=[0])\n",
    "targets = pd.DataFrame.from_csv('../exploratory-analysis/chosen_targets_new.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Level</th>\n",
       "      <th>Original_Text</th>\n",
       "      <th>Normalized_Essay</th>\n",
       "      <th>Revised_Essay</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_count</th>\n",
       "      <th>TTR</th>\n",
       "      <th>Guiraud</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>targ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1347</td>\n",
       "      <td>200611403</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200611403\\n\\n\\n\\nLast summer ho...</td>\n",
       "      <td>Last summer holiday iam going with my family t...</td>\n",
       "      <td>Last summer holiday iam going with my family t...</td>\n",
       "      <td>['Last', 'summer', 'holiday', 'iam', 'going', ...</td>\n",
       "      <td>82</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>4.858987</td>\n",
       "      <td>[(Last, 'JJ'), (summer, 'NN'), (holiday, 'NN')...</td>\n",
       "      <td>['last', 'summer', 'holiday', 'iam', 'go', 'wi...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1171</td>\n",
       "      <td>200608092</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200608092\\n\\n\\n\\nI have just ha...</td>\n",
       "      <td>I have just had the perfect holidy. In my holi...</td>\n",
       "      <td>I have just had the perfect holidy. In my holi...</td>\n",
       "      <td>['I', 'have', 'just', 'had', 'the', 'perfect',...</td>\n",
       "      <td>188</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>6.126330</td>\n",
       "      <td>[(I, 'PRP'), (have, 'VBP'), (just, 'RB'), (had...</td>\n",
       "      <td>['-PRON-', 'have', 'just', 'have', 'the', 'per...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1441</td>\n",
       "      <td>200603618</td>\n",
       "      <td>5</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 5 200603618\\n\\n\\n\\nIn the summer ...</td>\n",
       "      <td>In the summer holiday my family dicides to spe...</td>\n",
       "      <td>In the summer holiday my family dicides to spe...</td>\n",
       "      <td>['In', 'the', 'summer', 'holiday', 'my', 'fami...</td>\n",
       "      <td>215</td>\n",
       "      <td>0.460465</td>\n",
       "      <td>6.751744</td>\n",
       "      <td>[(In, 'IN'), (the, 'DT'), (summer, 'NN'), (hol...</td>\n",
       "      <td>['in', 'the', 'summer', 'holiday', '-PRON-', '...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1530</td>\n",
       "      <td>200607320</td>\n",
       "      <td>6</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 6 200607320\\n\\n\\n\\nThere have bee...</td>\n",
       "      <td>There have been many films reteased lately, So...</td>\n",
       "      <td>There have been many films reteased lately, So...</td>\n",
       "      <td>['There', 'have', 'been', 'many', 'films', 're...</td>\n",
       "      <td>234</td>\n",
       "      <td>0.598291</td>\n",
       "      <td>9.152086</td>\n",
       "      <td>[(There, 'EX'), (have, 'VBP'), (been, 'VBN'), ...</td>\n",
       "      <td>['there', 'have', 'be', 'many', 'film', 'retea...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>881</td>\n",
       "      <td>200607798</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200607798\\n\\nWhere I going to t...</td>\n",
       "      <td>Where I going to the India with my family , my...</td>\n",
       "      <td>Where I going to the India with my family , my...</td>\n",
       "      <td>['Where', 'I', 'going', 'to', 'the', 'India', ...</td>\n",
       "      <td>151</td>\n",
       "      <td>0.602649</td>\n",
       "      <td>7.405475</td>\n",
       "      <td>[(Where, 'WRB'), (I, 'PRP'), (going, 'VBG'), (...</td>\n",
       "      <td>['where', '-PRON-', 'go', 'to', 'the', 'india'...</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   Filename  Level                                      Original_Text  \\\n",
       "0   1347  200611403      3  \\t\\t\\t\\tCEPA 3 200611403\\n\\n\\n\\nLast summer ho...   \n",
       "1   1171  200608092      4  \\t\\t\\t\\tCEPA 4 200608092\\n\\n\\n\\nI have just ha...   \n",
       "2   1441  200603618      5  \\t\\t\\t\\tCEPA 5 200603618\\n\\n\\n\\nIn the summer ...   \n",
       "3   1530  200607320      6  \\t\\t\\t\\tCEPA 6 200607320\\n\\n\\n\\nThere have bee...   \n",
       "4    881  200607798      3  \\t\\t\\t\\tCEPA 3 200607798\\n\\nWhere I going to t...   \n",
       "\n",
       "                                    Normalized_Essay  \\\n",
       "0  Last summer holiday iam going with my family t...   \n",
       "1  I have just had the perfect holidy. In my holi...   \n",
       "2  In the summer holiday my family dicides to spe...   \n",
       "3  There have been many films reteased lately, So...   \n",
       "4  Where I going to the India with my family , my...   \n",
       "\n",
       "                                       Revised_Essay  \\\n",
       "0  Last summer holiday iam going with my family t...   \n",
       "1  I have just had the perfect holidy. In my holi...   \n",
       "2  In the summer holiday my family dicides to spe...   \n",
       "3  There have been many films reteased lately, So...   \n",
       "4  Where I going to the India with my family , my...   \n",
       "\n",
       "                                              tokens  token_count       TTR  \\\n",
       "0  ['Last', 'summer', 'holiday', 'iam', 'going', ...           82  0.536585   \n",
       "1  ['I', 'have', 'just', 'had', 'the', 'perfect',...          188  0.446809   \n",
       "2  ['In', 'the', 'summer', 'holiday', 'my', 'fami...          215  0.460465   \n",
       "3  ['There', 'have', 'been', 'many', 'films', 're...          234  0.598291   \n",
       "4  ['Where', 'I', 'going', 'to', 'the', 'India', ...          151  0.602649   \n",
       "\n",
       "    Guiraud                                                pos  \\\n",
       "0  4.858987  [(Last, 'JJ'), (summer, 'NN'), (holiday, 'NN')...   \n",
       "1  6.126330  [(I, 'PRP'), (have, 'VBP'), (just, 'RB'), (had...   \n",
       "2  6.751744  [(In, 'IN'), (the, 'DT'), (summer, 'NN'), (hol...   \n",
       "3  9.152086  [(There, 'EX'), (have, 'VBP'), (been, 'VBN'), ...   \n",
       "4  7.405475  [(Where, 'WRB'), (I, 'PRP'), (going, 'VBG'), (...   \n",
       "\n",
       "                                              lemmas   targ  \n",
       "0  ['last', 'summer', 'holiday', 'iam', 'go', 'wi...   book  \n",
       "1  ['-PRON-', 'have', 'just', 'have', 'the', 'per...   book  \n",
       "2  ['in', 'the', 'summer', 'holiday', '-PRON-', '...   book  \n",
       "3  ['there', 'have', 'be', 'many', 'film', 'retea...   book  \n",
       "4  ['where', '-PRON-', 'go', 'to', 'the', 'india'...  money  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Level</th>\n",
       "      <th>Original_Text</th>\n",
       "      <th>Normalized_Essay</th>\n",
       "      <th>Revised_Essay</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_count</th>\n",
       "      <th>TTR</th>\n",
       "      <th>Guiraud</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>targ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200611403</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200611403\\n\\n\\n\\nLast summer ho...</td>\n",
       "      <td>Last summer holiday iam going with my family t...</td>\n",
       "      <td>Last summer holiday iam going with my family t...</td>\n",
       "      <td>['Last', 'summer', 'holiday', 'iam', 'going', ...</td>\n",
       "      <td>82</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>4.858987</td>\n",
       "      <td>[(Last, 'JJ'), (summer, 'NN'), (holiday, 'NN')...</td>\n",
       "      <td>['last', 'summer', 'holiday', 'iam', 'go', 'wi...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200608092</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200608092\\n\\n\\n\\nI have just ha...</td>\n",
       "      <td>I have just had the perfect holidy. In my holi...</td>\n",
       "      <td>I have just had the perfect holidy. In my holi...</td>\n",
       "      <td>['I', 'have', 'just', 'had', 'the', 'perfect',...</td>\n",
       "      <td>188</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>6.126330</td>\n",
       "      <td>[(I, 'PRP'), (have, 'VBP'), (just, 'RB'), (had...</td>\n",
       "      <td>['-PRON-', 'have', 'just', 'have', 'the', 'per...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200603618</td>\n",
       "      <td>5</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 5 200603618\\n\\n\\n\\nIn the summer ...</td>\n",
       "      <td>In the summer holiday my family dicides to spe...</td>\n",
       "      <td>In the summer holiday my family dicides to spe...</td>\n",
       "      <td>['In', 'the', 'summer', 'holiday', 'my', 'fami...</td>\n",
       "      <td>215</td>\n",
       "      <td>0.460465</td>\n",
       "      <td>6.751744</td>\n",
       "      <td>[(In, 'IN'), (the, 'DT'), (summer, 'NN'), (hol...</td>\n",
       "      <td>['in', 'the', 'summer', 'holiday', '-PRON-', '...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200607320</td>\n",
       "      <td>6</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 6 200607320\\n\\n\\n\\nThere have bee...</td>\n",
       "      <td>There have been many films reteased lately, So...</td>\n",
       "      <td>There have been many films reteased lately, So...</td>\n",
       "      <td>['There', 'have', 'been', 'many', 'films', 're...</td>\n",
       "      <td>234</td>\n",
       "      <td>0.598291</td>\n",
       "      <td>9.152086</td>\n",
       "      <td>[(There, 'EX'), (have, 'VBP'), (been, 'VBN'), ...</td>\n",
       "      <td>['there', 'have', 'be', 'many', 'film', 'retea...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200607798</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200607798\\n\\nWhere I going to t...</td>\n",
       "      <td>Where I going to the India with my family , my...</td>\n",
       "      <td>Where I going to the India with my family , my...</td>\n",
       "      <td>['Where', 'I', 'going', 'to', 'the', 'India', ...</td>\n",
       "      <td>151</td>\n",
       "      <td>0.602649</td>\n",
       "      <td>7.405475</td>\n",
       "      <td>[(Where, 'WRB'), (I, 'PRP'), (going, 'VBG'), (...</td>\n",
       "      <td>['where', '-PRON-', 'go', 'to', 'the', 'india'...</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Filename  Level                                      Original_Text  \\\n",
       "0  200611403      3  \\t\\t\\t\\tCEPA 3 200611403\\n\\n\\n\\nLast summer ho...   \n",
       "1  200608092      4  \\t\\t\\t\\tCEPA 4 200608092\\n\\n\\n\\nI have just ha...   \n",
       "2  200603618      5  \\t\\t\\t\\tCEPA 5 200603618\\n\\n\\n\\nIn the summer ...   \n",
       "3  200607320      6  \\t\\t\\t\\tCEPA 6 200607320\\n\\n\\n\\nThere have bee...   \n",
       "4  200607798      3  \\t\\t\\t\\tCEPA 3 200607798\\n\\nWhere I going to t...   \n",
       "\n",
       "                                    Normalized_Essay  \\\n",
       "0  Last summer holiday iam going with my family t...   \n",
       "1  I have just had the perfect holidy. In my holi...   \n",
       "2  In the summer holiday my family dicides to spe...   \n",
       "3  There have been many films reteased lately, So...   \n",
       "4  Where I going to the India with my family , my...   \n",
       "\n",
       "                                       Revised_Essay  \\\n",
       "0  Last summer holiday iam going with my family t...   \n",
       "1  I have just had the perfect holidy. In my holi...   \n",
       "2  In the summer holiday my family dicides to spe...   \n",
       "3  There have been many films reteased lately, So...   \n",
       "4  Where I going to the India with my family , my...   \n",
       "\n",
       "                                              tokens  token_count       TTR  \\\n",
       "0  ['Last', 'summer', 'holiday', 'iam', 'going', ...           82  0.536585   \n",
       "1  ['I', 'have', 'just', 'had', 'the', 'perfect',...          188  0.446809   \n",
       "2  ['In', 'the', 'summer', 'holiday', 'my', 'fami...          215  0.460465   \n",
       "3  ['There', 'have', 'been', 'many', 'films', 're...          234  0.598291   \n",
       "4  ['Where', 'I', 'going', 'to', 'the', 'India', ...          151  0.602649   \n",
       "\n",
       "    Guiraud                                                pos  \\\n",
       "0  4.858987  [(Last, 'JJ'), (summer, 'NN'), (holiday, 'NN')...   \n",
       "1  6.126330  [(I, 'PRP'), (have, 'VBP'), (just, 'RB'), (had...   \n",
       "2  6.751744  [(In, 'IN'), (the, 'DT'), (summer, 'NN'), (hol...   \n",
       "3  9.152086  [(There, 'EX'), (have, 'VBP'), (been, 'VBN'), ...   \n",
       "4  7.405475  [(Where, 'WRB'), (I, 'PRP'), (going, 'VBG'), (...   \n",
       "\n",
       "                                              lemmas   targ  \n",
       "0  ['last', 'summer', 'holiday', 'iam', 'go', 'wi...   book  \n",
       "1  ['-PRON-', 'have', 'just', 'have', 'the', 'per...   book  \n",
       "2  ['in', 'the', 'summer', 'holiday', '-PRON-', '...   book  \n",
       "3  ['there', 'have', 'be', 'many', 'film', 'retea...   book  \n",
       "4  ['where', '-PRON-', 'go', 'to', 'the', 'india'...  money  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the index column, we don't need it\n",
    "balc = balc.drop('index', axis=1)\n",
    "balc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>class_code</th>\n",
       "      <th>level_id</th>\n",
       "      <th>native_language</th>\n",
       "      <th>version</th>\n",
       "      <th>toks_re</th>\n",
       "      <th>toks_re_len</th>\n",
       "      <th>toks_nltk</th>\n",
       "      <th>targ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1897</td>\n",
       "      <td>188</td>\n",
       "      <td>am1</td>\n",
       "      <td>13293</td>\n",
       "      <td>Adjective\\n a lot of traditional desserts\\n su...</td>\n",
       "      <td>w</td>\n",
       "      <td>3</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>1</td>\n",
       "      <td>['adjective', 'a', 'lot', 'of', 'traditional',...</td>\n",
       "      <td>200</td>\n",
       "      <td>['Adjective', 'a', 'lot', 'of', 'traditional',...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31692</td>\n",
       "      <td>4194</td>\n",
       "      <td>du3</td>\n",
       "      <td>69515</td>\n",
       "      <td>I like book called The Last Lecture,because it...</td>\n",
       "      <td>w</td>\n",
       "      <td>4</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>1</td>\n",
       "      <td>['i', 'like', 'book', 'called', 'the', 'last',...</td>\n",
       "      <td>13</td>\n",
       "      <td>['I', 'like', 'book', 'called', 'The', 'Last',...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36798</td>\n",
       "      <td>4778</td>\n",
       "      <td>dp7</td>\n",
       "      <td>78306</td>\n",
       "      <td>Studying English is very crucial because it ...</td>\n",
       "      <td>w</td>\n",
       "      <td>5</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>1</td>\n",
       "      <td>['studying', 'english', 'is', 'very', 'crucial...</td>\n",
       "      <td>132</td>\n",
       "      <td>['Studying', 'English', 'is', 'very', 'crucial...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18572</td>\n",
       "      <td>2544</td>\n",
       "      <td>dg7</td>\n",
       "      <td>41011</td>\n",
       "      <td>?        LIST\\n\\nThe entrance is in front of t...</td>\n",
       "      <td>w</td>\n",
       "      <td>3</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1</td>\n",
       "      <td>['list', 'the', 'entrance', 'is', 'in', 'front...</td>\n",
       "      <td>124</td>\n",
       "      <td>['?', 'LIST', 'The', 'entrance', 'is', 'in', '...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1483</td>\n",
       "      <td>140</td>\n",
       "      <td>eu6</td>\n",
       "      <td>11952</td>\n",
       "      <td>1.The !Kung's most important food is the mongo...</td>\n",
       "      <td>w</td>\n",
       "      <td>4</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'kung', 's', 'most', 'important', 'foo...</td>\n",
       "      <td>164</td>\n",
       "      <td>['1', '.', 'The', '!', 'Kung', \"'s\", 'most', '...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   answer_id  question_id anon_id  user_file_id  \\\n",
       "0       1897          188     am1         13293   \n",
       "1      31692         4194     du3         69515   \n",
       "2      36798         4778     dp7         78306   \n",
       "3      18572         2544     dg7         41011   \n",
       "4       1483          140     eu6         11952   \n",
       "\n",
       "                                                text class_code  level_id  \\\n",
       "0  Adjective\\n a lot of traditional desserts\\n su...          w         3   \n",
       "1  I like book called The Last Lecture,because it...          w         4   \n",
       "2    Studying English is very crucial because it ...          w         5   \n",
       "3  ?        LIST\\n\\nThe entrance is in front of t...          w         3   \n",
       "4  1.The !Kung's most important food is the mongo...          w         4   \n",
       "\n",
       "  native_language  version                                            toks_re  \\\n",
       "0          Arabic        1  ['adjective', 'a', 'lot', 'of', 'traditional',...   \n",
       "1          Arabic        1  ['i', 'like', 'book', 'called', 'the', 'last',...   \n",
       "2          Arabic        1  ['studying', 'english', 'is', 'very', 'crucial...   \n",
       "3          Korean        1  ['list', 'the', 'entrance', 'is', 'in', 'front...   \n",
       "4          Korean        1  ['the', 'kung', 's', 'most', 'important', 'foo...   \n",
       "\n",
       "   toks_re_len                                          toks_nltk  targ  \n",
       "0          200  ['Adjective', 'a', 'lot', 'of', 'traditional',...  book  \n",
       "1           13  ['I', 'like', 'book', 'called', 'The', 'Last',...  book  \n",
       "2          132  ['Studying', 'English', 'is', 'very', 'crucial...  book  \n",
       "3          124  ['?', 'LIST', 'The', 'entrance', 'is', 'in', '...  book  \n",
       "4          164  ['1', '.', 'The', '!', 'Kung', \"'s\", 'most', '...  book  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pelic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing regex\n",
    "I'll be using regular expressions to look for the targets, so below is some testing I did on a UDF and some test phrases to see what I can do with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "myre = re.compile(r'((\\w+ ){,2}\\w+ book.*?\\b)', re.I)\n",
    "test = [\"I put the book on the counter.\", \"I put a book on the counter.\", \"I put the books on the counter\",\n",
    "       \"I put some books on the counter.\", \"I put my books on the counter.\", \"I put book on the counter.\",\n",
    "       \"I put books on the counter.\", \"I put book and books and the other books on the counter.\"]\n",
    "\n",
    "def getArticles(regex, text):\n",
    "    myre = re.compile(regex)\n",
    "    search = myre.findall(text)\n",
    "    articles = []\n",
    "    for item in search:\n",
    "        if 'the' in item:\n",
    "            articles.append((item, 'the'))\n",
    "        elif 'a' in item or 'an' in item:\n",
    "            articles.append((item, 'a/an'))\n",
    "        else:\n",
    "            articles.append((item, '0'))\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('I put the book', 'put '), '0')]\n",
      "[(('I put a book', 'put '), '0')]\n",
      "[(('I put the books', 'put '), '0')]\n",
      "[(('I put some books', 'put '), '0')]\n",
      "[(('I put my books', 'put '), '0')]\n",
      "[(('I put book', 'I '), '0')]\n",
      "[(('I put books', 'I '), '0')]\n",
      "[(('I put book', 'I '), '0'), (('and books', ''), '0'), (('and the other books', 'the '), '0')]\n"
     ]
    }
   ],
   "source": [
    "for s in test:\n",
    "    print(getArticles(myre, s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, this is an obvious issue. All of the returns are zero articles, which is simply not true! Let's investigate a little further..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I put the book', 'put ')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = test[0]\n",
    "a = myre.findall(s1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I put the book', 'put ')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'I put the book'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]\n",
    "'the' in a[0]\n",
    "\n",
    "a[0][0]\n",
    "'the' in a[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the issue was that I was initially targeting the entire tuple, not the string object of interest, and it was returning 'false' for everything I searched for, thus kicking everything down to the 'else' condition. Let's rewrite getArticles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArticles(regex, text):\n",
    "    \"\"\"Uses a regex targeting a noun. Finds all instances of the noun and returns whether the return contains a definite article, an indefinite article, a zero article, or other types of determiners.\n",
    "    Input: regex (a regex compile), text (can be a single string object or a list of string objects).\n",
    "    Returns item and type of article in a list format.\"\"\"\n",
    "    myre = re.compile(regex)\n",
    "    look = myre.findall(text)\n",
    "    other = ['my', 'his', 'her', 'their', 'their', 'our', 'ours', 'its', \n",
    "            'this', 'that', 'these', 'those', 'some', 'much', 'many', 'most', 'some', 'any', 'enough',\n",
    "            'all', \"both\", 'half', 'either', 'neither', 'each', 'every']\n",
    "    articles = []\n",
    "    indef = re.compile(r'\\ban?\\b')\n",
    "    for item in look:\n",
    "        if any(search in item[0] for search in other):\n",
    "            if 'the' in item[0]:\n",
    "                articles.append((item, 'the'))\n",
    "            elif indef.search(item[0]):\n",
    "                matchobj = indef.search(item[0])\n",
    "                if matchobj:\n",
    "                    articles.append((item, 'a/an'))\n",
    "                else:\n",
    "                    articles.append((item, 'other'))\n",
    "            else:\n",
    "                articles.append((item, 'other'))\n",
    "        elif 'the' in item[0]:\n",
    "            articles.append((item, 'the'))\n",
    "        elif indef.search(item[0]):\n",
    "            matchobj = indef.search(item[0])\n",
    "            if matchobj:\n",
    "                articles.append((item, 'a/an'))\n",
    "        else:\n",
    "            articles.append((item, '0'))\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('I put the book', 'put '), 'the')]\n",
      "[(('I put a book', 'put '), 'a/an')]\n",
      "[(('I put the books', 'put '), 'the')]\n",
      "[(('I put some books', 'put '), 'other')]\n",
      "[(('I put my books', 'put '), 'other')]\n",
      "[(('I put book', 'I '), '0')]\n",
      "[(('I put books', 'I '), '0')]\n",
      "[(('I put book', 'I '), '0'), (('and books', ''), '0'), (('and the other books', 'the '), 'the')]\n"
     ]
    }
   ],
   "source": [
    "for s in test:\n",
    "    print(getArticles(myre, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('I put the book', 'put '), 'the')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getArticles(myre, s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and international dessert books', 'international '), ('many of dessert books', 'of '), ('and international dessert books', 'international ')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = myre.findall(pelic.text[0])\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('and international dessert books', 'international '), '0'), (('many of dessert books', 'of '), 'other'), (('and international dessert books', 'international '), '0')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getArticles(myre, pelic.text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may not be perfect, so we'll need to double-check along the way, but this should be a good start. Let's start looking at some nouns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count nouns\n",
    "In this section, I'll take a look at the targets that are count nouns:\n",
    "- book \n",
    "- place\n",
    "- park\n",
    "- week\n",
    "- story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>counts_cepa</th>\n",
       "      <th>counts_pelic</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>place</td>\n",
       "      <td>770</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>park</td>\n",
       "      <td>431</td>\n",
       "      <td>247.0</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>week</td>\n",
       "      <td>308</td>\n",
       "      <td>469.0</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>story</td>\n",
       "      <td>182</td>\n",
       "      <td>254.0</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>book</td>\n",
       "      <td>121</td>\n",
       "      <td>685.0</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lemma  counts_cepa  counts_pelic   type\n",
       "37   place          770        1883.0  count\n",
       "73    park          431         247.0  count\n",
       "101   week          308         469.0  count\n",
       "154  story          182         254.0  count\n",
       "194   book          121         685.0  count"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[targets.type == 'count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'Book'\n",
    "myre is already set to look for 'book', so let's just jump into it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_pelic = pelic[pelic.targ == 'book']\n",
    "book_balc = balc[balc.targ == 'book']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>anon_id</th>\n",
       "      <th>user_file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>class_code</th>\n",
       "      <th>level_id</th>\n",
       "      <th>native_language</th>\n",
       "      <th>version</th>\n",
       "      <th>toks_re</th>\n",
       "      <th>toks_re_len</th>\n",
       "      <th>toks_nltk</th>\n",
       "      <th>targ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1897</td>\n",
       "      <td>188</td>\n",
       "      <td>am1</td>\n",
       "      <td>13293</td>\n",
       "      <td>Adjective\\n a lot of traditional desserts\\n su...</td>\n",
       "      <td>w</td>\n",
       "      <td>3</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>1</td>\n",
       "      <td>['adjective', 'a', 'lot', 'of', 'traditional',...</td>\n",
       "      <td>200</td>\n",
       "      <td>['Adjective', 'a', 'lot', 'of', 'traditional',...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31692</td>\n",
       "      <td>4194</td>\n",
       "      <td>du3</td>\n",
       "      <td>69515</td>\n",
       "      <td>I like book called The Last Lecture,because it...</td>\n",
       "      <td>w</td>\n",
       "      <td>4</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>1</td>\n",
       "      <td>['i', 'like', 'book', 'called', 'the', 'last',...</td>\n",
       "      <td>13</td>\n",
       "      <td>['I', 'like', 'book', 'called', 'The', 'Last',...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36798</td>\n",
       "      <td>4778</td>\n",
       "      <td>dp7</td>\n",
       "      <td>78306</td>\n",
       "      <td>Studying English is very crucial because it ...</td>\n",
       "      <td>w</td>\n",
       "      <td>5</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>1</td>\n",
       "      <td>['studying', 'english', 'is', 'very', 'crucial...</td>\n",
       "      <td>132</td>\n",
       "      <td>['Studying', 'English', 'is', 'very', 'crucial...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18572</td>\n",
       "      <td>2544</td>\n",
       "      <td>dg7</td>\n",
       "      <td>41011</td>\n",
       "      <td>?        LIST\\n\\nThe entrance is in front of t...</td>\n",
       "      <td>w</td>\n",
       "      <td>3</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1</td>\n",
       "      <td>['list', 'the', 'entrance', 'is', 'in', 'front...</td>\n",
       "      <td>124</td>\n",
       "      <td>['?', 'LIST', 'The', 'entrance', 'is', 'in', '...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1483</td>\n",
       "      <td>140</td>\n",
       "      <td>eu6</td>\n",
       "      <td>11952</td>\n",
       "      <td>1.The !Kung's most important food is the mongo...</td>\n",
       "      <td>w</td>\n",
       "      <td>4</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'kung', 's', 'most', 'important', 'foo...</td>\n",
       "      <td>164</td>\n",
       "      <td>['1', '.', 'The', '!', 'Kung', \"'s\", 'most', '...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2738</td>\n",
       "      <td>300</td>\n",
       "      <td>ad1</td>\n",
       "      <td>16211</td>\n",
       "      <td>The statue is situated in the middle of a sea ...</td>\n",
       "      <td>w</td>\n",
       "      <td>5</td>\n",
       "      <td>Korean</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'statue', 'is', 'situated', 'in', 'the...</td>\n",
       "      <td>60</td>\n",
       "      <td>['The', 'statue', 'is', 'situated', 'in', 'the...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29216</td>\n",
       "      <td>3881</td>\n",
       "      <td>bt8</td>\n",
       "      <td>66247</td>\n",
       "      <td>...</td>\n",
       "      <td>w</td>\n",
       "      <td>3</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>1</td>\n",
       "      <td>['types', 'of', 'magazines', 'there', 'are', '...</td>\n",
       "      <td>166</td>\n",
       "      <td>['Types', 'of', 'magazines', 'There', 'are', '...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18537</td>\n",
       "      <td>2541</td>\n",
       "      <td>en1</td>\n",
       "      <td>40609</td>\n",
       "      <td>You can get other personal reasons in order to...</td>\n",
       "      <td>w</td>\n",
       "      <td>4</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>1</td>\n",
       "      <td>['you', 'can', 'get', 'other', 'personal', 're...</td>\n",
       "      <td>90</td>\n",
       "      <td>['You', 'can', 'get', 'other', 'personal', 're...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33911</td>\n",
       "      <td>4461</td>\n",
       "      <td>bi4</td>\n",
       "      <td>73652</td>\n",
       "      <td>Learning English has been very hard to underst...</td>\n",
       "      <td>w</td>\n",
       "      <td>5</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>1</td>\n",
       "      <td>['learning', 'english', 'has', 'been', 'very',...</td>\n",
       "      <td>365</td>\n",
       "      <td>['Learning', 'English', 'has', 'been', 'very',...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   answer_id  question_id anon_id  user_file_id  \\\n",
       "0       1897          188     am1         13293   \n",
       "1      31692         4194     du3         69515   \n",
       "2      36798         4778     dp7         78306   \n",
       "3      18572         2544     dg7         41011   \n",
       "4       1483          140     eu6         11952   \n",
       "5       2738          300     ad1         16211   \n",
       "6      29216         3881     bt8         66247   \n",
       "7      18537         2541     en1         40609   \n",
       "8      33911         4461     bi4         73652   \n",
       "\n",
       "                                                text class_code  level_id  \\\n",
       "0  Adjective\\n a lot of traditional desserts\\n su...          w         3   \n",
       "1  I like book called The Last Lecture,because it...          w         4   \n",
       "2    Studying English is very crucial because it ...          w         5   \n",
       "3  ?        LIST\\n\\nThe entrance is in front of t...          w         3   \n",
       "4  1.The !Kung's most important food is the mongo...          w         4   \n",
       "5  The statue is situated in the middle of a sea ...          w         5   \n",
       "6                                                ...          w         3   \n",
       "7  You can get other personal reasons in order to...          w         4   \n",
       "8  Learning English has been very hard to underst...          w         5   \n",
       "\n",
       "  native_language  version                                            toks_re  \\\n",
       "0          Arabic        1  ['adjective', 'a', 'lot', 'of', 'traditional',...   \n",
       "1          Arabic        1  ['i', 'like', 'book', 'called', 'the', 'last',...   \n",
       "2          Arabic        1  ['studying', 'english', 'is', 'very', 'crucial...   \n",
       "3          Korean        1  ['list', 'the', 'entrance', 'is', 'in', 'front...   \n",
       "4          Korean        1  ['the', 'kung', 's', 'most', 'important', 'foo...   \n",
       "5          Korean        1  ['the', 'statue', 'is', 'situated', 'in', 'the...   \n",
       "6         Spanish        1  ['types', 'of', 'magazines', 'there', 'are', '...   \n",
       "7         Spanish        1  ['you', 'can', 'get', 'other', 'personal', 're...   \n",
       "8         Spanish        1  ['learning', 'english', 'has', 'been', 'very',...   \n",
       "\n",
       "   toks_re_len                                          toks_nltk  targ  \n",
       "0          200  ['Adjective', 'a', 'lot', 'of', 'traditional',...  book  \n",
       "1           13  ['I', 'like', 'book', 'called', 'The', 'Last',...  book  \n",
       "2          132  ['Studying', 'English', 'is', 'very', 'crucial...  book  \n",
       "3          124  ['?', 'LIST', 'The', 'entrance', 'is', 'in', '...  book  \n",
       "4          164  ['1', '.', 'The', '!', 'Kung', \"'s\", 'most', '...  book  \n",
       "5           60  ['The', 'statue', 'is', 'situated', 'in', 'the...  book  \n",
       "6          166  ['Types', 'of', 'magazines', 'There', 'are', '...  book  \n",
       "7           90  ['You', 'can', 'get', 'other', 'personal', 're...  book  \n",
       "8          365  ['Learning', 'English', 'has', 'been', 'very',...  book  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_pelic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Level</th>\n",
       "      <th>Original_Text</th>\n",
       "      <th>Normalized_Essay</th>\n",
       "      <th>Revised_Essay</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_count</th>\n",
       "      <th>TTR</th>\n",
       "      <th>Guiraud</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>targ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200611403</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200611403\\n\\n\\n\\nLast summer ho...</td>\n",
       "      <td>Last summer holiday iam going with my family t...</td>\n",
       "      <td>Last summer holiday iam going with my family t...</td>\n",
       "      <td>['Last', 'summer', 'holiday', 'iam', 'going', ...</td>\n",
       "      <td>82</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>4.858987</td>\n",
       "      <td>[(Last, 'JJ'), (summer, 'NN'), (holiday, 'NN')...</td>\n",
       "      <td>['last', 'summer', 'holiday', 'iam', 'go', 'wi...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200608092</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200608092\\n\\n\\n\\nI have just ha...</td>\n",
       "      <td>I have just had the perfect holidy. In my holi...</td>\n",
       "      <td>I have just had the perfect holidy. In my holi...</td>\n",
       "      <td>['I', 'have', 'just', 'had', 'the', 'perfect',...</td>\n",
       "      <td>188</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>6.126330</td>\n",
       "      <td>[(I, 'PRP'), (have, 'VBP'), (just, 'RB'), (had...</td>\n",
       "      <td>['-PRON-', 'have', 'just', 'have', 'the', 'per...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200603618</td>\n",
       "      <td>5</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 5 200603618\\n\\n\\n\\nIn the summer ...</td>\n",
       "      <td>In the summer holiday my family dicides to spe...</td>\n",
       "      <td>In the summer holiday my family dicides to spe...</td>\n",
       "      <td>['In', 'the', 'summer', 'holiday', 'my', 'fami...</td>\n",
       "      <td>215</td>\n",
       "      <td>0.460465</td>\n",
       "      <td>6.751744</td>\n",
       "      <td>[(In, 'IN'), (the, 'DT'), (summer, 'NN'), (hol...</td>\n",
       "      <td>['in', 'the', 'summer', 'holiday', '-PRON-', '...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200607320</td>\n",
       "      <td>6</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 6 200607320\\n\\n\\n\\nThere have bee...</td>\n",
       "      <td>There have been many films reteased lately, So...</td>\n",
       "      <td>There have been many films reteased lately, So...</td>\n",
       "      <td>['There', 'have', 'been', 'many', 'films', 're...</td>\n",
       "      <td>234</td>\n",
       "      <td>0.598291</td>\n",
       "      <td>9.152086</td>\n",
       "      <td>[(There, 'EX'), (have, 'VBP'), (been, 'VBN'), ...</td>\n",
       "      <td>['there', 'have', 'be', 'many', 'film', 'retea...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Filename  Level                                      Original_Text  \\\n",
       "0  200611403      3  \\t\\t\\t\\tCEPA 3 200611403\\n\\n\\n\\nLast summer ho...   \n",
       "1  200608092      4  \\t\\t\\t\\tCEPA 4 200608092\\n\\n\\n\\nI have just ha...   \n",
       "2  200603618      5  \\t\\t\\t\\tCEPA 5 200603618\\n\\n\\n\\nIn the summer ...   \n",
       "3  200607320      6  \\t\\t\\t\\tCEPA 6 200607320\\n\\n\\n\\nThere have bee...   \n",
       "\n",
       "                                    Normalized_Essay  \\\n",
       "0  Last summer holiday iam going with my family t...   \n",
       "1  I have just had the perfect holidy. In my holi...   \n",
       "2  In the summer holiday my family dicides to spe...   \n",
       "3  There have been many films reteased lately, So...   \n",
       "\n",
       "                                       Revised_Essay  \\\n",
       "0  Last summer holiday iam going with my family t...   \n",
       "1  I have just had the perfect holidy. In my holi...   \n",
       "2  In the summer holiday my family dicides to spe...   \n",
       "3  There have been many films reteased lately, So...   \n",
       "\n",
       "                                              tokens  token_count       TTR  \\\n",
       "0  ['Last', 'summer', 'holiday', 'iam', 'going', ...           82  0.536585   \n",
       "1  ['I', 'have', 'just', 'had', 'the', 'perfect',...          188  0.446809   \n",
       "2  ['In', 'the', 'summer', 'holiday', 'my', 'fami...          215  0.460465   \n",
       "3  ['There', 'have', 'been', 'many', 'films', 're...          234  0.598291   \n",
       "\n",
       "    Guiraud                                                pos  \\\n",
       "0  4.858987  [(Last, 'JJ'), (summer, 'NN'), (holiday, 'NN')...   \n",
       "1  6.126330  [(I, 'PRP'), (have, 'VBP'), (just, 'RB'), (had...   \n",
       "2  6.751744  [(In, 'IN'), (the, 'DT'), (summer, 'NN'), (hol...   \n",
       "3  9.152086  [(There, 'EX'), (have, 'VBP'), (been, 'VBN'), ...   \n",
       "\n",
       "                                              lemmas  targ  \n",
       "0  ['last', 'summer', 'holiday', 'iam', 'go', 'wi...  book  \n",
       "1  ['-PRON-', 'have', 'just', 'have', 'the', 'per...  book  \n",
       "2  ['in', 'the', 'summer', 'holiday', '-PRON-', '...  book  \n",
       "3  ['there', 'have', 'be', 'many', 'film', 'retea...  book  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_balc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('and international dessert books', 'international '), '0'), (('many of dessert books', 'of '), 'other'), (('and international dessert books', 'international '), '0')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\"Adjective\\n a lot of traditional desserts\\n superior success\\n My mother was a wonderful cook\\n national and international dessert books\\n practiced the desirable recipes\\n my favorite food channels\\n\\n   Phrases of prepositions\\n from my mother\\n many of dessert books\\n on T.V for half an hour a day\\n\\n\\n      Topic:  personal success\\n            Making a dessert\\n\\n        I think I have a personal success in making a lot of traditional desserts from several countries.  There were some reasons for helping my superior success. One of the reasons, I gained this talent from my mother.  She was a wonderful cook especially when she made cakes. In fact, my mother taught me how to prepare German desserts.  For example, I learned the crepes, many kinds of the nut cakes, fruit cakes, and the cake's topping, too. Another reason for my success, I read many of national and international dessert books for several times ago.  I practiced the desirable recipes as soon as I read about them.  Finally, I've disciplined myself to watch the food channel on T.V for half an hour a day.  I feel that some of my favorite food channels would help me to improve my talent in the last two years.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getArticles(myre, book_pelic.text[0])\n",
    "book_pelic.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_pelic: 0\n",
      "[(('and international dessert books', 'international '), '0'), (('many of dessert books', 'of '), 'other'), (('and international dessert books', 'international '), '0')]\n",
      "Adjective\n",
      " a lot of traditional desserts\n",
      " superior success\n",
      " My mother was a wonderful cook\n",
      " national and international dessert books\n",
      " practiced the desirable recipes\n",
      " my favorite food channels\n",
      "\n",
      "   Phrases of prepositions\n",
      " from my mother\n",
      " many of dessert books\n",
      " on T.V for half an hour a day\n",
      "\n",
      "\n",
      "      Topic:  personal success\n",
      "            Making a dessert\n",
      "\n",
      "        I think I have a personal success in making a lot of traditional desserts from several countries.  There were some reasons for helping my superior success. One of the reasons, I gained this talent from my mother.  She was a wonderful cook especially when she made cakes. In fact, my mother taught me how to prepare German desserts.  For example, I learned the crepes, many kinds of the nut cakes, fruit cakes, and the cake's topping, too. Another reason for my success, I read many of national and international dessert books for several times ago.  I practiced the desirable recipes as soon as I read about them.  Finally, I've disciplined myself to watch the food channel on T.V for half an hour a day.  I feel that some of my favorite food channels would help me to improve my talent in the last two years.\n",
      "\n",
      "book_pelic: 1\n",
      "[(('I like book', 'I '), '0')]\n",
      "I like book called The Last Lecture,because it about authores's experience.\n",
      "\n",
      "book_pelic: 2\n",
      "[(('has materials and books', 'materials '), '0')]\n",
      "  Studying English is very crucial because it becomes the global language in the world. Studying English in my country has materials and books, just as studying English in the U.S. For example, the ELS institute has branches in my country as same as in the U.S. In addition, there are some teachers in my country whose native language is English; similar to the U.S. teachers. In contrast, people who studied English in the U.S. can speak English anywhere, but people who studied English in my country cannot speak English out of school. \n",
      "   Finally, studying English in my country and in the U.S. different, yet alike. Although studying English in my country has benefits, studying English in the U.S. is better because it BIASED speaking very well.\n",
      "\n",
      "\n",
      "book_pelic: 3\n",
      "[(('between book', ''), '0'), (('beside book', ''), '0'), (('between book', ''), '0'), (('I have two book', 'have '), '0'), (('One book', ''), '0'), (('beside book', ''), '0')]\n",
      "?        LIST\n",
      "\n",
      "The entrance is in front of the desk.\n",
      "The desk is on the front, between book chests.\n",
      "Bed is on the left corner, beside book chest.\n",
      "Clothes chest is on the left, in front of bed.\n",
      "My room center has the heart shape rug.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I have little furniture in my room.\n",
      "As you enter the door through the entrance, desk is in front of you. The desk is on the front, between book chests. I have two book chests. One book chest is on the right wall. The other one is on the front wall. My bed is on the left corner, beside book chest. Clothes chest is on the left, in front of bed. My room center has the heart shape rug.\n",
      "\n",
      "\n",
      "book_pelic: 4\n",
      "[(('The book', ''), '0')]\n",
      "1.The !Kung's most important food is the mongongo nut, which have various and high nutrition than other foods like calories and protein. So they distinguish nutrional food supply from hunting. \n",
      "\n",
      "2. - Overall evaluation is very positive. \n",
      "   - productive  reliable  selectivity\n",
      "     affluence   abundance \n",
      "\n",
      "3. The author had no direct experience with !Kung. But he used bool source. The book is \"Cultural Anthropology',which written by Gary Ferraro in 1992. \n",
      "\n",
      "4. + nutrional of mongongo nut \n",
      "   -> It contaims five times the calories and ten times the protein per cooked unit than cereaal crops.(Lee 1968) \n",
      "\n",
      "   + selecvity \n",
      "   -> Only about one-third of the edible foods are eaten and only 17 of the 223 local species if animals known to the !Kung are hunted regularly (Lee 1968:35)\n",
      "\n",
      "   + health and longevity of population. \n",
      "   -> Lee found that approximately ten percent, which was not substantially different from industrialilzed societies, of his sample population was sixty years of age or older. \n",
      "(Lee 1968:36)\n",
      "   + amount of time spent to procure food  \n",
      "   -> They still have considerable leisure time for visiting, entertaining, and dancing. (Lee 1968:37)\n",
      "\n",
      "book_pelic: 5\n",
      "[(('She has a book', 'has '), 'a/an')]\n",
      "The statue is situated in the middle of a sea or river, and it is pretty high. It is blush green and it looks like a beautiful woman. She has a book in her left hand, and she holds a torch in the right hand. On the top of her head, there is a crown, which looks good on her. \n",
      "\n",
      "book_pelic: 6\n",
      "[(('from all good bookshops', 'all '), 'other')]\n",
      "                                                                                  Types of magazines\n",
      "\n",
      "\n",
      "\n",
      "                   There are three types of magazines, they are available from all good bookshops or online.  I can to get the best preference or the information about if it is interesting for me.\n",
      "\n",
      "The first type of magazine is a sport magazine.  For example, I can find magazine providing the latest information on building and operating an athletic facility, athletic programs, action photos, athlete interviews, scores and statistic on an  professional and college sports.  The second type of magazine is an automobile whether if I have a passion for cars, I can find a long list of magazines especially tailored for the information needs of car such as car design, car market, or car lifestyle.  The last type is a health magazine these cover a variety of topics including physical fitness, nutrition, beauty, weight training and body building.\n",
      "In conclusion, I can find many types of magazines the most important,  I can choose or find my preference and what information is interesting for me.\n",
      "\n",
      "book_pelic: 7\n",
      "[(('and thousands of books', 'thousands '), '0')]\n",
      "You can get other personal reasons in order to acquire the proficiency in English and to continue including more benefits in this list. But, no body can deny that learning English has many benefits today. Because this language permits us communicate our ideas and feelings to the people that in some cases they are living in other side of the world. By the English we can accede to the advances of science, read thousands and thousands of books that are published every day, and finally, of course earn some money.\n",
      "\n",
      "book_pelic: 8\n",
      "[(('lessons in the book', 'in '), 'the')]\n",
      "Learning English has been very hard to understand for me, but I have had many teachers that have encouraged me to practice English all the time to improve my skills. Every teacher has its own style of teaching class, but it is crucial that at the end all teachers have the same goal, try to give to students the best information possible. Each style of teaching has positive and negative aspects; in this essay I will focus in two of my teachers, and specifically in how they were alike, and how they were different each other. \n",
      "\n",
      "\n",
      "First of all, I had a teacher she was very kind, good, orderly, and I could improve my English skill very well. But sometimes, in my class we missed a lot of time in a specific point or chapter, so we could not keep working as fast as possible in a semester. I enjoyed her style of teaching because was very useful, in areas such as listening activities in class, or learning new vocabulary words. On the other hand, I am having a teacher this semester who is always fighting with us in a good way, with the goal of encourage us to study hard every day. We have been practicing different kind of essay using god topics to keep our attention in class. We have tried to work very fast in the semester to cover as much as possible with respect of the lessons in the book. We have studied new vocabulary words, different form of words, and different kind of essay.\n",
      "\n",
      "Second, both teachers have different personalities in their styles of teaching. My teacher of last semester had a style of class very serious, where she explained all her class and students keep sitting, and listen to her carefully. With this teacher we had a system of work very strict, which consisted in listen to the theory, and then we did the practice. On the other hand, my current teacher has a style of teaching very interesting, which consist in different activities during the class. We have played games to figure out vocabulary words, also we have played games in team to practice different strategies of English.  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for x in book_pelic.text:\n",
    "    print(\"book_pelic:\", index)\n",
    "    print(getArticles(myre, x))\n",
    "    print(x)\n",
    "    print()\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_balc: 0\n",
      "[(('wooke in the booke', 'in '), 'the')]\n",
      "Last summer holiday iam going with my family to perfect weekend. we going to the India. We going to wooke in the booke and go to shopping. And we will go to see Tag Mhale. It was so wonderful. cause it have a nice people and a nice shope. After I finsed in India iam going to Hangare with my family. we spend in Loxx. And iam plaing football and going to swam.\n",
      "\n",
      "book_balc: 1\n",
      "[(('friend reading some Bookes', 'reading '), 'other')]\n",
      "I have just had the perfect holidy. In my holiday I went to dubai, Abu dabi, Sharjah Al-Ain and Fujirah I went there places with my family and my friends. I went the cinama and watched nice movies with my friends, I went malls I buys clothes and play some time with sisters and brothers for example went the sea with my family I just had a wonderfor time I swam in the sea and play with my father and sisters football. I'm very happy becouse I have nice holiday. In a some time I went net coffe set in a nel and drank some coffe or juce. On day in aholiday I went the my friends house she wented your friend reading some Bookes, magazims, and stores the mother my friend set and to took for a what's to do in holiday she gived nice idea. open the eyes and close the eyes and the butiful holidy finishd The holiday is wonderful becouse I went many places with my family and my friends.\n",
      "\n",
      "book_balc: 2\n",
      "[(('newspaper or story book', 'or '), '0')]\n",
      "In the summer holiday my family dicides to spend our holiday in Japan , so I prepared my self to spend 2 week there. When I reached Japan ,I feel so intresting when I saw Japanese child wearing traditional dress(keymono) and playing with water. The weather there was so nice . We stay in small house made of wood and there was a cute family from Japan living with us. They was so kind with us. They took us to have a nice Jeirney in the city. When I reached the city I been shocked when I saw people every where. there holding magazine or newspaper or story book, every where on the bus, in the street on the park every where, every where they Just read and work all the time. They really had diffrent life. When our Jeirney finished in the city .they took us to Japanese hotel where I eat a deliscious food. Really I spend intresting time in Japan I learned some Japanese word and I learned about there culture and tradition, and I learned how to manage my time. Really it was a nice and perfect holiday I have ever spend.\n",
      "\n",
      "book_balc: 3\n",
      "[(('t judde a book', 'judde '), 'a/an')]\n",
      "There have been many films reteased lately, Some were good and others were awful.. but there's always that little group of films that shine through the rest, films that are so good that you don't mind watching them a second time. The film that I enjoyed the most was based on and named after the classic novel \"Pride and Prejudice\" It stars Keira Knightley who's one of my favourite actresses. The story is about how important first impressions are and how they effect the way aperson is seen. This happened when Elizabeth bennet overhears Mr.Darsey , Arich gentleman complaing to his friend about the party they were attending and how he thought that Elizabeth was not pretty and called her plain. After that Elizabeth thinks of Mr. Darsey as an arrogant man and doesn't want anything to do with him, She also refuses his marrige proposal because of her pride, And it takes many incedents and some time before she realises that she had fallen in love with him and the film ends with her accepting his proposal.. I enjoyed this film because of the great story, the wonderful scenery and because it can be seen in the real world , last but not least I learnt that we shouldn't judde a book by it's cover .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for x in book_balc.Revised_Essay:\n",
    "    print(\"book_balc:\", index)\n",
    "    print(getArticles(myre, x))\n",
    "    print(x)\n",
    "    print()\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

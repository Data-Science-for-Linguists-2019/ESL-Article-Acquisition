{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elena Cimino, e.cimino@pitt.edu, 2019.02.12 - 2019.02.17\n",
    "\n",
    "# The Corpus: \n",
    "- BALC is a corpus compiled by researchers at the British University in Dubai of the writing of native Arabic speakers (L1 Arabic) in the United Arab Emirates who speak/have learned English as a Foreign Language (EFL). \n",
    "- The corpus has 1,865 texts that are handwritten. \n",
    "- All texts are available as plain text documents; some are also accompanied by jpeg/png image files of the essays.\n",
    "- There are several sources for the texts.\n",
    "\n",
    "# The Layout: \n",
    "- There are subdirectories with a folder that holds the files from each individual source. \n",
    "- There is a \"CEPA Images\" folder that has the images and texts for each text.\n",
    "- There is also a \"total\" folder that has every text in the corpus in this folder. \n",
    "- Therefore, each text in the corpus should be available in its individual folder as well as the \"total\" folder.\n",
    "- Additionally, each text from the CEPA examination should be available in _three_ different locations: \n",
    "    - The \"CEPA Images\" folder;\n",
    "    - The individual \"CEPA_#\" folder; \n",
    "    - The \"total\" folder.\n",
    "    \n",
    "# The Exploration: \n",
    "- Double-checking the format of the files in the different texts and checking numbers\n",
    "- I'm mainly interested in the CEPA files right now, since the proficiency levels (1-6, with 1 being the lowest perceived proficiency level and 6 the highest) can be compared against the proficiency levels found in the other corpus I'm looking at: Pitt ELI Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "%pprint            # to turn off pretty printing\n",
    "cor_dir = \"private/BUiD Arab Learner Corpus v.1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['private/BUiD Arab Learner Corpus v.1/CEPA Images/1/200604231.txt', 'private/BUiD Arab Learner Corpus v.1/CEPA Images/1/200602456.txt', 'private/BUiD Arab Learner Corpus v.1/CEPA Images/1/200600490.txt', 'private/BUiD Arab Learner Corpus v.1/CEPA Images/1/200605503.txt', 'private/BUiD Arab Learner Corpus v.1/CEPA Images/1/200604379.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# globbing \"CEPA images folder\"\n",
    "cepa_im_1 = glob.glob(cor_dir+'CEPA Images/1/*.txt')\n",
    "cepa_im_2 = glob.glob(cor_dir+'CEPA Images/2/*.txt')\n",
    "cepa_im_3 = glob.glob(cor_dir+'CEPA Images/3/*.txt')\n",
    "cepa_im_4 = glob.glob(cor_dir+'CEPA Images/4/*.txt')\n",
    "cepa_im_5 = glob.glob(cor_dir+'CEPA Images/5/*.txt')\n",
    "cepa_im_6 = glob.glob(cor_dir+'CEPA Images/6/*.txt')\n",
    "cepa_im = cepa_im_1 + cepa_im_2 + cepa_im_3 + cepa_im_4 + cepa_im_5 + cepa_im_6\n",
    "print(len(cepa_im))\n",
    "cepa_im[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cepa_im_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cepa_im_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cepa_im_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cepa_im_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cepa_im_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cepa_im_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'200609914' in cepa_im_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a fabulous way to name files -- identification of each file may be dependent on the folder structure, not the filename itself. I'll double-check to see if there are any identically named files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['200602841']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a list of the short-hand names of the cepa_images folder\n",
    "nums = []\n",
    "for file in cepa_im:\n",
    "    start = file.rindex('/')+1\n",
    "    name = file[start:-4]\n",
    "    nums.append(name)\n",
    "\n",
    "# Counting the number of occurences of each short-hand filename from nums\n",
    "import collections\n",
    "c = collections.Counter(nums)\n",
    "\n",
    "# collecting files with more than 1 occurence \n",
    "more = [x for x in c if c[x] > 1]\n",
    "\n",
    "# Seeing how many files are in \"more\"\n",
    "print(len(more))\n",
    "\n",
    "# oh, there's just one, let's see which file it is and how many occurences there are\n",
    "print(more)\n",
    "c['200602841']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['private/BUiD Arab Learner Corpus v.1/CEPA Images/4/200602841.txt', 'private/BUiD Arab Learner Corpus v.1/CEPA Images/5/200602841.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat = []\n",
    "for f in cepa_im:\n",
    "    if '200602841' in f:\n",
    "        repeat.append(f)\n",
    "repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "private/BUiD Arab Learner Corpus v.1/CEPA Images/4/200602841.txt:\n",
      "The best movie  that I have recently is (The Dafenshi Code) and one of the\n",
      "leading roles is played by a famouse novie star ( gorge clonie ) he plays the hero.\n",
      "The movie is about a super vikan that tries to speak the dafenshi book from the \n",
      "vadicane musiam but he misses up and gets tailled by a cope which tries\n",
      "toprevint he from using a code inthe book that is said to cause\n",
      "the end of the world (Armagedon) in the end good triamps over evil\n",
      "and every thing goes back to normal.I liked the movie because it`s \n",
      "about a mistrey that no one knew how to solve accept the evil vikan\n",
      "and because it`s based on history and real events,but I was abite\n",
      "disapoint ed because the ending was to easy to pradict I like the endings\n",
      "to be so twisted and unpradictable that you have to watch the movie 2 or\n",
      "3 times to under stand what really happined.Never the less I enjoyed\n",
      "the movie I liked it so nuch that I  saw it 6 limes in one week.\n",
      "\n",
      "private/BUiD Arab Learner Corpus v.1/CEPA Images/5/200602841.txt:\n",
      "The best movie  that I have recently is (The Dafenshi Code) and one of the\n",
      "leading roles is played by a famouse novie star ( gorge clonie ) he plays the hero.\n",
      "The movie is about a super vikan that tries to speak the dafenshi book from the \n",
      "vadicane musiam but he misses up and gets tailled by a cope which tries\n",
      "toprevint he from using a code inthe book that is said to cause\n",
      "the end of the world (Armagedon) in the end good triamps over evil\n",
      "and every thing goes back to normal.I liked the movie because it`s \n",
      "about a mistrey that no one knew how to solve accept the evil vikan\n",
      "and because it`s based on history and real events,but I was abite\n",
      "disapoint ed because the ending was to easy to pradict I like the endings\n",
      "to be so twisted and unpradictable that you have to watch the movie 2 or\n",
      "3 times to under stand what really happined.Never the less I enjoyed\n",
      "the movie I liked it so nuch that I  saw it 6 limes in one week.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "repeat_dict = {}\n",
    "for essay in cepa_im:\n",
    "    if '200602841' in essay:\n",
    "        f = open(essay)\n",
    "        txt = f.read()\n",
    "        f.close()\n",
    "        print(essay+\":\")\n",
    "        print(txt)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that will do it. \"CEPA-4-200602841\" and \"CEPA-5-200602841\" are identical files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the other two folders and see what's going on with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['private/BUiD Arab Learner Corpus v.1/cepa1_em/CEPA 1 200611825.txt', 'private/BUiD Arab Learner Corpus v.1/cepa1_em/CEPA 1 200606381.txt', 'private/BUiD Arab Learner Corpus v.1/cepa1_em/CEPA 1 200603548.txt', 'private/BUiD Arab Learner Corpus v.1/cepa1_em/CEPA 1 200610508.txt', 'private/BUiD Arab Learner Corpus v.1/cepa1_em/CEPA 1 200603206.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# globbing each cepa folder \n",
    "# folders with \"_em\" suffix have been coded for student corrections\n",
    "cepa_1 = glob.glob(cor_dir+'cepa1_em/*.txt')\n",
    "cepa_2 = glob.glob(cor_dir+'cepa2_em/*.txt')\n",
    "cepa_3 = glob.glob(cor_dir+'cepa3_em/*.txt')\n",
    "cepa_4 = glob.glob(cor_dir+'cepa4_em/*.txt')\n",
    "cepa_5 = glob.glob(cor_dir+'cepa5/*.txt')\n",
    "cepa_6 = glob.glob(cor_dir+'cepa6/*.txt')\n",
    "cepa_sub = cepa_1 + cepa_2 + cepa_3 + cepa_4 + cepa_5 + cepa_6\n",
    "print(len(cepa_sub))\n",
    "cepa_sub[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['private/BUiD Arab Learner Corpus v.1/total/CEPA 3 200607296.txt', 'private/BUiD Arab Learner Corpus v.1/total/CEPA 4 200607457.txt', 'private/BUiD Arab Learner Corpus v.1/total/CEPA 5 200600487.txt', 'private/BUiD Arab Learner Corpus v.1/total/CEPA 4 200608016.txt', 'private/BUiD Arab Learner Corpus v.1/total/CEPA 1 200611825.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# globbing \"total\" folder\n",
    "cepa_total = [f for f in glob.glob(cor_dir+\"total/*.txt\") if \"CEPA\" in f or \"Cepa\" in f or \"cepa\" in f or \"CEPa\" in f]\n",
    "print(len(cepa_total))\n",
    "cepa_total[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What we know so far: \n",
    "Across the board, we can see that the CEPA Images folder has the least amount of files. CEPA Total and the individual CEPA sub-folders have the same amount of files, which is good. Both the total and individual CEPA folders have student corrections coded with HTML tags by the researchers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's probe and see if we can spot where the differences are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_file(file):\n",
    "    \"\"\"If a file names contain spaces, these spaces are removed.\"\"\"\n",
    "    spaces = re.compile(r'\\s+')\n",
    "    matchobj = spaces.search(file)\n",
    "    if matchobj:\n",
    "        file = re.sub(r'\\s+', '-', file)\n",
    "    return file\n",
    "\n",
    "sub_files = {}\n",
    "for file in cepa_sub:\n",
    "    f = open(file)\n",
    "    txt = f.read()\n",
    "    f.close()\n",
    "    file = rename_file(file)\n",
    "    start = file.rindex('/')+1\n",
    "    name = file[start:-4]\n",
    "    sub_files[name] = txt\n",
    "    \n",
    "cep_total_files = {}\n",
    "for file in cepa_total:\n",
    "    f = open(file)\n",
    "    txt = f.read()\n",
    "    f.close()\n",
    "    file = rename_file(file)\n",
    "    start = file.rindex('/')+1\n",
    "    name = file[start:-4]\n",
    "    cep_total_files[name] = txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just quickly double check and make sure neither of the folders have a random file that's not in the other one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = [k for k in sub_files.keys() if k not in cep_total_files.keys()]\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = [k for k in cep_total_files.keys() if k not in sub_files.keys()]\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look into the repeated file in these two folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿\t\t\t\tCEPA 5 200602841\n",
      "\n",
      "\n",
      "\n",
      "The best movie  that I have recently is (The Dafenshi Code) and one of the\n",
      "leading roles is played by a famouse movie star ( gorge clonie ) he plays the hero.\n",
      "The movie is about a super villan that tries to steall the dafenshi book from the  vadicane musiam but he misses up and gets tailled by a cope which tries toprevint he from using a code in the book that is said to cause the end of the world (Armagedon) in the end good triamps over evil\n",
      "and every thing goes back to normal.I liked the movie because it`s \n",
      "about a mistrey that no one knew how to solve accept the evil villan\n",
      "and because it`s based on history and real events,but I was abite\n",
      "disapoint ed because the ending was to easy to pradict I like the endings\n",
      "to be so twisted and unpradictable that you have to watch the movie 2 or\n",
      "3 times to under stand what really happined.Never the less I enjoyed\n",
      "the movie I liked it so nuch that I  saw it 6 limes in one week.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for f in sub_files.keys():\n",
    "    if '200602841' in f :\n",
    "        print(sub_files[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿\t\t\t\tCEPA 5 200602841\n",
      "\n",
      "\n",
      "\n",
      "The best movie  that I have recently is (The Dafenshi Code) and one of the\n",
      "leading roles is played by a famouse movie star ( gorge clonie ) he plays the hero.\n",
      "The movie is about a super villan that tries to steall the dafenshi book from the  vadicane musiam but he misses up and gets tailled by a cope which tries toprevint he from using a code in the book that is said to cause the end of the world (Armagedon) in the end good triamps over evil\n",
      "and every thing goes back to normal.I liked the movie because it`s \n",
      "about a mistrey that no one knew how to solve accept the evil villan\n",
      "and because it`s based on history and real events,but I was abite\n",
      "disapoint ed because the ending was to easy to pradict I like the endings\n",
      "to be so twisted and unpradictable that you have to watch the movie 2 or\n",
      "3 times to under stand what really happined.Never the less I enjoyed\n",
      "the movie I liked it so nuch that I  saw it 6 limes in one week.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for f in cep_total_files.keys():\n",
    "    if '200602841' in f :\n",
    "        print(sub_files[f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like the level \"4\" repeated file was thrown out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

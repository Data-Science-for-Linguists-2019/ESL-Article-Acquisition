{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in spacy\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"I have a cat and that cat is my favorite cat in the whole wide world.\"\n",
    "test2 = \"Those cats I saw at a store down on Fifth Avenue were really the cutest cats I've ever seen in my life.\"\n",
    "test3 = \"I live on the Fifth Avenue.\"\n",
    "\n",
    "# Spacy\n",
    "one = []\n",
    "t = nlp(test)\n",
    "for tok in t:\n",
    "    one.append((tok.text, tok.tag_))\n",
    "\n",
    "two = []\n",
    "t = nlp(test2)\n",
    "for tok in t:\n",
    "    two.append((tok.text, tok.tag_))\n",
    "\n",
    "three = []\n",
    "t = nlp(test3)\n",
    "for tok in t:\n",
    "    three.append((tok.text, tok.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'), ('have', 'VBP'), ('a', 'DT'), ('cat', 'NN'), ('and', 'CC'), ('that', 'DT'), ('cat', 'NN'), ('is', 'VBZ'), ('my', 'PRP$'), ('favorite', 'JJ'), ('cat', 'NN'), ('in', 'IN'), ('the', 'DT'), ('whole', 'JJ'), ('wide', 'JJ'), ('world', 'NN'), ('.', '.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('Those', 'DT'), ('cats', 'NNS'), ('I', 'PRP'), ('saw', 'VBD'), ('at', 'IN'), ('a', 'DT'), ('store', 'NN'), ('down', 'RP'), ('on', 'IN'), ('Fifth', 'NNP'), ('Avenue', 'NNP'), ('were', 'VBD'), ('really', 'RB'), ('the', 'DT'), ('cutest', 'JJS'), ('cats', 'NNS'), ('I', 'PRP'), (\"'ve\", 'VB'), ('ever', 'RB'), ('seen', 'VBN'), ('in', 'IN'), ('my', 'PRP$'), ('life', 'NN'), ('.', '.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'), ('live', 'VBP'), ('on', 'IN'), ('the', 'DT'), ('Fifth', 'NNP'), ('Avenue', 'NNP'), ('.', '.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one\n",
    "two\n",
    "three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 1\n",
      "3\n",
      "----\n",
      "index: 1\n",
      "3\n",
      "----\n",
      "index: 1\n",
      "3\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "top = [1, 3, 7, 8, 3, -3, 3, 0]\n",
    "for i in top:\n",
    "    if i == 3:\n",
    "        print(\"index:\", top.index(i))\n",
    "        print(i)\n",
    "        print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 1\n",
      "3\n",
      "---\n",
      "index: 4\n",
      "3\n",
      "---\n",
      "index: 6\n",
      "3\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "hits = (i for i,value in enumerate(top) if value == 3)\n",
    "for i in hits:\n",
    "    print(\"index:\", i)\n",
    "    print(top[i])\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0\n",
      "(1, 'NN')\n",
      "---\n",
      "index: 3\n",
      "(8, 'NN')\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "top = [(1, 'NN'), (3, 'd'), (7, 'NNS'), (8, 'NN'), (3, 'd'), (-3, 0), (3, 1), (0, 'l')]\n",
    "hits = (i for i,value in enumerate(top) if value[1] == 'NN')\n",
    "for i in hits:\n",
    "    print(\"index:\", i)\n",
    "    print(top[i])\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findArticles(tokens):\n",
    "    \"\"\"Checks a list of tokens that have been POS-tagged with spaCyand are in the format [('tok', 'pos')...]. \n",
    "    Finds all nouns and looks at the word immediately before it to judge whether or not it is a determiner.\n",
    "    Returns a list of all nouns and some basic information about them. The format of the returned list is:\n",
    "    [('tok', isDefinite, isIndefinite, isZero, isPossessive, isPlural, isProper)], where everything after 'tok' is Boolean.\"\"\"\n",
    "    lst = []\n",
    "    sing_reg = (i for i,value in enumerate(tokens) if value[1] == 'NN')\n",
    "    pl_reg = (i for i,value in enumerate(tokens) if value[1] == 'NNS')\n",
    "    sing_prop = (i for i,value in enumerate(tokens) if value[1] == 'NNP')\n",
    "    pl_prop = (i for i,value in enumerate(tokens) if value[1] == 'NNPS')\n",
    "    for w in tokens:\n",
    "        # singular non-proper nouns\n",
    "        for i in sing_reg:\n",
    "            noun = tokens[i]\n",
    "            prev = tokens[i-1]\n",
    "            if prev[1] == 'DT':\n",
    "                if prev[0] == 'The' or prev[0] == 'the':\n",
    "                    lst.append((noun[0], 1, 0 , 0, 0, 0, 0))\n",
    "                elif prev[0] == 'A' or prev[0] == 'An' or prev[0] == 'a' or prev[0] == 'an':\n",
    "                    lst.append((noun[0], 0, 1 , 0, 0, 0, 0))\n",
    "                else: lst.append((noun[0], 0, 0 , 0, 0, 0, 0))\n",
    "            elif prev[1] == 'PRP$':\n",
    "                lst.append((noun[0], 0, 0 , 0, 1, 0, 0))\n",
    "            else:\n",
    "                lst.append((noun[0], 0, 0 , 1, 0, 0, 0))\n",
    "        # plural non-proper nouns\n",
    "        for i in pl_reg:\n",
    "            noun = tokens[i]\n",
    "            prev = tokens[i-1]\n",
    "            if prev[1] == 'DT':\n",
    "                if prev[0] == 'The' or prev[0] == 'the':\n",
    "                    lst.append((noun[0], 1, 0 , 0, 0, 1, 0))\n",
    "                elif prev[0] == 'A' or prev[0] == 'An' or prev[0] == 'a' or prev[0] == 'an':\n",
    "                    lst.append((noun[0], 0, 1 , 0, 0, 1, 0))\n",
    "                else: lst.append((noun[0], 0, 0 , 0, 0, 1, 0))\n",
    "            elif prev[1] == 'PRP$':\n",
    "                lst.append((noun[0], 0, 0 , 0, 1, 1, 0))\n",
    "            else:\n",
    "                lst.append((noun[0], 0, 0 , 1, 0, 1, 0))        \n",
    "        # singular proper nouns\n",
    "        for i in sing_prop:\n",
    "            noun = tokens[i]\n",
    "            prev = tokens[i-1]\n",
    "            if prev[1] != 'NNP':\n",
    "                if prev[1] == 'DT':\n",
    "                    if prev[0] == 'The' or prev[0] == 'the':\n",
    "                        lst.append((noun[0], 1, 0 , 0, 0, 0, 1))\n",
    "                    elif prev[0] == 'A' or prev[0] == 'An' or prev[0] == 'a' or prev[0] == 'an':\n",
    "                        lst.append((noun[0], 0, 1 , 0, 0, 0, 1))\n",
    "                    else: lst.append((noun[0], 0, 0 , 0, 0, 0, 1))\n",
    "                elif prev[1] == 'PRP$':\n",
    "                    lst.append((noun[0], 0, 0 , 0, 1, 0, 1))\n",
    "                else:\n",
    "                    lst.append((noun[0], 0, 0 , 1, 0, 0, 1))                                    \n",
    "            else: \n",
    "                two = tokens[i-2]\n",
    "                if two[1] == 'DT':\n",
    "                    if two[0] == 'The' or two[0] == 'the':\n",
    "                        lst.append((noun[0], 1, 0 , 0, 0, 0, 1, 'long'))\n",
    "                    elif two[0] == 'A' or two[0] == 'An' or two[0] == 'a' or two[0] == 'an':\n",
    "                        lst.append((noun[0], 0, 1 , 0, 0, 0, 1, 'long'))\n",
    "                    else: lst.append((noun[0], 0, 0 , 0, 0, 0, 1, 'long'))\n",
    "                elif two[1] == 'PRP$':\n",
    "                    lst.append((noun[0], 0, 0 , 0, 1, 0, 1, 'long'))\n",
    "                else:\n",
    "                    lst.append((noun[0], 0, 0 , 1, 0, 0, 1, 'long'))\n",
    "        # plural proper nouns\n",
    "        for i in pl_prop:\n",
    "            noun = tokens[i]\n",
    "            prev = tokens[i-1]\n",
    "            if prev[1] != 'NNP':\n",
    "                if prev[1] == 'DT':\n",
    "                    if prev[0] == 'The' or prev[0] == 'the':\n",
    "                        lst.append((noun[0], 1, 0 , 0, 0, 1, 1))\n",
    "                    elif prev[0] == 'A' or prev[0] == 'An' or prev[0] == 'a' or prev[0] == 'an':\n",
    "                        lst.append((noun[0], 0, 1 , 0, 0, 1, 1))\n",
    "                    else: lst.append((noun[0], 0, 0 , 0, 0, 1, 1))\n",
    "                elif prev[1] == 'PRP$':\n",
    "                    lst.append((noun[0], 0, 0 , 0, 1, 1, 1))\n",
    "                else:\n",
    "                    lst.append((noun[0], 0, 0 , 1, 0, 1, 1))\n",
    "            else: \n",
    "                two = tokens[i-2]\n",
    "                if two[1] == 'DT':\n",
    "                    if two[0] == 'The' or two[0] == 'the':\n",
    "                        lst.append((noun[0], 1, 0 , 0, 0, 1, 1, 'long'))\n",
    "                    elif two[0] == 'A' or two[0] == 'An' or two[0] == 'a' or two[0] == 'an':\n",
    "                        lst.append((noun[0], 0, 1 , 0, 0, 1, 1, 'long'))\n",
    "                    else: lst.append((noun[0], 0, 0 , 0, 0, 1, 1, 'long'))\n",
    "                elif two[1] == 'PRP$':\n",
    "                    lst.append((noun[0], 0, 0 , 0, 1, 1, 1, 'long'))\n",
    "                else:\n",
    "                    lst.append((noun[0], 0, 0 , 1, 0, 1, 1, 'long'))\n",
    "    long = (i for i,value in enumerate(lst) if value[-1] == 'long')\n",
    "    for i in long:\n",
    "        prev = lst[i-1]\n",
    "        lst.remove(prev)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'), ('have', 'VBP'), ('a', 'DT'), ('cat', 'NN'), ('and', 'CC'), ('that', 'DT'), ('cat', 'NN'), ('is', 'VBZ'), ('my', 'PRP$'), ('favorite', 'JJ'), ('cat', 'NN'), ('in', 'IN'), ('the', 'DT'), ('whole', 'JJ'), ('wide', 'JJ'), ('world', 'NN'), ('.', '.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('cat', 0, 1, 0, 0, 0, 0), ('cat', 0, 0, 0, 0, 0, 0), ('cat', 0, 0, 1, 0, 0, 0), ('world', 0, 0, 1, 0, 0, 0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one\n",
    "findArticles(one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Those', 'DT'), ('cats', 'NNS'), ('I', 'PRP'), ('saw', 'VBD'), ('at', 'IN'), ('a', 'DT'), ('store', 'NN'), ('down', 'RP'), ('on', 'IN'), ('Fifth', 'NNP'), ('Avenue', 'NNP'), ('were', 'VBD'), ('really', 'RB'), ('the', 'DT'), ('cutest', 'JJS'), ('cats', 'NNS'), ('I', 'PRP'), (\"'ve\", 'VB'), ('ever', 'RB'), ('seen', 'VBN'), ('in', 'IN'), ('my', 'PRP$'), ('life', 'NN'), ('.', '.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('store', 0, 1, 0, 0, 0, 0), ('life', 0, 0, 0, 1, 0, 0), ('cats', 0, 0, 0, 0, 1, 0), ('cats', 0, 0, 1, 0, 1, 0), ('Avenue', 0, 0, 1, 0, 0, 1, 'long')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two\n",
    "findArticles(two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'), ('live', 'VBP'), ('on', 'IN'), ('the', 'DT'), ('Fifth', 'NNP'), ('Avenue', 'NNP'), ('.', '.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('Avenue', 1, 0, 0, 0, 0, 1, 'long')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three\n",
    "findArticles(three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

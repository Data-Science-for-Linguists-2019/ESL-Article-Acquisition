{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BALC cleaning \n",
    "## Subset: CEPA files \n",
    "\n",
    "2019.02.08 — 2019.02.21\n",
    "\n",
    "## Summary of code\n",
    "- Created a corpus dictionary with the file name, original text, and perceived level of proficiency\n",
    "- Initial set up of cepa_df based off the corpus dictionary, which included\n",
    "    - Filenames\n",
    "    - Original Text\n",
    "- Cleaning up the text for cepa_df by making:\n",
    "    - A \"Normalized\" Text with standardized tagging (if applicable)\n",
    "    - A \"Revised\" Essay, which removes student correction tags and removes crossed out text\n",
    "- Building up cepa_df with: \n",
    "    - Tokenized essays (built off of the revised essay)\n",
    "    - Token counts\n",
    "    - TTR count\n",
    "- Making sure everything read in correctly\n",
    "- Visualizing a bit of data about the various levels (token_count, TTR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "Prior to February 21, 2019, I was having many issues with the coding system in the BALC corpus, since it is not consistent across all files, or sometimes even within files. Originally, I was trying to process the whole corpus from the \"BUiD Arab Learner Corpus v.1/total/\" file, which contains every text file in the corpus. What I came to realize is that most of the issues were with a relatively small part of the corpus. Out of 1,865 files in the corpus, non-CEPA files only clock in at 189. Additionally, these files do not come with any proficiency rating. While the proficiency or level rating for the CEPA files are better stated as something along the lines of _perceived proficiency of a student's rating_ (as opposed to be taken as a measure of the student's actual proficency with English), it still serves as a jumping off point and a measure to compare the writing of students in this corpus with students in other corpora.\n",
    "\n",
    "Therefore, I opted to work from the /total/ folder, for several reasons:\n",
    "- For one, it has more files than the subsets of CEPA Images folders, and the distribution of files across levels is more even in /total/ than in the CEPA Images folder (as can be seen in my exploration [here](https://github.com/Data-Science-for-Linguists-2019/ESL-Article-Acquisition/blob/master/exploratory-analysis/exploring_balc.ipynb) (compare outputs 3, 4, and 13).\n",
    "- It is easier to access each file in this file as opposed to the /cepa_#/ folders, which are separated into each individual level.\n",
    "- Finally, it has content tagged with student error corrections, which could be used to make the essays more comparable, given that these are handwritten essays.\n",
    "    - So if students realized they used the wrong word/letter and crossed it out, or realized they had forgotten a word and inserted one, this is marked in essays levels 1-4 on CEPA, but _not_ in the CEPA Images folder.\n",
    "    - In CEPA Images, student corrections are generally ignored, and whatever is written gets put in the text files without taking into account crossing out words/letters, for example.\n",
    "    - Again, this can be seen in my exploration [in output cell 31](https://github.com/Data-Science-for-Linguists-2019/ESL-Article-Acquisition/blob/master/exploratory-analysis/exploring_balc.ipynb).\n",
    "\n",
    "So in this notebook, I read in the CEPA files from the corpus, accounting for the \"bad\" (repeated) files, and then take efforts to normalize, \"revise\", and clean the essays. I also tokenize, get token counts and TTR, and start on some basic analysis (descriptive and quantitative). There's still more to do: POS-tagging, and maybe lemmatization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import nltk\n",
    "import glob\n",
    "import re\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%pprint            # to turn off pretty printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../private/BUiD Arab Learner Corpus v.1/total/CEPA 3 200607296.txt', '../private/BUiD Arab Learner Corpus v.1/total/CEPA 4 200607457.txt', '../private/BUiD Arab Learner Corpus v.1/total/CEPA 5 200600487.txt', '../private/BUiD Arab Learner Corpus v.1/total/CEPA 4 200608016.txt', '../private/BUiD Arab Learner Corpus v.1/total/CEPA 1 200611825.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_dir = \"../private/BUiD Arab Learner Corpus v.1/total/\"\n",
    "corpus = glob.glob(cor_dir+'*.txt')\n",
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some duplicates in the total folder, which I'm using for the corpus root. The majority of these are cross-listed in two different proficiency levels (a few are in the same folder, but have two different file names with different spacing). \n",
    "\n",
    "I was able to locate the correctly labeled files (`clean_files`) in the CEPA Images folder, where all the original handwritten essays are located. Therefore, during my exploration of the corpus, I picked the duplicated (`bad_files`) as well as the clean files. I'll be using these two variables to point my code in the correct direction when it comes to these specific files, so that we don't have essays incorrectly labeled or duplicated files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['200607856', '200607880', '200607857', '200607777', '200607875', '200607861', '200607902', '200607910', '200612324', '200611115', '200621158', '200619773']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['../private/BUiD Arab Learner Corpus v.1/CEPA Images/2/200607777.jpg', '../private/BUiD Arab Learner Corpus v.1/CEPA Images/2/200607856.jpg', '../private/BUiD Arab Learner Corpus v.1/CEPA Images/2/200607880.jpg', '../private/BUiD Arab Learner Corpus v.1/CEPA Images/2/200607857.jpg', '../private/BUiD Arab Learner Corpus v.1/CEPA Images/2/200612324.jpg', '../private/BUiD Arab Learner Corpus v.1/CEPA Images/2/200607902.jpg', '../private/BUiD Arab Learner Corpus v.1/CEPA Images/2/200607861.jpg', '../private/BUiD Arab Learner Corpus v.1/CEPA Images/2/200607875.jpg', '../private/BUiD Arab Learner Corpus v.1/CEPA Images/2/200607910.jpg', '../private/BUiD Arab Learner Corpus v.1/CEPA Images/3/200611115.jpg', '../private/BUiD Arab Learner Corpus v.1/CEPA Images/6/200621158.jpg', '../private/BUiD Arab Learner Corpus v.1/CEPA Images/6/200619773.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opening the pickle files that have the problem files... \n",
    "f_in = open(\"duplicated_files.pickle\",\"rb\")\n",
    "bad_files = pickle.load(f_in)\n",
    "f_in.close()\n",
    "\n",
    "# ... and the clean files\n",
    "f_in = open(\"clean_files.pickle\",\"rb\")\n",
    "clean_files = pickle.load(f_in)\n",
    "f_in.close()\n",
    "\n",
    "# checking the variables and making sure this looks right\n",
    "bad_files\n",
    "clean_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, those are looking good! `bad_files` is a list of the duplicated files, and `clean_files` is the list of the correct location. The `clean_files` gives us which location in total we should head to to get the file (e.g. level 2, if a file is cross-listed in levels 1 and 2).\n",
    "\n",
    "Let's make sure the code will spit out the correct file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use: ../private/BUiD Arab Learner Corpus v.1/CEPA Images/2/200607777.jpg\n",
      "use: ../private/BUiD Arab Learner Corpus v.1/CEPA Images/2/200607856.jpg\n",
      "use: ../private/BUiD Arab Learner Corpus v.1/CEPA Images/2/200607880.jpg\n",
      "use: ../private/BUiD Arab Learner Corpus v.1/CEPA Images/2/200607857.jpg\n",
      "use: ../private/BUiD Arab Learner Corpus v.1/CEPA Images/2/200612324.jpg\n",
      "use: ../private/BUiD Arab Learner Corpus v.1/CEPA Images/2/200607902.jpg\n",
      "use: ../private/BUiD Arab Learner Corpus v.1/CEPA Images/2/200607861.jpg\n",
      "use: ../private/BUiD Arab Learner Corpus v.1/CEPA Images/2/200607875.jpg\n",
      "use: ../private/BUiD Arab Learner Corpus v.1/CEPA Images/2/200607910.jpg\n",
      "use: ../private/BUiD Arab Learner Corpus v.1/CEPA Images/3/200611115.jpg\n",
      "use: ../private/BUiD Arab Learner Corpus v.1/CEPA Images/6/200621158.jpg\n",
      "use: ../private/BUiD Arab Learner Corpus v.1/CEPA Images/6/200619773.jpg\n"
     ]
    }
   ],
   "source": [
    "# Making sure the code will pull the correct file for the duplicated files -- we're reading from /total/, but we can get the nececssary information from these filenames\n",
    "# we'll need the two numbers after \"CEPA Images\": the first number is the level, and the second number is the \"short\" file name we'll be using\n",
    "for item in clean_files:\n",
    "    if any(search in item for search in bad_files):\n",
    "        print(\"use:\", item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1652"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up a cepa dict\n",
    "corpus = glob.glob(cor_dir+'*.txt')\n",
    "corpus_dict = {}\n",
    "for file in corpus:\n",
    "    start = file.rindex('/')+1\n",
    "    name = file[start:-4]\n",
    "    x = re.findall(r'^((C|c).*?\\d{3,}( -)?)', name)   \n",
    "    if len(x) > 0:\n",
    "            x = x[0][0].split()\n",
    "            if x[-1] not in bad_files:  # duplicated files - ignoring them for now, will put in a separate dict and concatenate\n",
    "                f = open(file, encoding='utf-8-sig')   # fixes \\ufeff code at beginning of strings\n",
    "                txt = f.read()\n",
    "                f.close()\n",
    "                corpus_dict[x[-1]] = {\"Level\": x[1], \"Text\": txt}\n",
    "len(corpus_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Level': '1', 'Text': '\\t\\t\\t\\tCEPA 1 200601970\\n\\n\\n\\nYou have just had the perfect holiday you went Yaman There go <o>my  father and my brather. You</o> saw and did hadr<o>a</o> mot and sanaa moll. It was so wonderful m<o>y</o> famely\\n'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_dict[\"200601970\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_dict[\"200600215\"][\"Level\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Level': '5', 'Text': '\\t\\t\\t\\tCEPA 5 200600215\\n\\n\\n\\nLast summer holiday was the worst holiday I have ever had. It was bad holiday because evrythings happened suddenly and without any prepairing.\\nLast summer holiday, my family decided to spend  the holiday in India, so my father booked us a tickets to India. We all prepaired the bags for travelling on Tuesday.\\nWe were on the airport befor one hour of plane flying. We were told that the plane had something wrong and it would be late. We waited for three hours in the airport. Then, we flew to India. It took us three hours. When we arrived we started looking for taxi for a long time. After that we found small bus to take us to the hotel. \\nIn the way of the hotel, I saw many dogs in the street and I was afraid. In the entrence of the hotel there were many poor children with dirty cats. We spent this day in hotel because of  the bad weather.\\nNext day, I suggested going to the park. My father bought the lunch and took us to the park. We played in some games because the others were broken. In the afternoon, we became hungry so much but the food was bad and nobody ate it\\nIn the evening, while my brother played in the street with some children. he had an accident and his leg was broken. Endly, we left India with some bad memorise. \\n'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_dict[\"200600215\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '200607777'] ../private/BUiD Arab Learner Corpus v.1/total/CEPA 2 200607777.txt\n",
      "['2', '200607856'] ../private/BUiD Arab Learner Corpus v.1/total/CEPA 2 200607856.txt\n",
      "['2', '200607880'] ../private/BUiD Arab Learner Corpus v.1/total/CEPA 2 200607880.txt\n",
      "['2', '200607857'] ../private/BUiD Arab Learner Corpus v.1/total/CEPA 2 200607857.txt\n",
      "['2', '200612324'] ../private/BUiD Arab Learner Corpus v.1/total/CEPA 2 200612324.txt\n",
      "['2', '200607902'] ../private/BUiD Arab Learner Corpus v.1/total/CEPA 2 200607902.txt\n",
      "['2', '200607861'] ../private/BUiD Arab Learner Corpus v.1/total/CEPA 2 200607861.txt\n",
      "['2', '200607875'] ../private/BUiD Arab Learner Corpus v.1/total/CEPA 2 200607875.txt\n",
      "['2', '200607910'] ../private/BUiD Arab Learner Corpus v.1/total/CEPA 2 200607910.txt\n",
      "['3', '200611115'] ../private/BUiD Arab Learner Corpus v.1/total/CEPA 3 200611115.txt\n",
      "['6', '200621158'] ../private/BUiD Arab Learner Corpus v.1/total/CEPA 6 200621158.txt\n",
      "['6', '200619773'] ../private/BUiD Arab Learner Corpus v.1/total/CEPA 6 200619773.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\t\\t\\t\\tCEPA 2 200607777\\n\\n\\n\\nThe perfet holiday in UAE. You went suren cantres to one holiday. went with you me sister and mather. I’m see in Abu Dhabie “shate alraha” is a very nice sea and I went “Al maryna moll”. alfter is going to AlAin. it very nice, I went “  Mouten of hafied” and “mobazar AlKadra”. In Dubai went to the “meina salam” and “almaha” is a nice hotiel in Dubai. In RAK is go in masafi and see the water of masafi. wheth alfugaira isvery nise cantry because is have more of mouten”\\nThe ajnan amalguin is avery smoler than save cantres. it was so wonderful because I’m going xxx with father and sister. went to sven emarit. I’m very happey to see emarat in  one holiday.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is for the bad files. There should be twelve of them!\n",
    "mini = {}\n",
    "for item in clean_files:\n",
    "    if any(search in item for search in bad_files):\n",
    "        x = re.findall(r'\\d/\\d+', item)   # gets the level (/\\d/) and the file (\\d+) information\n",
    "        x = x[0]\n",
    "        x = x.split('/')\n",
    "        fn = cor_dir+\"CEPA \"+str(x[0])+\" \"+str(x[1])+\".txt\"\n",
    "        print(x, fn)\n",
    "        f = open(fn, encoding='utf-8-sig')\n",
    "        txt = f.read()\n",
    "        f.close()\n",
    "        mini[x[1]] = {\"Level\": x[0], \"Text\": txt}\n",
    "len(mini.keys())\n",
    "mini['200607777'][\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1664"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenating corpus_dict and mini, making sure they have the right amount of keys\n",
    "z = {**corpus_dict, **mini}\n",
    "len(z.keys())\n",
    "\n",
    "# Yes! We have gone down from the original 1676 files found in the total and individual cepa_# folders, but that's because we took out the duplicates in those folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting up the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1664, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200607296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200607457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200600487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200608016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200611825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Filename\n",
       "0  200607296\n",
       "1  200607457\n",
       "2  200600487\n",
       "3  200608016\n",
       "4  200611825"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cepa_df = pd.DataFrame(list(z.keys()), columns={\"Filename\"})\n",
    "cepa_df.shape\n",
    "cepa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDFs to get the level and the original text\n",
    "def get_level(file):\n",
    "    return z[file][\"Level\"]\n",
    "\n",
    "def get_text(file):\n",
    "    return z[file][\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Level</th>\n",
       "      <th>Original_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200607296</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200607296\\n\\n\\n\\nNow I tell you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200607457</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200607457\\n\\n\\n\\n              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200600487</td>\n",
       "      <td>5</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 5 200600487\\n\\n\\n\\n\\nEvery body i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200608016</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200608016\\n\\n\\n\\nEvery body hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200611825</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200611825\\n\\n\\n\\nyou go in the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Filename Level                                      Original_Text\n",
       "0  200607296     3  \\t\\t\\t\\tCEPA 3 200607296\\n\\n\\n\\nNow I tell you...\n",
       "1  200607457     4  \\t\\t\\t\\tCEPA 4 200607457\\n\\n\\n\\n              ...\n",
       "2  200600487     5  \\t\\t\\t\\tCEPA 5 200600487\\n\\n\\n\\n\\nEvery body i...\n",
       "3  200608016     4  \\t\\t\\t\\tCEPA 4 200608016\\n\\n\\n\\nEvery body hav...\n",
       "4  200611825     1  \\t\\t\\t\\tCEPA 1 200611825\\n\\n\\n\\nyou go in the ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cepa_df[\"Level\"] = cepa_df.Filename.apply(get_level)\n",
    "cepa_df[\"Original_Text\"] = cepa_df.Filename.apply(get_text)\n",
    "cepa_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data up\n",
    "It's time to get clean up these files! We can see from the DataFrame and dict entries above that these files all have a lot of white space, as well as a header with the file name. We don't need that! \n",
    "\n",
    "In this section, I:\n",
    "- Remove excessive whitespace\n",
    "- Remove things like curly quotes \n",
    "- Standardize tagging\n",
    "    - `<o>...</o>` -> `_`\n",
    "    - `<i>...</i>` -> `^`\n",
    "    - `<x>...</x>` -> `~~`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making UDFs to clean up data a bit\n",
    "\n",
    "# Remove whitespace and strange characters found in some of the files\n",
    "def clean_text(txt):\n",
    "    \"\"\"Removes excessive whitespace, backticks, and curly quotes from a text.\"\"\"\n",
    "    txt = re.sub(r'[\\n\\t ]+', ' ', txt)\n",
    "    txt = re.sub(r'^`', '', txt)\n",
    "    txt = txt.replace('“','\"').replace('”','\"').replace(\"’\", \"'\")\n",
    "    txt = txt.strip()\n",
    "    return txt\n",
    "\n",
    "# Retag files, dealing with unclosed tags, and making it easier to remove these tags later -- instead of looking for 6+ opening and closing tags, I just need to look for underscores, carrots, and the double tildes tags\n",
    "def retag(essay):\n",
    "    \"\"\"Replaces tags for student emphasis (<o>, </o>)with '_' and removes any unecessary spaces between emphasized \n",
    "    letters in words. Replaces tags for student insertions (<i>, </i>) with '^' and removes any unecessary spaces \n",
    "    between letters in inserted words. Replaces cross-out tags (<x>, </x>) with '~~' Removes any left over brackets.\"\"\"\n",
    "    essay = re.sub(r'\\<i +', '<i>', essay)\n",
    "    essay = re.sub(r'<x +', '<x>', essay)\n",
    "    essay = re.sub(r'<o +', '<o>', essay)\n",
    "    essay = re.sub(r'<\\/o[^>]', '</o>', essay)\n",
    "    essay = re.sub(r'<o>(\\s)?', '_', essay)\n",
    "    essay = re.sub(r'(\\s)?<\\/o>', '_', essay)\n",
    "    essay = re.sub(r'<i>(\\s)?', '^', essay)\n",
    "    essay = re.sub(r'(\\s)?<\\/i>', '^', essay)\n",
    "    essay = re.sub(r'</?x>', '~~', essay)\n",
    "    essay = re.sub(r'>', ' ', essay)\n",
    "    essay = re.sub(r'<', ' ', essay)\n",
    "#    essay = re.sub(r'__', '_ _', essay)\n",
    "    return essay\n",
    "\n",
    "# Remove heading from files\n",
    "def un_head(txt):\n",
    "    \"\"\"Removes headers from text that include the file name, as well as student's names, grades, schools, etc.\"\"\"\n",
    "    cepa = re.compile(r'^C(EPA|EPa|epa)')      # removes cepa headers\n",
    "    if cepa.search(txt):\n",
    "        txt = re.sub(r'CEPA.*?\\d{2,}( ?-)?', '', txt, flags=re.I)   # there was one file that was CEPA ! filename\n",
    "    return txt\n",
    "\n",
    "# Apply all of these UDFs in a convenient, single function!\n",
    "def normalize_essay(txt):\n",
    "    txt = clean_text(txt)\n",
    "    txt = retag(txt)\n",
    "    txt = un_head(txt)\n",
    "    txt = txt.strip()\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the UDFs out to make sure they work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\t\\t\\t\\tCEPA 1 2006625\\n\\n\\n\\nwhat the activity is to ideas and to Play foot ball in the clamp and see to manh in T.V of foot ball Games Iam we play move foor ball in the zoo with may fired XXX I paly in the\\nFradey <o>a</o>t 4 coclek is too storing of tham am and to ray ferar<o>d</o>e  in the Zoo as behtFele sprts in any am and I go may fired to see foot ball in clarp in LAwqL Calmp Iam more afeh see footpall amy fired and go to the coFe see foot ball an gierk to cof and wentes and go to may clamp see may pephel play fotb<o>a</o>ll im clamp and me I kan paly more Gams in the comfotre Games\\nin cold places they culive by living with humans.\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\"\\t\\t\\t\\tCEPA 2 200606375\\n\\n\\n\\nthe most beau<o>u</otiful pla<x>c</x>e you know in <o>A</o>l Hilly . I like go to the allh<x>i</x>lly because I'm play geam and look in the most beautiful . I play foot ball , tens basketball and play geam to t<x>h</x>e car . I'm look to the sea. I'm go to the AllHilly on frend .your go in the play <o>and aet</o>. I should you go in the All Hilly sawfa li<x>k</x>e and love . because in the be<x>a</x>utiful place. why I like it so much ? <x>beaucse</x> beautiful place and I'm go to AllHelly only Time. what you do eat ?? I'm eat to Hamborgar , Frish and Asier .Thnke you.\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original file\n",
    "cepa_df.Original_Text[137]\n",
    "cepa_df.Original_Text[1524]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CEPA 1 2006625 what the activity is to ideas and to Play foot ball in the clamp and see to manh in T.V of foot ball Games Iam we play move foor ball in the zoo with may fired XXX I paly in the Fradey <o>a</o>t 4 coclek is too storing of tham am and to ray ferar<o>d</o>e in the Zoo as behtFele sprts in any am and I go may fired to see foot ball in clarp in LAwqL Calmp Iam more afeh see footpall amy fired and go to the coFe see foot ball an gierk to cof and wentes and go to may clamp see may pephel play fotb<o>a</o>ll im clamp and me I kan paly more Gams in the comfotre Games in cold places they culive by living with humans.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\"CEPA 2 200606375 the most beau<o>u</otiful pla<x>c</x>e you know in <o>A</o>l Hilly . I like go to the allh<x>i</x>lly because I'm play geam and look in the most beautiful . I play foot ball , tens basketball and play geam to t<x>h</x>e car . I'm look to the sea. I'm go to the AllHilly on frend .your go in the play <o>and aet</o>. I should you go in the All Hilly sawfa li<x>k</x>e and love . because in the be<x>a</x>utiful place. why I like it so much ? <x>beaucse</x> beautiful place and I'm go to AllHelly only Time. what you do eat ?? I'm eat to Hamborgar , Frish and Asier .Thnke you.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning it\n",
    "clean_text(cepa_df.Original_Text[137])\n",
    "clean_text(cepa_df.Original_Text[1524])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' what the activity is to ideas and to Play foot ball in the clamp and see to manh in T.V of foot ball Games Iam we play move foor ball in the zoo with may fired XXX I paly in the Fradey <o>a</o>t 4 coclek is too storing of tham am and to ray ferar<o>d</o>e in the Zoo as behtFele sprts in any am and I go may fired to see foot ball in clarp in LAwqL Calmp Iam more afeh see footpall amy fired and go to the coFe see foot ball an gierk to cof and wentes and go to may clamp see may pephel play fotb<o>a</o>ll im clamp and me I kan paly more Gams in the comfotre Games in cold places they culive by living with humans.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\" the most beau<o>u</otiful pla<x>c</x>e you know in <o>A</o>l Hilly . I like go to the allh<x>i</x>lly because I'm play geam and look in the most beautiful . I play foot ball , tens basketball and play geam to t<x>h</x>e car . I'm look to the sea. I'm go to the AllHilly on frend .your go in the play <o>and aet</o>. I should you go in the All Hilly sawfa li<x>k</x>e and love . because in the be<x>a</x>utiful place. why I like it so much ? <x>beaucse</x> beautiful place and I'm go to AllHelly only Time. what you do eat ?? I'm eat to Hamborgar , Frish and Asier .Thnke you.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Un-heading the cleaned file\n",
    "un_head(clean_text(cepa_df.Original_Text[137]))\n",
    "un_head(clean_text(cepa_df.Original_Text[1524]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' what the activity is to ideas and to Play foot ball in the clamp and see to manh in T.V of foot ball Games Iam we play move foor ball in the zoo with may fired XXX I paly in the Fradey _a_t 4 coclek is too storing of tham am and to ray ferar_d_e in the Zoo as behtFele sprts in any am and I go may fired to see foot ball in clarp in LAwqL Calmp Iam more afeh see footpall amy fired and go to the coFe see foot ball an gierk to cof and wentes and go to may clamp see may pephel play fotb_a_ll im clamp and me I kan paly more Gams in the comfotre Games in cold places they culive by living with humans.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\" the most beau_u_iful pla~~c~~e you know in _A_l Hilly . I like go to the allh~~i~~lly because I'm play geam and look in the most beautiful . I play foot ball , tens basketball and play geam to t~~h~~e car . I'm look to the sea. I'm go to the AllHilly on frend .your go in the play _and aet_. I should you go in the All Hilly sawfa li~~k~~e and love . because in the be~~a~~utiful place. why I like it so much ? ~~beaucse~~ beautiful place and I'm go to AllHelly only Time. what you do eat ?? I'm eat to Hamborgar , Frish and Asier .Thnke you.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retag(un_head(clean_text(cepa_df.Original_Text[137])))\n",
    "retag(un_head(clean_text(cepa_df.Original_Text[1524])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check `normalize()`. It goes a step farther by retagging the HTML codes. This was giving me a lot of trouble earlier! Sometimes it will link words that shouldn't be linked (e.g. \"\\_to_do\" instead of \"\\_to_ do\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Topic _A_ I will writing this a Prerf in far_mer_ in AlAin, who you were of father and mother and ster You did Planing foot dall . happened to watah camall and ive it was so had XXX Donka you like it so much'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_essay(cepa_df.Original_Text[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what the activity is to ideas and to Play foot ball in the clamp and see to manh in T.V of foot ball Games Iam we play move foor ball in the zoo with may fired XXX I paly in the Fradey _a_t 4 coclek is too storing of tham am and to ray ferar_d_e in the Zoo as behtFele sprts in any am and I go may fired to see foot ball in clarp in LAwqL Calmp Iam more afeh see footpall amy fired and go to the coFe see foot ball an gierk to cof and wentes and go to may clamp see may pephel play fotb_a_ll im clamp and me I kan paly more Gams in the comfotre Games in cold places they culive by living with humans.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_essay(cepa_df.Original_Text[137])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding on cepa_df\n",
    "\n",
    "In this section, I will:\n",
    "- Normalize essays with UDFs created in previous section\n",
    "- Make \"Revised_essay\", which removes all tagging\n",
    "- Tokenize (based on revised_essay)\n",
    "- Get token counts (based on revised_essay)\n",
    "- Get TTR (based on revised_essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Level</th>\n",
       "      <th>Original_Text</th>\n",
       "      <th>Normalized_Essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200607296</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200607296\\n\\n\\n\\nNow I tell you...</td>\n",
       "      <td>Now I tell you why my worst holiday ever in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200607457</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200607457\\n\\n\\n\\n              ...</td>\n",
       "      <td>My worst holiday Last year I have just had the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200600487</td>\n",
       "      <td>5</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 5 200600487\\n\\n\\n\\n\\nEvery body i...</td>\n",
       "      <td>Every body in this life have a favourite posse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200608016</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200608016\\n\\n\\n\\nEvery body hav...</td>\n",
       "      <td>Every body have a lot ofpossessions in this li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200611825</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200611825\\n\\n\\n\\nyou go in the ...</td>\n",
       "      <td>you go in the oman just had the perfect holida...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Filename Level                                      Original_Text  \\\n",
       "0  200607296     3  \\t\\t\\t\\tCEPA 3 200607296\\n\\n\\n\\nNow I tell you...   \n",
       "1  200607457     4  \\t\\t\\t\\tCEPA 4 200607457\\n\\n\\n\\n              ...   \n",
       "2  200600487     5  \\t\\t\\t\\tCEPA 5 200600487\\n\\n\\n\\n\\nEvery body i...   \n",
       "3  200608016     4  \\t\\t\\t\\tCEPA 4 200608016\\n\\n\\n\\nEvery body hav...   \n",
       "4  200611825     1  \\t\\t\\t\\tCEPA 1 200611825\\n\\n\\n\\nyou go in the ...   \n",
       "\n",
       "                                    Normalized_Essay  \n",
       "0  Now I tell you why my worst holiday ever in th...  \n",
       "1  My worst holiday Last year I have just had the...  \n",
       "2  Every body in this life have a favourite posse...  \n",
       "3  Every body have a lot ofpossessions in this li...  \n",
       "4  you go in the oman just had the perfect holida...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cepa_df['Normalized_Essay'] = cepa_df.Original_Text.apply(normalize_essay)\n",
    "cepa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Level</th>\n",
       "      <th>Original_Text</th>\n",
       "      <th>Normalized_Essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200607296</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200607296\\n\\n\\n\\nNow I tell you...</td>\n",
       "      <td>Now I tell you why my worst holiday ever in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200607457</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200607457\\n\\n\\n\\n              ...</td>\n",
       "      <td>My worst holiday Last year I have just had the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200608016</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200608016\\n\\n\\n\\nEvery body hav...</td>\n",
       "      <td>Every body have a lot ofpossessions in this li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200611351</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200611351\\n\\n\\n\\nAl_ain mall is...</td>\n",
       "      <td>Al_ain mall is the most beautiful place. First...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>200603206</td>\n",
       "      <td>1</td>\n",
       "      <td>\\n\\t\\t\\t\\tCEPA 1 200603206\\n\\n\\n\\n        Topi...</td>\n",
       "      <td>Topic _A_ I will writing this a Prerf in far_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>200611379</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200611379\\n\\n\\n\\n\\nI spend my w...</td>\n",
       "      <td>I spend my weekend in Dubai. I go with my fami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>200611190</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200611190\\n\\n\\n\\nThere are many...</td>\n",
       "      <td>There are many things make the worst holiday f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>200606353</td>\n",
       "      <td>2</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 2 200606353\\n\\n\\n\\nI m Love the U...</td>\n",
       "      <td>I m Love the UAE the UAE I am very very Love t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>200601400</td>\n",
       "      <td>2</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 2 200601400\\n\\n\\n\\nI have just ha...</td>\n",
       "      <td>I have just had the worst holiday ever . The h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>200601414</td>\n",
       "      <td>2</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 2 200601414\\n\\n\\n\\n&lt;o&gt;I am go to ...</td>\n",
       "      <td>_I am go to the_sumar holabuy in The Oman in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>200601954</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200601954\\n\\n\\n\\nI am go with m...</td>\n",
       "      <td>I am go with may friene_d_ to Oman. I am go wX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>200607721</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200607721\\n\\n\\n\\nIn the last ho...</td>\n",
       "      <td>In the last holid_a_y my family and my uncles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>200600121</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200600121\\n\\n\\n\\nI’m going and ...</td>\n",
       "      <td>I'm going and _zoom_ there _with_ fimi_l_ you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>200606833</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200606833\\n\\n\\n\\nI went the Ome...</td>\n",
       "      <td>I went the Omen. Because is wonderful and a go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>200611556</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200611556\\n\\n\\n\\nI spend my hol...</td>\n",
       "      <td>I spend my holiday is Sauid Arabia. I want wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>200607306</td>\n",
       "      <td>2</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 2 200607306\\n\\n\\n\\nI waite trevel...</td>\n",
       "      <td>I waite trevel wath my famliy to AlAin to see ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>200606756</td>\n",
       "      <td>2</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 2 200606756\\n\\n\\n\\nTopic B : We g...</td>\n",
       "      <td>Topic B : We go with my family by car in a ^Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>200605920</td>\n",
       "      <td>2</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 2 200605920\\n\\n\\n\\nMy live in the...</td>\n",
       "      <td>My live in the Shajohe, A house is very beauti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>200605692</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200605692\\n\\n\\n\\nEvery body kno...</td>\n",
       "      <td>Every body know that the summer holiday is the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>200611608</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200611608\\n\\n\\n\\nLast weekend I...</td>\n",
       "      <td>Last weekend Im went to Dudai with my Frinds i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>200611835</td>\n",
       "      <td>2</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 2 200611835\\n\\n\\n\\nIs vary bast f...</td>\n",
       "      <td>Is vary bast filme you have seen recentry. The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>200605673</td>\n",
       "      <td>2</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 2 200605673\\n\\n\\n\\n        Sport....</td>\n",
       "      <td>Sport.... The Sport is very important in peopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>200601415</td>\n",
       "      <td>2</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 2 200601415\\n\\n\\n\\nlast week &lt;o&gt;i...</td>\n",
       "      <td>last week _in the End i_t is verey bad the hol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>200612469</td>\n",
       "      <td>2</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 2 200612469\\n\\n\\n\\nI writ thise t...</td>\n",
       "      <td>I writ thise topic about Imagin you have just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>200605115</td>\n",
       "      <td>2</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 2 200605115\\n\\n\\n\\nThe last holid...</td>\n",
       "      <td>The last holiday Imagine went you _have_ just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>200607898</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200607898\\n\\n\\n\\nIn the last su...</td>\n",
       "      <td>In the last summar I have spent awery wonderfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>200607268</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200607268\\n\\n\\n\\nIn the summer ...</td>\n",
       "      <td>In the summer 2004 I went to bahrain with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>200610880</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200610880\\n\\n\\n\\n\\n\\nIn  the ho...</td>\n",
       "      <td>In the holiday , My family decided go to the b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>200611385</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200611385\\n\\n\\n\\nIn summer holi...</td>\n",
       "      <td>In summer holiday I went with my fami_lly_ to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>200607326</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200607326\\n\\n\\n\\nLast summer &lt;x...</td>\n",
       "      <td>Last summer ~~I weih~~ I went to Syria with my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>200607854</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200607854\\n\\n\\n\\nIn the last ye...</td>\n",
       "      <td>In the last year I have jast had the worst hol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>200607840</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200607840\\n\\n\\n\\nReally I love ...</td>\n",
       "      <td>Really I love the Indian films because it took...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>200606375</td>\n",
       "      <td>2</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 2 200606375\\n\\n\\n\\nthe most beau&lt;...</td>\n",
       "      <td>the most beau_u_iful pla~~c~~e you know in _A_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>200602894</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCepa 1 200602894\\n\\n\\n\\nYou went In Om...</td>\n",
       "      <td>You went In Oman you have just has the perfect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>200607303</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200607303\\n\\n\\n\\nThe main reaso...</td>\n",
       "      <td>The main reason that people travel in holidaye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>200606605</td>\n",
       "      <td>2</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 2 200606605\\n\\n\\n\\nI love play fo...</td>\n",
       "      <td>I love play football . I play with my friend ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>200608018</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200608018\\n\\n\\n\\nThere are many...</td>\n",
       "      <td>There are many favourite thing`s in my Life bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>200609733</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200609733\\n\\n\\n\\n&lt;o&gt;Sea in UAE ...</td>\n",
       "      <td>_Sea in UAE I like the sea I look the fish and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>200611836</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200611836\\n\\n\\n\\n\\t\\t\\t\\tThe wo...</td>\n",
       "      <td>The worst holiday Imagine my holiday in the Ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>200612442</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200612442\\n\\n\\n\\nLast xxx week ...</td>\n",
       "      <td>Last xxx week I am see a good movie or film. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>200607842</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200607842\\n\\n\\n\\n&lt;o&gt;T&lt;/o&gt;hese  ...</td>\n",
       "      <td>_T_hese holiday is worst holiday I spend it . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>200601958</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200601958\\n\\n\\n\\nMy car the my ...</td>\n",
       "      <td>My car the my car is ver_y_ fast the name my c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>200601970</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200601970\\n\\n\\n\\nYou have just ...</td>\n",
       "      <td>You have just had the perfect holiday you went...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>200600313</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200600313\\n\\n\\n\\nI me give a lo...</td>\n",
       "      <td>I me give a lot than Iam gin_e_ you have just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>200606782</td>\n",
       "      <td>3</td>\n",
       "      <td>CEPA 3 200606782\\n\\n\\n\\n\\nI go withe m...</td>\n",
       "      <td>I go withe my Frineds to USA and i go to hilto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>200612085</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200612085\\n\\n\\n\\n\\nMy perfect h...</td>\n",
       "      <td>My perfect holiday was in Last year. It was in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>200606796</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200606796\\n\\n\\n\\nThe weekend in...</td>\n",
       "      <td>The weekend in the summer I am go to visit , I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>200600677</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200600677\\n\\n\\n\\nshe have just ...</td>\n",
       "      <td>she have just ha_d_ the perfect. went go to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>200604411</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200604411\\n\\n\\n\\nThe ar&lt;o&gt;e&lt;/o&gt;...</td>\n",
       "      <td>The ar_e_ simr it flmatd . the you went smie ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>200607310</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200607310\\n\\n\\n\\nIn one day I w...</td>\n",
       "      <td>In one day I was in holiday . The holiday was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>200605068</td>\n",
       "      <td>1</td>\n",
       "      <td>`\\t\\t\\t\\tCEPA 1 200605068\\n\\n\\n\\nOn The Samir ...</td>\n",
       "      <td>On The Samir i go fo The sliame will i sea fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>200605846</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200605846\\n\\n\\n\\n              ...</td>\n",
       "      <td>The most beautiful place I was choose this top...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>200601971</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA  1 200601971\\n\\n\\n\\nwhere you wen...</td>\n",
       "      <td>where you went in the we XXX. xxx in The zoo w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>200605336</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200605336\\n\\n\\nThe go in Sharja...</td>\n",
       "      <td>The go in Sharja sate to help you could descri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>20067753</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 20067753\\n\\n\\n\\nIn sutardy I wi...</td>\n",
       "      <td>In sutardy I will perfact happy holiday,..I we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>200600299</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200600299\\n\\n\\n\\nI magine you h...</td>\n",
       "      <td>I magine you hav_e_ just the P_er_fect holiday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>200610505</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200610505\\n\\n\\n\\nWhere you went...</td>\n",
       "      <td>Where you went, who you went there with, what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>200608033</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200608033\\n\\n\\n\\n\\t\\t\\t\\tThe wo...</td>\n",
       "      <td>The worst holiday The worst holiday in my hole...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>200606606</td>\n",
       "      <td>2</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 2 200606606\\n\\n\\n\\n        Topic ...</td>\n",
       "      <td>Topic A In the summer I went with my f~~ri~~nd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>200608027</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200608027\\n\\n\\n\\n\\t\\t\\t\\tThe pe...</td>\n",
       "      <td>The perfect holiday Summer holiday is the best...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Filename Level                                      Original_Text  \\\n",
       "0     200607296     3  \\t\\t\\t\\tCEPA 3 200607296\\n\\n\\n\\nNow I tell you...   \n",
       "1     200607457     4  \\t\\t\\t\\tCEPA 4 200607457\\n\\n\\n\\n              ...   \n",
       "3     200608016     4  \\t\\t\\t\\tCEPA 4 200608016\\n\\n\\n\\nEvery body hav...   \n",
       "9     200611351     3  \\t\\t\\t\\tCEPA 3 200611351\\n\\n\\n\\nAl_ain mall is...   \n",
       "15    200603206     1  \\n\\t\\t\\t\\tCEPA 1 200603206\\n\\n\\n\\n        Topi...   \n",
       "16    200611379     3  \\t\\t\\t\\tCEPA 3 200611379\\n\\n\\n\\n\\nI spend my w...   \n",
       "18    200611190     3  \\t\\t\\t\\tCEPA 3 200611190\\n\\n\\n\\nThere are many...   \n",
       "19    200606353     2  \\t\\t\\t\\tCEPA 2 200606353\\n\\n\\n\\nI m Love the U...   \n",
       "23    200601400     2  \\t\\t\\t\\tCEPA 2 200601400\\n\\n\\n\\nI have just ha...   \n",
       "24    200601414     2  \\t\\t\\t\\tCEPA 2 200601414\\n\\n\\n\\n<o>I am go to ...   \n",
       "30    200601954     1  \\t\\t\\t\\tCEPA 1 200601954\\n\\n\\n\\nI am go with m...   \n",
       "32    200607721     4  \\t\\t\\t\\tCEPA 4 200607721\\n\\n\\n\\nIn the last ho...   \n",
       "52    200600121     1  \\t\\t\\t\\tCEPA 1 200600121\\n\\n\\n\\nI’m going and ...   \n",
       "59    200606833     4  \\t\\t\\t\\tCEPA 4 200606833\\n\\n\\n\\nI went the Ome...   \n",
       "60    200611556     3  \\t\\t\\t\\tCEPA 3 200611556\\n\\n\\n\\nI spend my hol...   \n",
       "62    200607306     2  \\t\\t\\t\\tCEPA 2 200607306\\n\\n\\n\\nI waite trevel...   \n",
       "65    200606756     2  \\t\\t\\t\\tCEPA 2 200606756\\n\\n\\n\\nTopic B : We g...   \n",
       "69    200605920     2  \\t\\t\\t\\tCEPA 2 200605920\\n\\n\\n\\nMy live in the...   \n",
       "71    200605692     4  \\t\\t\\t\\tCEPA 4 200605692\\n\\n\\n\\nEvery body kno...   \n",
       "79    200611608     3  \\t\\t\\t\\tCEPA 3 200611608\\n\\n\\n\\nLast weekend I...   \n",
       "82    200611835     2  \\t\\t\\t\\tCEPA 2 200611835\\n\\n\\n\\nIs vary bast f...   \n",
       "83    200605673     2  \\t\\t\\t\\tCEPA 2 200605673\\n\\n\\n\\n        Sport....   \n",
       "84    200601415     2  \\t\\t\\t\\tCEPA 2 200601415\\n\\n\\n\\nlast week <o>i...   \n",
       "86    200612469     2  \\t\\t\\t\\tCEPA 2 200612469\\n\\n\\n\\nI writ thise t...   \n",
       "88    200605115     2  \\t\\t\\t\\tCEPA 2 200605115\\n\\n\\n\\nThe last holid...   \n",
       "92    200607898     4  \\t\\t\\t\\tCEPA 4 200607898\\n\\n\\n\\nIn the last su...   \n",
       "97    200607268     3  \\t\\t\\t\\tCEPA 3 200607268\\n\\n\\n\\nIn the summer ...   \n",
       "104   200610880     4  \\t\\t\\t\\tCEPA 4 200610880\\n\\n\\n\\n\\n\\nIn  the ho...   \n",
       "113   200611385     3  \\t\\t\\t\\tCEPA 3 200611385\\n\\n\\n\\nIn summer holi...   \n",
       "114   200607326     4  \\t\\t\\t\\tCEPA 4 200607326\\n\\n\\n\\nLast summer <x...   \n",
       "...         ...   ...                                                ...   \n",
       "1517  200607854     4  \\t\\t\\t\\tCEPA 4 200607854\\n\\n\\n\\nIn the last ye...   \n",
       "1519  200607840     4  \\t\\t\\t\\tCEPA 4 200607840\\n\\n\\n\\nReally I love ...   \n",
       "1524  200606375     2  \\t\\t\\t\\tCEPA 2 200606375\\n\\n\\n\\nthe most beau<...   \n",
       "1536  200602894     1  \\t\\t\\t\\tCepa 1 200602894\\n\\n\\n\\nYou went In Om...   \n",
       "1541  200607303     4  \\t\\t\\t\\tCEPA 4 200607303\\n\\n\\n\\nThe main reaso...   \n",
       "1542  200606605     2  \\t\\t\\t\\tCEPA 2 200606605\\n\\n\\n\\nI love play fo...   \n",
       "1546  200608018     4  \\t\\t\\t\\tCEPA 4 200608018\\n\\n\\n\\nThere are many...   \n",
       "1556  200609733     1  \\t\\t\\t\\tCEPA 1 200609733\\n\\n\\n\\n<o>Sea in UAE ...   \n",
       "1559  200611836     3  \\t\\t\\t\\tCEPA 3 200611836\\n\\n\\n\\n\\t\\t\\t\\tThe wo...   \n",
       "1563  200612442     3  \\t\\t\\t\\tCEPA 3 200612442\\n\\n\\n\\nLast xxx week ...   \n",
       "1566  200607842     4  \\t\\t\\t\\tCEPA 4 200607842\\n\\n\\n\\n<o>T</o>hese  ...   \n",
       "1572  200601958     1  \\t\\t\\t\\tCEPA 1 200601958\\n\\n\\n\\nMy car the my ...   \n",
       "1573  200601970     1  \\t\\t\\t\\tCEPA 1 200601970\\n\\n\\n\\nYou have just ...   \n",
       "1577  200600313     1  \\t\\t\\t\\tCEPA 1 200600313\\n\\n\\n\\nI me give a lo...   \n",
       "1581  200606782     3          CEPA 3 200606782\\n\\n\\n\\n\\nI go withe m...   \n",
       "1582  200612085     3  \\t\\t\\t\\tCEPA 3 200612085\\n\\n\\n\\n\\nMy perfect h...   \n",
       "1583  200606796     3  \\t\\t\\t\\tCEPA 3 200606796\\n\\n\\n\\nThe weekend in...   \n",
       "1589  200600677     1  \\t\\t\\t\\tCEPA 1 200600677\\n\\n\\n\\nshe have just ...   \n",
       "1592  200604411     1  \\t\\t\\t\\tCEPA 1 200604411\\n\\n\\n\\nThe ar<o>e</o>...   \n",
       "1598  200607310     3  \\t\\t\\t\\tCEPA 3 200607310\\n\\n\\n\\nIn one day I w...   \n",
       "1604  200605068     1  `\\t\\t\\t\\tCEPA 1 200605068\\n\\n\\n\\nOn The Samir ...   \n",
       "1611  200605846     4  \\t\\t\\t\\tCEPA 4 200605846\\n\\n\\n\\n              ...   \n",
       "1617  200601971     1  \\t\\t\\t\\tCEPA  1 200601971\\n\\n\\n\\nwhere you wen...   \n",
       "1628  200605336     1  \\t\\t\\t\\tCEPA 1 200605336\\n\\n\\nThe go in Sharja...   \n",
       "1630   20067753     3  \\t\\t\\t\\tCEPA 3 20067753\\n\\n\\n\\nIn sutardy I wi...   \n",
       "1635  200600299     1  \\t\\t\\t\\tCEPA 1 200600299\\n\\n\\n\\nI magine you h...   \n",
       "1639  200610505     1  \\t\\t\\t\\tCEPA 1 200610505\\n\\n\\n\\nWhere you went...   \n",
       "1647  200608033     4  \\t\\t\\t\\tCEPA 4 200608033\\n\\n\\n\\n\\t\\t\\t\\tThe wo...   \n",
       "1648  200606606     2  \\t\\t\\t\\tCEPA 2 200606606\\n\\n\\n\\n        Topic ...   \n",
       "1649  200608027     4  \\t\\t\\t\\tCEPA 4 200608027\\n\\n\\n\\n\\t\\t\\t\\tThe pe...   \n",
       "\n",
       "                                       Normalized_Essay  \n",
       "0     Now I tell you why my worst holiday ever in th...  \n",
       "1     My worst holiday Last year I have just had the...  \n",
       "3     Every body have a lot ofpossessions in this li...  \n",
       "9     Al_ain mall is the most beautiful place. First...  \n",
       "15    Topic _A_ I will writing this a Prerf in far_m...  \n",
       "16    I spend my weekend in Dubai. I go with my fami...  \n",
       "18    There are many things make the worst holiday f...  \n",
       "19    I m Love the UAE the UAE I am very very Love t...  \n",
       "23    I have just had the worst holiday ever . The h...  \n",
       "24    _I am go to the_sumar holabuy in The Oman in t...  \n",
       "30    I am go with may friene_d_ to Oman. I am go wX...  \n",
       "32    In the last holid_a_y my family and my uncles ...  \n",
       "52    I'm going and _zoom_ there _with_ fimi_l_ you ...  \n",
       "59    I went the Omen. Because is wonderful and a go...  \n",
       "60    I spend my holiday is Sauid Arabia. I want wit...  \n",
       "62    I waite trevel wath my famliy to AlAin to see ...  \n",
       "65    Topic B : We go with my family by car in a ^Al...  \n",
       "69    My live in the Shajohe, A house is very beauti...  \n",
       "71    Every body know that the summer holiday is the...  \n",
       "79    Last weekend Im went to Dudai with my Frinds i...  \n",
       "82    Is vary bast filme you have seen recentry. The...  \n",
       "83    Sport.... The Sport is very important in peopl...  \n",
       "84    last week _in the End i_t is verey bad the hol...  \n",
       "86    I writ thise topic about Imagin you have just ...  \n",
       "88    The last holiday Imagine went you _have_ just ...  \n",
       "92    In the last summar I have spent awery wonderfu...  \n",
       "97    In the summer 2004 I went to bahrain with my f...  \n",
       "104   In the holiday , My family decided go to the b...  \n",
       "113   In summer holiday I went with my fami_lly_ to ...  \n",
       "114   Last summer ~~I weih~~ I went to Syria with my...  \n",
       "...                                                 ...  \n",
       "1517  In the last year I have jast had the worst hol...  \n",
       "1519  Really I love the Indian films because it took...  \n",
       "1524  the most beau_u_iful pla~~c~~e you know in _A_...  \n",
       "1536  You went In Oman you have just has the perfect...  \n",
       "1541  The main reason that people travel in holidaye...  \n",
       "1542  I love play football . I play with my friend ....  \n",
       "1546  There are many favourite thing`s in my Life bu...  \n",
       "1556  _Sea in UAE I like the sea I look the fish and...  \n",
       "1559  The worst holiday Imagine my holiday in the Ho...  \n",
       "1563  Last xxx week I am see a good movie or film. I...  \n",
       "1566  _T_hese holiday is worst holiday I spend it . ...  \n",
       "1572  My car the my car is ver_y_ fast the name my c...  \n",
       "1573  You have just had the perfect holiday you went...  \n",
       "1577  I me give a lot than Iam gin_e_ you have just ...  \n",
       "1581  I go withe my Frineds to USA and i go to hilto...  \n",
       "1582  My perfect holiday was in Last year. It was in...  \n",
       "1583  The weekend in the summer I am go to visit , I...  \n",
       "1589  she have just ha_d_ the perfect. went go to th...  \n",
       "1592  The ar_e_ simr it flmatd . the you went smie ....  \n",
       "1598  In one day I was in holiday . The holiday was ...  \n",
       "1604  On The Samir i go fo The sliame will i sea fal...  \n",
       "1611  The most beautiful place I was choose this top...  \n",
       "1617  where you went in the we XXX. xxx in The zoo w...  \n",
       "1628  The go in Sharja sate to help you could descri...  \n",
       "1630  In sutardy I will perfact happy holiday,..I we...  \n",
       "1635  I magine you hav_e_ just the P_er_fect holiday...  \n",
       "1639  Where you went, who you went there with, what ...  \n",
       "1647  The worst holiday The worst holiday in my hole...  \n",
       "1648  Topic A In the summer I went with my f~~ri~~nd...  \n",
       "1649  The perfect holiday Summer holiday is the best...  \n",
       "\n",
       "[434 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cepa_df[cepa_df.Normalized_Essay.str.contains(r'_\\w{2,}')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Level</th>\n",
       "      <th>Original_Text</th>\n",
       "      <th>Normalized_Essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Filename, Level, Original_Text, Normalized_Essay]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cepa_df[cepa_df.Normalized_Essay.str.contains(r'[<>]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\t\\t\\t\\tCEPA 3 200606808\\n\\n\\n\\nA Good day ti go the picnicto a Al Ain, I am go wiht my friend , I say them \"i <x>s</x>ee you in the M<x>e</x>ga Mall t<x>o</x> begin th picnic toworoion\" In 8.30 A.M I meet my fi<x>r</x>iend he say \" I want breakfast I am don\\'t e<o>a</o>ten <o><it </o>\" , I say \"O.K le<x>t\\'s</x> go to the fastfood, i<x>t h</x>as eiar the mall \" we began the picnic, I the street my firend say\"Al Ain a wanderful cityI would go the AlHale park\", than I say \" It\\'s good iea<o>sc</o> let\\'s go ther\" than I <x>am</x> see Al Ain cit<x>y</x> than I go to xxx the park ,I around the AlHafet montrain in 6.00pm I say my fi<x>r</x>end \" let\\'s go bark and sharjah \"I say my selt \" The picnic it\\'s wonderful picnic I se<x>e</x> in the park a football ground, the cinldren play ground and an AlHafet mountrain I see the <x>w</x>o<x>n</x>derful reck I get them for my father he like the rock \"it\\'s my picnis .\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'A Good day ti go the picnicto a Al Ain, I am go wiht my friend , I say them \"i ~~s~~ee you in the M~~e~~ga Mall t~~o~~ begin th picnic toworoion\" In 8.30 A.M I meet my fi~~r~~iend he say \" I want breakfast I am don\\'t e_a_ten _ it_\" , I say \"O.K le~~t\\'s~~ go to the fastfood, i~~t h~~as eiar the mall \" we began the picnic, I the street my firend say\"Al Ain a wanderful cityI would go the AlHale park\", than I say \" It\\'s good iea_sc_ let\\'s go ther\" than I ~~am~~ see Al Ain cit~~y~~ than I go to xxx the park ,I around the AlHafet montrain in 6.00pm I say my fi~~r~~end \" let\\'s go bark and sharjah \"I say my selt \" The picnic it\\'s wonderful picnic I se~~e~~ in the park a football ground, the cinldren play ground and an AlHafet mountrain I see the ~~w~~o~~n~~derful reck I get them for my father he like the rock \"it\\'s my picnis .'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cepa_df.Original_Text[214]\n",
    "cepa_df.Normalized_Essay[214]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\t\\t\\t\\tCEPA 2 200606375\\n\\n\\n\\nthe most beau<o>u</otiful pla<x>c</x>e you know in <o>A</o>l Hilly . I like go to the allh<x>i</x>lly because I'm play geam and look in the most beautiful . I play foot ball , tens basketball and play geam to t<x>h</x>e car . I'm look to the sea. I'm go to the AllHilly on frend .your go in the play <o>and aet</o>. I should you go in the All Hilly sawfa li<x>k</x>e and love . because in the be<x>a</x>utiful place. why I like it so much ? <x>beaucse</x> beautiful place and I'm go to AllHelly only Time. what you do eat ?? I'm eat to Hamborgar , Frish and Asier .Thnke you.\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cepa_df.Original_Text[1524]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_I am go to the_sumar holabuy in The Oman in the Slala in my family the Salala is very haphe and go to The Oman in The car on my calal becoues is not go in the sun and becoues people go in Oman go to the sea and the swming ,eating in Faham beoue_s_ is bleshes food in the brth_a_r in the very nais in the swmming and go the play foot ple and go to the santar in the shoping and go to the Zoo is very naies and becoues in the manke and lion and tor to us in the anmils and go to The hotel go the slep. becous go to in The Famliy is very nais and is very haply'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\t\\t\\t\\tCEPA 2 200601414\\n\\n\\n\\n<o>I am go to the</o>sumar holabuy in The Oman in the Slala in my family the Salala is very haphe and go to The Oman in The car on my calal becoues is not go in the sun and becoues people go in Oman go to the sea and the swming ,eating in Faham beoue<o>s</o> is bleshes food in the brth<o>a</o>r in the very nais in the swmming and go the play foot ple and go to the santar in the shoping and go to the Zoo is very naies and becoues in the manke and lion and tor to us in the anmils and go to The hotel go the slep. becous go to in The Famliy is very nais and is very haply\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cepa_df.Normalized_Essay[24]\n",
    "cepa_df.Original_Text[24]\n",
    "\n",
    "# Yes, we can see \"the\" and \"sumar\" are connected in the phrase \"I am go in the sumar\" -- but that was in the original text, so that's probably not an error created by me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\t\\t\\t\\tCEPA 2 200605920\\n\\n\\n\\nMy live in the Shajohe, A house is very beautiful, 2 rezens  <i>for righting</i>\\nThe houses in the <o>fife</o> romes, I like rome is me .\\nFirse, be<x>c</x>uos a beautiful my rome, I like the rome becous the see are me bar play in rome and eat \\nSacend,\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'My live in the Shajohe, A house is very beautiful, 2 rezens ^for righting^ The houses in the _fife_ romes, I like rome is me . Firse, be~~c~~uos a beautiful my rome, I like the rome becous the see are me bar play in rome and eat Sacend,'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cepa_df.Original_Text[69]\n",
    "cepa_df.Normalized_Essay[69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF to remove tags -- removes tagging for insertions and emphasis, and removes anything within a cross-out tag\n",
    "def remove_tags(text):\n",
    "    \"\"\"Removes tags from Normalized_Essay. If there are tags indicating a student crossed something out, whatever is \n",
    "    enclosed in those tags is removed.\"\"\"\n",
    "    text = re.sub(r'~~.*?~~', '', text)         # delete tags for crossing out and the text in those tags\n",
    "    text = text.replace('_', '').replace('^', '')   # remove emphasis and insertion tags\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Level</th>\n",
       "      <th>Original_Text</th>\n",
       "      <th>Normalized_Essay</th>\n",
       "      <th>Revised_Essay</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>200607088</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200607088\\n\\nxxx No body can de...</td>\n",
       "      <td>xxx No body can deny how I spent my summer hol...</td>\n",
       "      <td>xxx No body can deny how I spent my summer hol...</td>\n",
       "      <td>[xxx, No, body, can, deny, how, I, spent, my, ...</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>200610975</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200610975\\n\\n\\n\\nI had the wors...</td>\n",
       "      <td>I had the worst holiday ever. _I_ went to the ...</td>\n",
       "      <td>I had the worst holiday ever. I went to the  ,...</td>\n",
       "      <td>[I, had, the, worst, holiday, ever, ., I, went...</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>200601835</td>\n",
       "      <td>5</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 5 200601835\\n\\n\\n\\nLast year I ha...</td>\n",
       "      <td>Last year I had my worst summer holiday. I tra...</td>\n",
       "      <td>Last year I had my worst summer holiday. I tra...</td>\n",
       "      <td>[Last, year, I, had, my, worst, summer, holida...</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>200680259</td>\n",
       "      <td>6</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 6 200680259\\n\\n\\n\\nThrough out li...</td>\n",
       "      <td>Through out life people posses many stuff, som...</td>\n",
       "      <td>Through out life people posses many stuff, som...</td>\n",
       "      <td>[Through, out, life, people, posses, many, stu...</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>200608835</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200608835\\n\\n\\n\\nI go in the sa...</td>\n",
       "      <td>I go in the safa park</td>\n",
       "      <td>I go in the safa park</td>\n",
       "      <td>[I, go, in, the, safa, park]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>200607970</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200607970\\n\\n\\n\\nOne day whew I...</td>\n",
       "      <td>One day whew I was in a grade 11 my mother dec...</td>\n",
       "      <td>One day whew I was in a grade 11 my mother dec...</td>\n",
       "      <td>[One, day, whew, I, was, in, a, grade, 11, my,...</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>200607804</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200607804\\n\\n\\n\\nLast summer  I...</td>\n",
       "      <td>Last summer I had a very nice holiday .It was ...</td>\n",
       "      <td>Last summer I had a very nice holiday .It was ...</td>\n",
       "      <td>[Last, summer, I, had, a, very, nice, holiday,...</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>200600469</td>\n",
       "      <td>5</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 5 200600469\\n\\n\\n\\nI think the im...</td>\n",
       "      <td>I think the imagine is very important and enjo...</td>\n",
       "      <td>I think the imagine is very important and enjo...</td>\n",
       "      <td>[I, think, the, imagine, is, very, important, ...</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>200608142</td>\n",
       "      <td>5</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 5 200608142\\n\\n\\n\\nI think everyo...</td>\n",
       "      <td>I think everyone should spend a nice and beaut...</td>\n",
       "      <td>I think everyone should spend a nice and beaut...</td>\n",
       "      <td>[I, think, everyone, should, spend, a, nice, a...</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>200605666</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200605666\\n\\n\\n\\n        My hap...</td>\n",
       "      <td>My happy holiday Any people should spend thier...</td>\n",
       "      <td>My happy holiday Any people should spend thier...</td>\n",
       "      <td>[My, happy, holiday, Any, people, should, spen...</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>200621795</td>\n",
       "      <td>6</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 6 200621795\\n\\n\\n\\nLast summer I ...</td>\n",
       "      <td>Last summer I had the perfect holiday.I went t...</td>\n",
       "      <td>Last summer I had the perfect holiday.I went t...</td>\n",
       "      <td>[Last, summer, I, had, the, perfect, holiday.I...</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>200601700</td>\n",
       "      <td>5</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 5 200601700\\n\\n\\n\\nThere are many...</td>\n",
       "      <td>There are many intersting holidays I had it bu...</td>\n",
       "      <td>There are many intersting holidays I had it bu...</td>\n",
       "      <td>[There, are, many, intersting, holidays, I, ha...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>200605806</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200605806\\n\\n\\n\\nI actvity ther...</td>\n",
       "      <td>I actvity ther you enjoy doing. You could desc...</td>\n",
       "      <td>I actvity ther you enjoy doing. You could desc...</td>\n",
       "      <td>[I, actvity, ther, you, enjoy, doing, ., You, ...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>200606476</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200606476\\n\\n\\n\\nThe Kan we TV....</td>\n",
       "      <td>The Kan we TV. me star predator Tim 2.0 m, K w...</td>\n",
       "      <td>The Kan we TV. me star predator Tim 2.0 m, K w...</td>\n",
       "      <td>[The, Kan, we, TV, ., me, star, predator, Tim,...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>200605544</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200605544\\n\\n\\n\\nThe holiday is...</td>\n",
       "      <td>The holiday is the wonderful time you can spen...</td>\n",
       "      <td>The holiday is the wonderful time you can spen...</td>\n",
       "      <td>[The, holiday, is, the, wonderful, time, you, ...</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Filename Level                                      Original_Text  \\\n",
       "1340  200607088     3  \\t\\t\\t\\tCEPA 3 200607088\\n\\nxxx No body can de...   \n",
       "1169  200610975     3  \\t\\t\\t\\tCEPA 3 200610975\\n\\n\\n\\nI had the wors...   \n",
       "46    200601835     5  \\t\\t\\t\\tCEPA 5 200601835\\n\\n\\n\\nLast year I ha...   \n",
       "1560  200680259     6  \\t\\t\\t\\tCEPA 6 200680259\\n\\n\\n\\nThrough out li...   \n",
       "1633  200608835     1  \\t\\t\\t\\tCEPA 1 200608835\\n\\n\\n\\nI go in the sa...   \n",
       "482   200607970     4  \\t\\t\\t\\tCEPA 4 200607970\\n\\n\\n\\nOne day whew I...   \n",
       "500   200607804     4  \\t\\t\\t\\tCEPA 4 200607804\\n\\n\\n\\nLast summer  I...   \n",
       "326   200600469     5  \\t\\t\\t\\tCEPA 5 200600469\\n\\n\\n\\nI think the im...   \n",
       "256   200608142     5  \\t\\t\\t\\tCEPA 5 200608142\\n\\n\\n\\nI think everyo...   \n",
       "1372  200605666     4  \\t\\t\\t\\tCEPA 4 200605666\\n\\n\\n\\n        My hap...   \n",
       "1101  200621795     6  \\t\\t\\t\\tCEPA 6 200621795\\n\\n\\n\\nLast summer I ...   \n",
       "753   200601700     5  \\t\\t\\t\\tCEPA 5 200601700\\n\\n\\n\\nThere are many...   \n",
       "858   200605806     1  \\t\\t\\t\\tCEPA 1 200605806\\n\\n\\n\\nI actvity ther...   \n",
       "1255  200606476     1  \\t\\t\\t\\tCEPA 1 200606476\\n\\n\\n\\nThe Kan we TV....   \n",
       "533   200605544     4  \\t\\t\\t\\tCEPA 4 200605544\\n\\n\\n\\nThe holiday is...   \n",
       "\n",
       "                                       Normalized_Essay  \\\n",
       "1340  xxx No body can deny how I spent my summer hol...   \n",
       "1169  I had the worst holiday ever. _I_ went to the ...   \n",
       "46    Last year I had my worst summer holiday. I tra...   \n",
       "1560  Through out life people posses many stuff, som...   \n",
       "1633                              I go in the safa park   \n",
       "482   One day whew I was in a grade 11 my mother dec...   \n",
       "500   Last summer I had a very nice holiday .It was ...   \n",
       "326   I think the imagine is very important and enjo...   \n",
       "256   I think everyone should spend a nice and beaut...   \n",
       "1372  My happy holiday Any people should spend thier...   \n",
       "1101  Last summer I had the perfect holiday.I went t...   \n",
       "753   There are many intersting holidays I had it bu...   \n",
       "858   I actvity ther you enjoy doing. You could desc...   \n",
       "1255  The Kan we TV. me star predator Tim 2.0 m, K w...   \n",
       "533   The holiday is the wonderful time you can spen...   \n",
       "\n",
       "                                          Revised_Essay  \\\n",
       "1340  xxx No body can deny how I spent my summer hol...   \n",
       "1169  I had the worst holiday ever. I went to the  ,...   \n",
       "46    Last year I had my worst summer holiday. I tra...   \n",
       "1560  Through out life people posses many stuff, som...   \n",
       "1633                              I go in the safa park   \n",
       "482   One day whew I was in a grade 11 my mother dec...   \n",
       "500   Last summer I had a very nice holiday .It was ...   \n",
       "326   I think the imagine is very important and enjo...   \n",
       "256   I think everyone should spend a nice and beaut...   \n",
       "1372  My happy holiday Any people should spend thier...   \n",
       "1101  Last summer I had the perfect holiday.I went t...   \n",
       "753   There are many intersting holidays I had it bu...   \n",
       "858   I actvity ther you enjoy doing. You could desc...   \n",
       "1255  The Kan we TV. me star predator Tim 2.0 m, K w...   \n",
       "533   The holiday is the wonderful time you can spen...   \n",
       "\n",
       "                                                 tokens  token_count  \n",
       "1340  [xxx, No, body, can, deny, how, I, spent, my, ...           79  \n",
       "1169  [I, had, the, worst, holiday, ever, ., I, went...          152  \n",
       "46    [Last, year, I, had, my, worst, summer, holida...          217  \n",
       "1560  [Through, out, life, people, posses, many, stu...          245  \n",
       "1633                       [I, go, in, the, safa, park]            6  \n",
       "482   [One, day, whew, I, was, in, a, grade, 11, my,...          192  \n",
       "500   [Last, summer, I, had, a, very, nice, holiday,...          271  \n",
       "326   [I, think, the, imagine, is, very, important, ...          211  \n",
       "256   [I, think, everyone, should, spend, a, nice, a...          278  \n",
       "1372  [My, happy, holiday, Any, people, should, spen...          206  \n",
       "1101  [Last, summer, I, had, the, perfect, holiday.I...          286  \n",
       "753   [There, are, many, intersting, holidays, I, ha...          200  \n",
       "858   [I, actvity, ther, you, enjoy, doing, ., You, ...           54  \n",
       "1255  [The, Kan, we, TV, ., me, star, predator, Tim,...           15  \n",
       "533   [The, holiday, is, the, wonderful, time, you, ...          217  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove_tags applied to creat \"Revised_Essay\"\n",
    "# Tokenize revised_essay\n",
    "# Get token count\n",
    "cepa_df['Revised_Essay'] = cepa_df.Normalized_Essay.apply(remove_tags)\n",
    "cepa_df['tokens'] = cepa_df.Revised_Essay.apply(nltk.word_tokenize)\n",
    "cepa_df['token_count'] = cepa_df.tokens.map(len)\n",
    "cepa_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Level</th>\n",
       "      <th>Original_Text</th>\n",
       "      <th>Normalized_Essay</th>\n",
       "      <th>Revised_Essay</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200608959</td>\n",
       "      <td>5</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 5 200608959\\n\\n\\n\\nI have just ha...</td>\n",
       "      <td>I have just had the perfect and the best holid...</td>\n",
       "      <td>I have just had the perfect and the best holid...</td>\n",
       "      <td>[I, have, just, had, the, perfect, and, the, b...</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>200612443</td>\n",
       "      <td>2</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 2 200612443\\n\\n\\n\\nI’m writing To...</td>\n",
       "      <td>I'm writing Topic B to Describe the best film ...</td>\n",
       "      <td>I'm writing Topic B to Describe the best film ...</td>\n",
       "      <td>[I, 'm, writing, Topic, B, to, Describe, the, ...</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>200611155</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200611155\\n\\n\\n\\nIn the last su...</td>\n",
       "      <td>In the last summer holiday, I hade the worest ...</td>\n",
       "      <td>In the last summer holiday, I hade the worest ...</td>\n",
       "      <td>[In, the, last, summer, holiday, ,, I, hade, t...</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>200612584</td>\n",
       "      <td>2</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 2 200612584\\n\\n\\n\\nThese weekend ...</td>\n",
       "      <td>These weekend the worst. Because I stayd at ho...</td>\n",
       "      <td>These weekend the worst. Because I stayd at ho...</td>\n",
       "      <td>[These, weekend, the, worst, ., Because, I, st...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>200611303</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200611303\\n\\n\\n\\nThere are many...</td>\n",
       "      <td>There are many qualites the worst weekend bad....</td>\n",
       "      <td>There are many qualites the worst weekend bad....</td>\n",
       "      <td>[There, are, many, qualites, the, worst, weeke...</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>200604402</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200604402\\n\\n\\n\\n&lt;x&gt;me&lt;/x&gt; &lt;o&gt;m...</td>\n",
       "      <td>~~me~~ _my you went ar_wous. went ~~my~~ and f...</td>\n",
       "      <td>my you went arwous. went  and fraund  Yor  ne...</td>\n",
       "      <td>[my, you, went, arwous, ., went, and, fraund, ...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Filename Level                                      Original_Text  \\\n",
       "6     200608959     5  \\t\\t\\t\\tCEPA 5 200608959\\n\\n\\n\\nI have just ha...   \n",
       "128   200612443     2  \\t\\t\\t\\tCEPA 2 200612443\\n\\n\\n\\nI’m writing To...   \n",
       "237   200611155     3  \\t\\t\\t\\tCEPA 3 200611155\\n\\n\\n\\nIn the last su...   \n",
       "812   200612584     2  \\t\\t\\t\\tCEPA 2 200612584\\n\\n\\n\\nThese weekend ...   \n",
       "1251  200611303     3  \\t\\t\\t\\tCEPA 3 200611303\\n\\n\\n\\nThere are many...   \n",
       "1401  200604402     1  \\t\\t\\t\\tCEPA 1 200604402\\n\\n\\n\\n<x>me</x> <o>m...   \n",
       "\n",
       "                                       Normalized_Essay  \\\n",
       "6     I have just had the perfect and the best holid...   \n",
       "128   I'm writing Topic B to Describe the best film ...   \n",
       "237   In the last summer holiday, I hade the worest ...   \n",
       "812   These weekend the worst. Because I stayd at ho...   \n",
       "1251  There are many qualites the worst weekend bad....   \n",
       "1401  ~~me~~ _my you went ar_wous. went ~~my~~ and f...   \n",
       "\n",
       "                                          Revised_Essay  \\\n",
       "6     I have just had the perfect and the best holid...   \n",
       "128   I'm writing Topic B to Describe the best film ...   \n",
       "237   In the last summer holiday, I hade the worest ...   \n",
       "812   These weekend the worst. Because I stayd at ho...   \n",
       "1251  There are many qualites the worst weekend bad....   \n",
       "1401   my you went arwous. went  and fraund  Yor  ne...   \n",
       "\n",
       "                                                 tokens  token_count  \n",
       "6     [I, have, just, had, the, perfect, and, the, b...          277  \n",
       "128   [I, 'm, writing, Topic, B, to, Describe, the, ...          310  \n",
       "237   [In, the, last, summer, holiday, ,, I, hade, t...          264  \n",
       "812   [These, weekend, the, worst, ., Because, I, st...           52  \n",
       "1251  [There, are, many, qualites, the, worst, weeke...          199  \n",
       "1401  [my, you, went, arwous, ., went, and, fraund, ...           42  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to make sure there are no \"cepa\" tokens included from incorrect/incomplete heading removal\n",
    "cepa_df[cepa_df.tokens.apply(lambda x: 'cepa' in [y.lower() for y in x])]\n",
    "\n",
    "# returns are essays that talk about cepa "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Let's keep truckin' along!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get TTR\n",
    "def get_TTR(toks):\n",
    "    \"\"\"All tokens are lowercased, punctuation is included.\n",
    "    Get TTR by dividing set of lowercased tokens by length of tokens.\"\"\"\n",
    "    all_toks = [x.lower() for x in toks]\n",
    "    if len(all_toks) == 0:   # at least one file has 0 tokens, so I got an error about dividing by zero without this\n",
    "        return 0\n",
    "    else: return len(set(all_toks))/len(all_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619047619047619"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking UDF\n",
    "foo = \"My name is Elena and I am a Junior Linguist. I study applied linguistics, and i want to be a linguist.\"\n",
    "get_TTR(foo.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619047619047619"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking UDF by hand\n",
    "lil = [x.lower() for x in foo.split()]\n",
    "len(set(lil))/len(lil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking UDF on an empty string\n",
    "foo = \"\"\n",
    "get_TTR(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cepa_df['TTR'] = cepa_df.tokens.apply(get_TTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Level</th>\n",
       "      <th>Original_Text</th>\n",
       "      <th>Normalized_Essay</th>\n",
       "      <th>Revised_Essay</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_count</th>\n",
       "      <th>TTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200607296</td>\n",
       "      <td>3</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 3 200607296\\n\\n\\n\\nNow I tell you...</td>\n",
       "      <td>Now I tell you why my worst holiday ever in th...</td>\n",
       "      <td>Now I tell you why my worst holiday ever in th...</td>\n",
       "      <td>[Now, I, tell, you, why, my, worst, holiday, e...</td>\n",
       "      <td>207</td>\n",
       "      <td>0.492754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200607457</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200607457\\n\\n\\n\\n              ...</td>\n",
       "      <td>My worst holiday Last year I have just had the...</td>\n",
       "      <td>My worst holiday Last year I have just had the...</td>\n",
       "      <td>[My, worst, holiday, Last, year, I, have, just...</td>\n",
       "      <td>180</td>\n",
       "      <td>0.572222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200600487</td>\n",
       "      <td>5</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 5 200600487\\n\\n\\n\\n\\nEvery body i...</td>\n",
       "      <td>Every body in this life have a favourite posse...</td>\n",
       "      <td>Every body in this life have a favourite posse...</td>\n",
       "      <td>[Every, body, in, this, life, have, a, favouri...</td>\n",
       "      <td>229</td>\n",
       "      <td>0.445415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200608016</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200608016\\n\\n\\n\\nEvery body hav...</td>\n",
       "      <td>Every body have a lot ofpossessions in this li...</td>\n",
       "      <td>Every body have a lot ofpossessions in this li...</td>\n",
       "      <td>[Every, body, have, a, lot, ofpossessions, in,...</td>\n",
       "      <td>156</td>\n",
       "      <td>0.608974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200611825</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200611825\\n\\n\\n\\nyou go in the ...</td>\n",
       "      <td>you go in the oman just had the perfect holida...</td>\n",
       "      <td>you go in the oman just had the perfect holida...</td>\n",
       "      <td>[you, go, in, the, oman, just, had, the, perfe...</td>\n",
       "      <td>27</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Filename Level                                      Original_Text  \\\n",
       "0  200607296     3  \\t\\t\\t\\tCEPA 3 200607296\\n\\n\\n\\nNow I tell you...   \n",
       "1  200607457     4  \\t\\t\\t\\tCEPA 4 200607457\\n\\n\\n\\n              ...   \n",
       "2  200600487     5  \\t\\t\\t\\tCEPA 5 200600487\\n\\n\\n\\n\\nEvery body i...   \n",
       "3  200608016     4  \\t\\t\\t\\tCEPA 4 200608016\\n\\n\\n\\nEvery body hav...   \n",
       "4  200611825     1  \\t\\t\\t\\tCEPA 1 200611825\\n\\n\\n\\nyou go in the ...   \n",
       "\n",
       "                                    Normalized_Essay  \\\n",
       "0  Now I tell you why my worst holiday ever in th...   \n",
       "1  My worst holiday Last year I have just had the...   \n",
       "2  Every body in this life have a favourite posse...   \n",
       "3  Every body have a lot ofpossessions in this li...   \n",
       "4  you go in the oman just had the perfect holida...   \n",
       "\n",
       "                                       Revised_Essay  \\\n",
       "0  Now I tell you why my worst holiday ever in th...   \n",
       "1  My worst holiday Last year I have just had the...   \n",
       "2  Every body in this life have a favourite posse...   \n",
       "3  Every body have a lot ofpossessions in this li...   \n",
       "4  you go in the oman just had the perfect holida...   \n",
       "\n",
       "                                              tokens  token_count       TTR  \n",
       "0  [Now, I, tell, you, why, my, worst, holiday, e...          207  0.492754  \n",
       "1  [My, worst, holiday, Last, year, I, have, just...          180  0.572222  \n",
       "2  [Every, body, in, this, life, have, a, favouri...          229  0.445415  \n",
       "3  [Every, body, have, a, lot, ofpossessions, in,...          156  0.608974  \n",
       "4  [you, go, in, the, oman, just, had, the, perfe...           27  0.629630  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cepa_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptives\n",
    "Here, I do two things: I make sure everything is read in correctly, and I look at some basic descriptive stats for the DataFrame, such as the descriptions of token count, TTR, and value counts for the different levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all filenames should have only 1 value\n",
    "all(cepa_df.Filename.value_counts() == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1664, 8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of the DataFrame as is\n",
    "cepa_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2', '6', '5', '4', '3', '1'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Levels should be 1-6 only\n",
    "set(cepa_df.Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_count</th>\n",
       "      <th>TTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1664.000000</td>\n",
       "      <td>1664.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>160.146635</td>\n",
       "      <td>0.546312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>86.137210</td>\n",
       "      <td>0.115905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>0.471569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>164.000000</td>\n",
       "      <td>0.522902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>224.000000</td>\n",
       "      <td>0.590166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>397.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token_count          TTR\n",
       "count  1664.000000  1664.000000\n",
       "mean    160.146635     0.546312\n",
       "std      86.137210     0.115905\n",
       "min       0.000000     0.000000\n",
       "25%      85.000000     0.471569\n",
       "50%     164.000000     0.522902\n",
       "75%     224.000000     0.590166\n",
       "max     397.000000     1.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be 1664 counts for everything -- at least 1 token_count of 0\n",
    "cepa_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    299\n",
       "4    297\n",
       "2    292\n",
       "1    276\n",
       "3    250\n",
       "6    250\n",
       "Name: Level, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's review the number of files for each level\n",
    "cepa_df.Level.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Level</th>\n",
       "      <th>Original_Text</th>\n",
       "      <th>Normalized_Essay</th>\n",
       "      <th>Revised_Essay</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_count</th>\n",
       "      <th>TTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>200604511</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200604511\\n\\n\\n\\n\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Filename Level                       Original_Text Normalized_Essay  \\\n",
       "1079  200604511     1  \\t\\t\\t\\tCEPA 1 200604511\\n\\n\\n\\n\\n                    \n",
       "\n",
       "     Revised_Essay tokens  token_count  TTR  \n",
       "1079                   []            0  0.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see how many files have no tokens\n",
    "cepa_df[cepa_df.token_count == 0]\n",
    "\n",
    "# Just 1! and it's a level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Level</th>\n",
       "      <th>Original_Text</th>\n",
       "      <th>Normalized_Essay</th>\n",
       "      <th>Revised_Essay</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_count</th>\n",
       "      <th>TTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>200608341</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200608341\\n\\n\\n\\nI don’t now\\n</td>\n",
       "      <td>I don't now</td>\n",
       "      <td>I don't now</td>\n",
       "      <td>[I, do, n't, now]</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>200606487</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200606487\\n\\n\\n\\nThe mask\\nThes...</td>\n",
       "      <td>The mask These film is Dangrs</td>\n",
       "      <td>The mask These film is Dangrs</td>\n",
       "      <td>[The, mask, These, film, is, Dangrs]</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>200611449</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200611449\\n\\n\\n\\nOman it agood ...</td>\n",
       "      <td>Oman it agood cantry.</td>\n",
       "      <td>Oman it agood cantry.</td>\n",
       "      <td>[Oman, it, agood, cantry, .]</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>200611925</td>\n",
       "      <td>2</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 2 200611925\\n\\n\\n\\nIm KHALED ABDU...</td>\n",
       "      <td>Im KHALED ABDULLA AL SHAMISI from the UAE. ALAin</td>\n",
       "      <td>Im KHALED ABDULLA AL SHAMISI from the UAE. ALAin</td>\n",
       "      <td>[Im, KHALED, ABDULLA, AL, SHAMISI, from, the, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>200611666</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200611666\\n\\n\\n\\nSo good weathe...</td>\n",
       "      <td>So good weather in the summer</td>\n",
       "      <td>So good weather in the summer</td>\n",
       "      <td>[So, good, weather, in, the, summer]</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>200604490</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200604490\\n\\n\\n\\nyo to &lt;o&gt;AL&lt;/o...</td>\n",
       "      <td>yo to _AL_Ain an sammr not Haeep</td>\n",
       "      <td>yo to ALAin an sammr not Haeep</td>\n",
       "      <td>[yo, to, ALAin, an, sammr, not, Haeep]</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>200606507</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200606507\\n\\n\\n\\nThe Al Ain in ...</td>\n",
       "      <td>The Al Ain in no To fot xxx EYecPh</td>\n",
       "      <td>The Al Ain in no To fot xxx EYecPh</td>\n",
       "      <td>[The, Al, Ain, in, no, To, fot, xxx, EYecPh]</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>200608510</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200608510\\n\\n\\n\\nI you a Oman ....</td>\n",
       "      <td>I you a Oman .I are went there faiml</td>\n",
       "      <td>I you a Oman .I are went there faiml</td>\n",
       "      <td>[I, you, a, Oman, .I, are, went, there, faiml]</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>200612172</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200612172\\n\\n\\n\\nOne fire day w...</td>\n",
       "      <td>One fire day waent to the _cea_nima with ferin...</td>\n",
       "      <td>One fire day waent to the ceanima with ferinds...</td>\n",
       "      <td>[One, fire, day, waent, to, the, ceanima, with...</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>200603781</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200603781\\n\\n\\n\\nI go to the Du...</td>\n",
       "      <td>I go to the Dubai</td>\n",
       "      <td>I go to the Dubai</td>\n",
       "      <td>[I, go, to, the, Dubai]</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>200612328</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200612328\\n\\n\\n\\nmy freid a&lt;x&gt;s...</td>\n",
       "      <td>my freid a~~s~~ the s footboul,</td>\n",
       "      <td>my freid a the s footboul,</td>\n",
       "      <td>[my, freid, a, the, s, footboul, ,]</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>200603779</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200603779\\n\\n\\n\\nwhere you went...</td>\n",
       "      <td>where you went to Al Ain abd Oman Go people an...</td>\n",
       "      <td>where you went to Al Ain abd Oman Go people an...</td>\n",
       "      <td>[where, you, went, to, Al, Ain, abd, Oman, Go,...</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>200608835</td>\n",
       "      <td>1</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 1 200608835\\n\\n\\n\\nI go in the sa...</td>\n",
       "      <td>I go in the safa park</td>\n",
       "      <td>I go in the safa park</td>\n",
       "      <td>[I, go, in, the, safa, park]</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>200606988</td>\n",
       "      <td>4</td>\n",
       "      <td>\\t\\t\\t\\tCEPA 4 200606988\\n\\n\\nHandwriting not ...</td>\n",
       "      <td>Handwriting not clear, legible</td>\n",
       "      <td>Handwriting not clear, legible</td>\n",
       "      <td>[Handwriting, not, clear, ,, legible]</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Filename Level                                      Original_Text  \\\n",
       "227   200608341     1      \\t\\t\\t\\tCEPA 1 200608341\\n\\n\\n\\nI don’t now\\n   \n",
       "538   200606487     1  \\t\\t\\t\\tCEPA 1 200606487\\n\\n\\n\\nThe mask\\nThes...   \n",
       "620   200611449     1  \\t\\t\\t\\tCEPA 1 200611449\\n\\n\\n\\nOman it agood ...   \n",
       "684   200611925     2  \\t\\t\\t\\tCEPA 2 200611925\\n\\n\\n\\nIm KHALED ABDU...   \n",
       "736   200611666     1  \\t\\t\\t\\tCEPA 1 200611666\\n\\n\\n\\nSo good weathe...   \n",
       "794   200604490     1  \\t\\t\\t\\tCEPA 1 200604490\\n\\n\\n\\nyo to <o>AL</o...   \n",
       "922   200606507     1  \\t\\t\\t\\tCEPA 1 200606507\\n\\n\\n\\nThe Al Ain in ...   \n",
       "1115  200608510     1  \\t\\t\\t\\tCEPA 1 200608510\\n\\n\\n\\nI you a Oman ....   \n",
       "1187  200612172     1  \\t\\t\\t\\tCEPA 1 200612172\\n\\n\\n\\nOne fire day w...   \n",
       "1337  200603781     1  \\t\\t\\t\\tCEPA 1 200603781\\n\\n\\n\\nI go to the Du...   \n",
       "1426  200612328     1  \\t\\t\\t\\tCEPA 1 200612328\\n\\n\\n\\nmy freid a<x>s...   \n",
       "1457  200603779     1  \\t\\t\\t\\tCEPA 1 200603779\\n\\n\\n\\nwhere you went...   \n",
       "1633  200608835     1  \\t\\t\\t\\tCEPA 1 200608835\\n\\n\\n\\nI go in the sa...   \n",
       "1651  200606988     4  \\t\\t\\t\\tCEPA 4 200606988\\n\\n\\nHandwriting not ...   \n",
       "\n",
       "                                       Normalized_Essay  \\\n",
       "227                                         I don't now   \n",
       "538                       The mask These film is Dangrs   \n",
       "620                               Oman it agood cantry.   \n",
       "684    Im KHALED ABDULLA AL SHAMISI from the UAE. ALAin   \n",
       "736                       So good weather in the summer   \n",
       "794                    yo to _AL_Ain an sammr not Haeep   \n",
       "922                  The Al Ain in no To fot xxx EYecPh   \n",
       "1115               I you a Oman .I are went there faiml   \n",
       "1187  One fire day waent to the _cea_nima with ferin...   \n",
       "1337                                  I go to the Dubai   \n",
       "1426                    my freid a~~s~~ the s footboul,   \n",
       "1457  where you went to Al Ain abd Oman Go people an...   \n",
       "1633                              I go in the safa park   \n",
       "1651                     Handwriting not clear, legible   \n",
       "\n",
       "                                          Revised_Essay  \\\n",
       "227                                         I don't now   \n",
       "538                       The mask These film is Dangrs   \n",
       "620                               Oman it agood cantry.   \n",
       "684    Im KHALED ABDULLA AL SHAMISI from the UAE. ALAin   \n",
       "736                       So good weather in the summer   \n",
       "794                      yo to ALAin an sammr not Haeep   \n",
       "922                  The Al Ain in no To fot xxx EYecPh   \n",
       "1115               I you a Oman .I are went there faiml   \n",
       "1187  One fire day waent to the ceanima with ferinds...   \n",
       "1337                                  I go to the Dubai   \n",
       "1426                         my freid a the s footboul,   \n",
       "1457  where you went to Al Ain abd Oman Go people an...   \n",
       "1633                              I go in the safa park   \n",
       "1651                     Handwriting not clear, legible   \n",
       "\n",
       "                                                 tokens  token_count  TTR  \n",
       "227                                   [I, do, n't, now]            4  1.0  \n",
       "538                [The, mask, These, film, is, Dangrs]            6  1.0  \n",
       "620                        [Oman, it, agood, cantry, .]            5  1.0  \n",
       "684   [Im, KHALED, ABDULLA, AL, SHAMISI, from, the, ...           10  1.0  \n",
       "736                [So, good, weather, in, the, summer]            6  1.0  \n",
       "794              [yo, to, ALAin, an, sammr, not, Haeep]            7  1.0  \n",
       "922        [The, Al, Ain, in, no, To, fot, xxx, EYecPh]            9  1.0  \n",
       "1115     [I, you, a, Oman, .I, are, went, there, faiml]            9  1.0  \n",
       "1187  [One, fire, day, waent, to, the, ceanima, with...           13  1.0  \n",
       "1337                            [I, go, to, the, Dubai]            5  1.0  \n",
       "1426                [my, freid, a, the, s, footboul, ,]            7  1.0  \n",
       "1457  [where, you, went, to, Al, Ain, abd, Oman, Go,...           14  1.0  \n",
       "1633                       [I, go, in, the, safa, park]            6  1.0  \n",
       "1651              [Handwriting, not, clear, ,, legible]            5  1.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, let's see how many TTRs of 1.0 there are \n",
    "cepa_df[cepa_df.TTR == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few of these should probably be thrown out -- \"I don't (k)now\", \"Handwriting not clear, legible\". Or maybe the cutoff for token_count in analysis should be greater than 4 -- it would get rid of the empty file above, as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic visualization and analysis\n",
    "Now I want to look at some graphs quickly before wrapping up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot object at 0x1a1e409cf8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's visualize the amount of files in each level\n",
    "sns.countplot(x=\"Level\", data=cepa_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already know the value counts of the levels, but it doesn't hurt to visualize it! Levels 2, 4, and 5 have the most files, getting near to 300. It looks like 3 and 6 have the least amount of files.\n",
    "\n",
    "Normally, we would expect the least amount of files in higher proficiencies. We would expect to see more files around a medium proficiency, and more low-level files than high-level files. We did see that for the most part in our original .jpg data: Levels 1, 2, 3, and 5 had 300 files each, Level 4 had 298, and Level 6 had 252 files.\n",
    "\n",
    "Therefore, it looks like we \"lost\" the most data in Levels 1 and 3. Only a handful of files were dropped from the other levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid object at 0x1a1e4098d0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's look at general length by level\n",
    "sns.catplot(x='Level', y='token_count', kind='box', data=cepa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=764.373757392868, pvalue=0.0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lv1_tokct = cepa_df[cepa_df.Level == '1'].token_count # token count for level 1\n",
    "lv2_tokct = cepa_df[cepa_df.Level == '2'].token_count # token count for level 2\n",
    "lv3_tokct = cepa_df[cepa_df.Level == '3'].token_count # token count for level 3\n",
    "lv4_tokct = cepa_df[cepa_df.Level == '4'].token_count # token count for level 4\n",
    "lv5_tokct = cepa_df[cepa_df.Level == '5'].token_count # token count for level 5\n",
    "lv6_tokct = cepa_df[cepa_df.Level == '6'].token_count # token count for level 6\n",
    "\n",
    "stats.f_oneway(lv1_tokct, lv2_tokct, lv3_tokct, lv4_tokct, lv5_tokct, lv6_tokct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see something that's pretty expected! The higher level students typically write more than the lower level students. There's a handful of outliers, mostly in Level 1. The one-way ANOVA suggests that there is a significant difference between groups here, but we will have to investigate a little bit more to pinpoint exactly where/what it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid object at 0x1a1e863ac8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(x='Level', y='TTR', kind='box', data=cepa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=208.1989467995349, pvalue=1.6028012530002684e-172)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lv1_ttr = cepa_df[cepa_df.Level == '1'].TTR # ttr for level 1\n",
    "lv2_ttr = cepa_df[cepa_df.Level == '2'].TTR # ttr for level 2\n",
    "lv3_ttr = cepa_df[cepa_df.Level == '3'].TTR # ttr for level 3\n",
    "lv4_ttr = cepa_df[cepa_df.Level == '4'].TTR # ttr for level 4\n",
    "lv5_ttr = cepa_df[cepa_df.Level == '5'].TTR # ttr for level 5\n",
    "lv6_ttr = cepa_df[cepa_df.Level == '6'].TTR # ttr for level 6\n",
    "\n",
    "stats.f_oneway(lv1_ttr, lv2_ttr, lv3_ttr, lv4_ttr, lv5_ttr, lv6_ttr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This really isn't too surprising! The higher the (perceived) level is, the more students seem to write. Conversely, becuase they're writing more, there's more of a likelihood that they'll repeat their words, especially when compared to much lower levels (1, 2). Of course, TTR tells us more when it's normalized/controlled for length, so maybe we can return to this later.\n",
    "\n",
    "There's a few TTRs of or near 1.0, which means students didn't repeat _any_ words in their essays. Again, that's not too hard to do when you're writing very short essays! However, there's another thing to take into account here: we have seen from our work above that students make a _lot_ of spelling errors, and sometimes the same student will spell the same word several different ways in the same essay! So this measure of TTR still may not have the highest accuracy because students _may actually be repeating words_, but it isn't caught by the TTR function because they're misspelling the word, so they may appear to be different words. Just something to think about!\n",
    "\n",
    "As with the token count, the one-way ANOVA suggests that there is a significant difference between groups here, though we'll still need to do some digging!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "So, I've done quite a bit here, I think! I read in all the CEPA files, accounting for duplicates; standardized the tagging in essays, and then removed it; and now I have some specific linguistic data to look at! The essays, tokens, token counts, and TTR so far. I would like to POS tag and possibly lemmatize still, but I think this is a good start.\n",
    "\n",
    "From my brief (and admittedly pretty shallow) descriptive and quantitative analysis, I found that we still have a pretty good distribution of texts across the different levels. We found that get higher in (perceived) quality/proficiency, they tend to get longer, and their TTR tends to get lower. Again, this is expected, so that's not bad! Both of these differences appear to be signficant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
